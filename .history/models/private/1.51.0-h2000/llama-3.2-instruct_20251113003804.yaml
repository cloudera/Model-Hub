models:
- name: Llama 3.2 Instruct
  displayName: Llama 3.2 Instruct
  modelHubID: llama-3.2-instruct
  category: Commercial and Research
  type: NGC
  description: The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pre-trained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://llama.meta.com/llama3_2/use-policy/
  - label: License Agreement
    url: https://llama.meta.com/llama3_2/license/
  modelVariants:
  - variantId: Llama 3.2 1B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_2-1b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.2-1b-instruct:b200x1-throughput-bf16-olbx5u2wza
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct B200x1 BF16 Throughput
      ngcMetadata:
        00974a79b608dd9dc2e302879e71708692c9c6304f5905eb4da7d661dadd6ec2:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3190e2309f20a42f1888add452d98f204147634d83e7e5a7bbb401f9e898de2e
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h100x1-throughput-bf16-coy0mruniw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100x1 BF16 Throughput
      ngcMetadata:
        023958aa70e985eb0a0d25c60d7a03732ad5ee7d4f9ac2ebcce17397b172b58c:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4ba0b194b524b5d78bfa90c76ad9789b54069996b45beca9ce05762a295d871a
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-fp8-q4ene2avnw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        0b900e8d26b11d548f74a903739434bf00fc990439a9245042e344d253481719:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b771a0a1bf21ee92364a0f1c9db64628d74919517edf09f47b079aab90af963e
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:a10gx1-throughput-bf16-wmuh1shq9q
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A10Gx1 BF16 Throughput
      ngcMetadata:
        0f7eb9e9a9b4470a7b5b6e93b806ad27ff49b1a94c30aa2986ffaf281f6e8d1f:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e28f4aa923af93efab6e6c14dceae117980f3f805e47f871464af69ea1457946
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 BF16 Latency
      ngcMetadata:
        0f87e0f30087419b3a4a74d7902753a6daee998e59c0676d412fefe141f62ffe:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6582d9bebeaaa8b1cc21b6a10cdde0daf92a198e7f9950b21908a77a90d47c3e
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100_NVLx1 BF16 Throughput
      ngcMetadata:
        0f94ccdaf02fa00a986ba3b2b8ff0351ffa73fe262176e89830445ad81b6bfbc:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 92f394e8f167dca76b9c8eb40b8a09edd896b6fd6ec126ba5609a9c90cc21f59
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_144GBx1 FP8 Latency
      ngcMetadata:
        129db5959331b4c24cae55957a8bef7cce73fcc7571001fe18556c9b691db5d8:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 11d5467289919d18be03dbdd3236e1d2b1fdf81681b52167fadc2af453e8f6ea
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:l40sx1-throughput-bf16-mr-zfjdk9w
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct L40Sx1 BF16 Throughput
      ngcMetadata:
        13d24e5a873aea5df261998c94710c6d00b59074f8389143d94a370762569bf8:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 72a4b35de823e2ba47bc9bac68b3704d0a9eae3db2037458d70d813809c6af78
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 FP8 Latency
      ngcMetadata:
        14389e34e76649cff246559bc0374718143cb5ac1286f7a53f6e0314c70b004b:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2493505e4182b1596bf60600e22bae9fd94056b3988e591bceace38117523d26
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 BF16 Throughput
      ngcMetadata:
        1d76561dbe108226813651f3fd70416295040612f0cf3c36fd330fc388d9ef60:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8d4e43ad080af609d17f7c559a838f1e46da4a990bfbee068d540601847951e5
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200_NVLx1 FP8 Throughput
      ngcMetadata:
        280bfbbbf4ea6e6744b706d25032054ad18289814406f251d9f862b044c51c67:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 50ad558f72f96fb5171036046bfaab28fc9eb1157e31488c5da2c3ab0134c020
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200_NVLx1 BF16 Throughput
      ngcMetadata:
        2d1a186f55c204c95b4abd9df2056e3095b148700cd8fdda115ffe7bea3bed60:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 940e6e9a959cdd8829c9cba449c1c8bc83ef2522ce1f263cbc7e1920399fe465
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100_NVLx1 FP8 Throughput
      ngcMetadata:
        2e2ecec7b2d03c998a8bae64e150a5f88bfde56917d372dc91ffc08f94c9d07f:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9fb78395ea4e775bdbf7c8df874ee89b4e084d35fd3ee6f8b105ec6061e8d887
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200_NVLx2 FP8 Latency
      ngcMetadata:
        2e92e2be673e48b2312076393db8caff10c7dae24bf90cd1637b197fe2dda0f2:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ba433d54af67e3a0d72db4a896acb2e92ba9caa41d731086c34d9e77df019c7d
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:a100x2-latency-bf16-ezdh3qtgsw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A100x2 BF16 Latency
      ngcMetadata:
        345837de17bc4e103174352bc07a86112cef00318470e5477afb24908d09abb6:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f517db32f12098356f9ef902992f57d5362a4e58a8d185c993cc93657f18a3cb
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:a10gx2-latency-bf16-sdcegxqefa
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A10Gx2 BF16 Latency
      ngcMetadata:
        41eb6cd432c8d498926942101511e4da1e913d0d22adbc96ed547a8042d2b7ce:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 071daef17e33c140ef8b82b89004ed3d5412e3eca9b4bedb8b57824dc05e975c
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A100_SXM4_40GBx2 BF16 Latency
      ngcMetadata:
        43a51be16bada864c0ab6acc3e267e333fe69150a05287d5386e7cb39c7c61bb:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 04ee232eb94574469d111ff8001c42836ee881f67fbf9040fbdc582e6b1b1c42
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_144GBx1 BF16 Latency
      ngcMetadata:
        4843f0f1c0b0b410cbc37dbb748396f2793b0eb5ed8ad9f215e06da1e82b98e8:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 736c2ad1750f0504768fb31d97587a07cc473517c232e8454f098e63c0f5de5c
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A100_SXM4_40GBx1 BF16 Throughput
      ngcMetadata:
        4acbbc32a700f17dd483e6a53914ec62688d029120fb0c216420e8481983d0e7:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 10849901781866ddf59b10df9f42464a7c089c5f0a61f41f6b25862f19195a7b
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:l40sx2-latency-fp8-uvobdo54ig
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct L40Sx2 FP8 Latency
      ngcMetadata:
        55be74aa57225eb45db56bda45a2e1ad7a02f8f30d5f8eef9877df8adacc0550:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0669a60d949ab85b17b5f2a73d7e9f6b131797740da6ed43e29e5f41066d571c
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-fp8--yymwnqgka
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x2 FP8 Latency
      ngcMetadata:
        58db8acdee23b42a43f731e5e6e7d123ff889d70318dd876d8325bfdd9d52023:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d9bafa9974769a2f7539affd5e55acef006ce62c15bc088dc3a55afd818ee124
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:gb200x1-throughput-bf16-zyj-crhkzq
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GB200x1 BF16 Throughput
      ngcMetadata:
        59619a192c8ef4c65e8363642f722508401f1392f64fd007337abb01ecbe7d19:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 35decffe402ab43b965bedff55c8cef9addc05e917187701562af2f4fe213de9
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-bf16-tsa8sfptpw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x1 BF16 Throughput
      ngcMetadata:
        61555d7be4e6de25c9219d7a0bb106d40ce887b31f29ea8df4fee6110e2b853b:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9b5fee25e36a210bec2865d4ebd5c974a8cf4e4002efacd9ec516642370cbd9c
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:b200x1-throughput-fp8-ys-xbyv-sg
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        6d0ee85cf622a72848fc5daa170614ce7fcec7167fe53d718878f08eb24cb965:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 5c56717955f737f260b918572f35036dee10c1b54530f4096fa66af19b17ffd5
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        700827bec7ac9724fe295b4bdde657eff97c34de54f3ad504fabfe32e12e3e18:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8e95c5073de6fd99ffce7014cc733fe55fa894162cfec8c938756de81fa8ecac
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200_NVLx2 BF16 Latency
      ngcMetadata:
        70089c0e01ba82698bed7ab932bafebc141455e40bd15567f7e37496ac7bcf1e:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3575e95e2064a522faa33fa6dbf9a6c3eddbee6bcf286d0c44315142c402b089
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-bf16-itm2i3hlig
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x2 BF16 Latency
      ngcMetadata:
        7c29442049d0390525e51aaf5d3d3ac7c676bf7222707b7ed29442e2a95227c5:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f987c70ae752902a0fb500d8f378afd65fc5b47b5eeb88627004b0edb210bcd8
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 FP8 Throughput
      ngcMetadata:
        85eeb431dec2e7ce1aff645c1e1e08d0a42a644f64874c68a65fd4e07189b902:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d76814b2d2442f8ad709563f653ed4b80e39f5ad1acbd0b84822235fe4e3d1a4
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:l40sx1-throughput-fp8-wocwu5pweq
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct L40Sx1 FP8 Throughput
      ngcMetadata:
        894221e5032dfb82de8567266ea22114b8597aabc85b93e92ad290508ecd33bf:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 13f1a9e953c8a5320111dc8a580cd3855291326abe1d1e5b5c7dfced9cb6f6ea
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:a100x1-throughput-bf16-dohmk4psfa
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct A100x1 BF16 Throughput
      ngcMetadata:
        8b22a466a5ef2f848151ea4679201cf4f7fe7ebd7094671cfa3df7a25836b4ff:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c83a64076a4cecd2c6d8d55db86ba5d0b31395c28ab806962828aa291c192b33
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:gb200x2-latency-bf16-2w1oa3-9bw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GB200x2 BF16 Latency
      ngcMetadata:
        930b33fdac9c955b3149d675d262d286f7e4db61503e9c9de17aa18dfe092238:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e8d3089f177a1641f3b610799a19a3a4c752e1795eca7be92a129e9bae5cbc39
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_480GBx1 BF16 Throughput
      ngcMetadata:
        a416c249ee8f78d2790919c1d5e6f3afa3be9d85f3e77cd635e65335caae4ddb:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: cafc299ec54dd11d527965baac566347feccd9dad56d5a89cfb4e710e56b8b2c
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-fp8-b62hkfmx2a
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        a6780e332aeb2c67ff491b2b1d13f04c58c238bc07bad39af5b0c552d6e3dfae:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7ccea195195ee0642c6785c8d5aa7ab8976737fc4f80f2966f5dcf7c8333391d
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:gb200x1-throughput-fp8-nupr5gs2dw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GB200x1 FP8 Throughput
      ngcMetadata:
        a8d5512071d8c48e62ac709edc231cbf158aacc5faae00040379c8c3bc4f2bf8:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: bc56bf15cfcf13e2c7834d0ce1767a27719c1de7291cee654f6232c35375bf45
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h100x2-latency-fp8-5cyndvc2za
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100x2 FP8 Latency
      ngcMetadata:
        af99cd31d06f9fb19ffe3dfce1e5c053ffbd43f3c7e671d9c4550eccb8dee31e:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 44b31027ddef82c6ddcd49ecfc68f20067975ad0d9b62755ca3667e055f48ab5
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:l40sx2-latency-bf16-wimz1alj0q
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct L40Sx2 BF16 Latency
      ngcMetadata:
        b0833059fa3270d15e7a2ccbd1228fe5a3681b5801395d5c2c306fac3a386534:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a4315018cc1c0f75d76920b73d557daea0e2f4dfbd8b626515adb36e90ebba12
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        b4375abbe106a961f61ebfc40ecb73490ca64fadba7b06c156173aeec81ed2fa:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 94f9fdc707b068711db2447004698e4a90be58c6d3329463ba57c85714bff488
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:b200x2-latency-bf16-jvvom3lafg
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct B200x2 BF16 Latency
      ngcMetadata:
        bb8774e429cd06145c3af972a557193da4859bbb406bdd6ab4eba1111b757ee4:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 417053eecdaf868c0db37d64920e90eb29881638168c9781c33309dabd9852c8
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100_NVLx2 FP8 Latency
      ngcMetadata:
        bbc09967e87df528eafcdee9c95946cbc528a004bade8c30e4d655902b4a1eda:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7ad4d81f5c1ff5bd7171ee75a51e45af792644f3cc45282999e3405adfbec78e
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h100x1-throughput-fp8-tfwwzbhdca
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100x1 FP8 Throughput
      ngcMetadata:
        cad5ff155623a7ed9e6e400347be5d2b1772324a4389585f372d99ab2b18310b:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: fa0733fe89758e6911ee12b330d3bc39d1e933a9cffcd13f80f54f00e44d5808
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 2GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GH200_144GBx1 BF16 Throughput
      ngcMetadata:
        cc2a610402f4d5fc1b580b09af8e0f35c4a6214bc5a3da2de66aa1c9eaf00703:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 64b5a893869e9c17ddd2a31f28ebe867079c41899f1e00c503cce640fa487128
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:gb200x2-latency-fp8-mj9h4xjlpw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct GB200x2 FP8 Latency
      ngcMetadata:
        d30b476874b44f6d697a81c37a6a5df7747b95d77ec196644b1b288cfa4ebb99:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a79685d119872d802f1fd849c1636665049ff58a7354fb536df1451d42952a75
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h100x2-latency-bf16-kdm6hypmza
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100x2 BF16 Latency
      ngcMetadata:
        d35b0a4879ffc8a4ee620979a9b0306c1d35265c0d0d4917b1079da1bd44c830:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: adb5fe983b732e233035db031b01461e698505aa8db330f00da89ed240b244b3
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-fp8-qdlgs44zrw
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H200x2 FP8 Latency
      ngcMetadata:
        ece478a8ed72c4ff1b85bf758b105a30b724f5da2320278a50d7328ae661eaed:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a14e294573c64a9a49641e82012cb4fa3776f6fe25d9be84092b4ec2476006e1
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 3GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
      framework: TensorRT-LLM
      displayName: Llama 3.2 1B Instruct H100_NVLx2 BF16 Latency
      ngcMetadata:
        ee50ced41e24f36d4ad7c0bb3504688562be53a94b7f76fa99a867ff8b5d06ca:
          model: meta/llama-3.2-1b-instruct
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 77f4dfe035e443e59bbaf204c6e17b9c52cb16cbb638e426a5eedb0a8b6b2177
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  - variantId: Llama 3.2 3B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_2-3b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-throughput-fp8-jtgu5wt2yg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX4090x1 FP8 Throughput
      ngcMetadata:
        08cb5b3735b6331f07212bd488639ad1a049dbcf3e96375acbbb83ca861f9ec9:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX4090
            gpu_device: 2684:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX4090
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2684:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 4GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h20x1-throughput-bf16-hnixelsq-q
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H20x1 BF16 Throughput
      ngcMetadata:
        1cdb4d3f28059cb1aacb005776112ce4f7060a20d25d072932ce60bbe993fabc:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H20
            gpu_device: 2329:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H20
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2329:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:a100x2-latency-bf16-dbue0mkzcw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A100x2 BF16 Latency
      ngcMetadata:
        2146fcf18ea0412d564c6ed21d2f727281b95361fd78ccfa3d0570ec1716e8db:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:a100x1-throughput-bf16-lblsxfeipq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A100x1 BF16 Throughput
      ngcMetadata:
        222d1729a785201e8a021b226d74d227d01418c41b556283ee1bdbf0a818bd94:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100_NVLx1 BF16 Throughput
      ngcMetadata:
        25b5e251d366671a4011eaada9872ad1d02b48acc33aa0637853a3e3c3caa516:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A100_SXM4_40GBx2 BF16 Latency
      ngcMetadata:
        30316e5488489e3c0c2b0e7eee9e4bf5e82655b2a31b66d2e2c5dfa2b4e99bb2:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-latency-fp8-cq5x62ffbg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX4090x1 FP8 Latency
      ngcMetadata:
        33ca5a99fa9b89117df4b610b3f37fdf3462bc2e84a5b96bcf7685e5d839f7f5:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX4090
            gpu_device: 2684:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX4090
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2684:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h20x2-latency-bf16-u-xo-smuuq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H20x2 BF16 Latency
      ngcMetadata:
        362bd1de84adb8cc5be888391810dd9cc02ce3f25ad0b70fd500be54f93b9d4c:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H20
            gpu_device: 2329:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H20
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2329:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h200x1-throughput-bf16-frc0n1b7nw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H200x1 BF16 Throughput
      ngcMetadata:
        434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:b200x2-latency-fp8-04qswl5yla
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct B200x2 FP8 Latency
      ngcMetadata:
        4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 BF16 Latency
      ngcMetadata:
        566962048d4b01afd12f466ae697cf071eed5a46be33d66f3733e978ce99d1e7:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100_NVLx1 FP8 Throughput
      ngcMetadata:
        5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h200x2-latency-bf16--b69z90dgg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H200x2 BF16 Latency
      ngcMetadata:
        6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h100x2-latency-fp8-r2-4vhtqrq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100x2 FP8 Latency
      ngcMetadata:
        6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:a10gx1-throughput-bf16-r9bno-v4fw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A10Gx1 BF16 Throughput
      ngcMetadata:
        74bfd8b2df5eafe452a9887637eef4820779fb4e1edb72a4a7a2a1a2d1e6480b:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h100x1-throughput-fp8-kc5b4ag-cg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100x1 FP8 Throughput
      ngcMetadata:
        7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h20x2-latency-fp8-icgplntjww
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H20x2 FP8 Latency
      ngcMetadata:
        7fba1c034f3ace0a31d7cc345ec44482735555168c62c332bb38121c26345bbd:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H20
            gpu_device: 2329:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H20
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2329:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 FP8 Throughput
      ngcMetadata:
        8620431f3069e2f17f1cf712639ba06d67290d74c4c2e9a0d6e606952de91a88:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h20x1-throughput-fp8-bmppgnfoeq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H20x1 FP8 Throughput
      ngcMetadata:
        86be215b815363c818c00883dd403bd1f4ce5c610037637529a2a7e039973de6:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H20
            gpu_device: 2329:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H20
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2329:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:b200x1-throughput-fp8-pysymm95jq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        8b87146e39b0305ae1d73bc053564d1b4b4c565f81aa5abe3e84385544ca9b60:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l20x1-throughput-bf16-rpqq5ggd-q
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L20x1 BF16 Throughput
      ngcMetadata:
        91c52b108cd75967df6ed98f3d1d73a34cb0899d625f6f86499089f545ebe458:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L20
            gpu_device: 26ba:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L20
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26BA:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100_NVLx2 FP8 Latency
      ngcMetadata:
        a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 FP8 Latency
      ngcMetadata:
        a1ebfd69da7c3b97aa566387a4f086e563ff848cc5bab442147badc55f63364a:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:b200x1-throughput-bf16-iwdccsjltw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct B200x1 BF16 Throughput
      ngcMetadata:
        a4c63a91bccf635b570ddb6d14eeb6e7d0acb2389712892b08d21fad2ceaee38:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 BF16 Throughput
      ngcMetadata:
        a7b900f860f8770ecf1a982e79395659729010beeec832b522d96e8243b2439a:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l40sx1-throughput-bf16-i09pxvzjbg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L40Sx1 BF16 Throughput
      ngcMetadata:
        ac5071bbd91efcc71dc486fcd5210779570868b3b8328b4abf7a408a58b5e57c:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l40sx1-throughput-fp8-jnzgjqaxuw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L40Sx1 FP8 Throughput
      ngcMetadata:
        ad17776f4619854fccd50354f31132a558a1ca619930698fd184d6ccf5fe3c99:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h200x1-throughput-fp8-r0-6osqtng
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        af876a179190d1832143f8b4f4a71f640f3df07b0503259cedee3e3a8363aa96:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h100x2-latency-bf16-0i4agi9azq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100x2 BF16 Latency
      ngcMetadata:
        b3d535c0a7eaaea089b087ae645417c0b32fd01e7e9d638217cc032e51e74fd0:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100_NVLx2 BF16 Latency
      ngcMetadata:
        b7fad3b35b07d623fac6549078305b71d0e6e1d228a86fa0f7cfe4dbeca9151a:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l20x2-latency-bf16-acj72sjf5a
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L20x2 BF16 Latency
      ngcMetadata:
        c1c471464263781f56805d7768a50f70c830dbc68d795d641bd5bef18455b6f4:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L20
            gpu_device: 26ba:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L20
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26BA:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l40sx2-latency-fp8-44i4vvrorq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L40Sx2 FP8 Latency
      ngcMetadata:
        c4ff823a8202af4b523274fb8c6cdd73fa8ee5af16391a6d36b17f714a3c71a0:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l20x2-latency-fp8-f2nzfrgyia
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L20x2 FP8 Latency
      ngcMetadata:
        c610b690036f0e8ac96ea3ed1e584ef5c4f8a4cf1253664b8dc08df5b404de48:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L20
            gpu_device: 26ba:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L20
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26BA:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A100_SXM4_40GBx1 BF16 Throughput
      ngcMetadata:
        c6821c013c559912c37e61d7b954c5ca8fe07dda76d8bea0f4a52320e0a54427:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-throughput-bf16-8m--uis3tg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX4090x1 BF16 Throughput
      ngcMetadata:
        c78670b98ba7d5bc4105cbf723eb1cb514e3cb159dacd3d8b997b20c9ceeb1ea:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX4090
            gpu_device: 2684:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX4090
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2684:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l20x1-throughput-fp8-fqsk6q2inq
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L20x1 FP8 Throughput
      ngcMetadata:
        d2f14fb35f10d3ffef37a9f198d3c39f37a1452f65a1b523ec0135868fb23ba7:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L20
            gpu_device: 26ba:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L20
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26BA:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h200x2-latency-fp8-zzxu8dlxcw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H200x2 FP8 Latency
      ngcMetadata:
        e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 5GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:h100x1-throughput-bf16--lfg89p-ew
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct H100x1 BF16 Throughput
      ngcMetadata:
        e7dbd9a8ce6270d2ec649a0fecbcae9b5336566113525f20aee3809ba5e63856:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:a10gx2-latency-bf16-0ksvrbt0ww
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct A10Gx2 BF16 Latency
      ngcMetadata:
        ee94491ed7167340de93fe9d1c87f10ba424da6f497eeabf83b4edcbeb69364c:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:b200x2-latency-bf16-f-dquqynva
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct B200x2 BF16 Latency
      ngcMetadata:
        f44768c625db71a327cf17e750d5e1a8e60171a8d8ef6b4c1c4b57fe74c9bf46:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        f49b49f3d90159a594def51efd8595f1d618e288bca2721fe08e786a1ac67d04:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-latency-bf16-b25uxqlekg
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct RTX4090x1 BF16 Latency
      ngcMetadata:
        f5e266ce2a4692b37b80e0cb6ab2dea59a54d26b80396f1a521921384bd79ffe:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: RTX4090
            gpu_device: 2684:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX4090
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2684:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 7GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct GH200_480GBx1 BF16 Throughput
      ngcMetadata:
        f7f74ecd523cd63065a50016a8786a893b9b1efe0d313bc5bcc54682f56e55fe:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 12GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.2-3b-instruct:l40sx2-latency-bf16-pb6dhqvrgw
      framework: TensorRT-LLM
      displayName: Llama 3.2 3B Instruct L40Sx2 BF16 Latency
      ngcMetadata:
        fa36c3502e92c50f78a1906242f929864955e702b7dbfbdb19758fb7ee9aa811:
          model: meta/llama-3.2-3b-instruct
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Llama
  - Meta
  - Multilingual Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License

