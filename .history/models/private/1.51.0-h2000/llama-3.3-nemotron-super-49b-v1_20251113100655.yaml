models:
- name: Llama 3.3 Nemotron Super 49B
  displayName: Llama 3.3 Nemotron Super 49B
  modelHubID: llama-3.3-nemotron-super-49b
  category: Chatbots
  type: NGC
  description: Llama-3.3-Nemotron-Super-49B v1 and v1.5 are language models that can follow instructions, complete requests, and generate creative text formats. The Llama-3.3-Nemotron-Super-49B v1 series of Large Language Models (LLMs) are instruction-tuned versions of the Llama-Nemotron.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
  - label: License Agreement
    url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
  - variantId: Llama 3.3 Nemotron Super 49B V1
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.3-nemotron-super-49b-v1
    optimizationProfiles:
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:a100x2-throughput-bf16-ozhgcnodhw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 A100x2 BF16 Throughput
      ngcMetadata:
        0db3b5e8468c9debf30bcf41cbfea084adc59000885efd6fdcb3bbb902651bd6:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x2-throughput-bf16-aie7yrqp4q
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100x2 BF16 Throughput
      ngcMetadata:
        1617d074ce252f66e96d5f0e331fa5c6cc0a0330519e56b5c66c60eb7d7bf4f9:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-throughput-fp8-hq3hflct5a
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 FP8 Throughput
      ngcMetadata:
        26bd84b107a99415b474267bec4cbcf932fbb28e45d7fb4e4db2971506825888:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx4 BF16 Latency
      ngcMetadata:
        28552abdb2c491d46065d52ca1dc1265b99ba95a5bf8daaee4c5de12511a3b4f:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x1-throughput-bf16-2mmw837ykw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H200x1 BF16 Throughput
      ngcMetadata:
        434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 94GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-latency-fp8-1m3h4ytjug
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 FP8 Latency
      ngcMetadata:
        4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx1 FP8 Throughput
      ngcMetadata:
        5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-latency-bf16-19zfbhbq3g
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 BF16 Latency
      ngcMetadata:
        6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 A100_SXM4_40GBx4 BF16 Throughput
      ngcMetadata:
        6c29727e6e3d48a900c348c1fab181dc40bc926be07b06ca5b8eae42a6bc9901:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x2-latency-fp8-3wbe0ygpmg
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100x2 FP8 Latency
      ngcMetadata:
        6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x4-latency-bf16-9sreahcbuq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100x4 BF16 Latency
      ngcMetadata:
        73f41fabbb60beb5b05ab21c8dcce5c277d99bcabec31abf46a0194d0dd18d04:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x1-throughput-fp8-mhpv-tjmtq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100x1 FP8 Throughput
      ngcMetadata:
        7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 A100_SXM4_40GBx8 BF16 Latency
      ngcMetadata:
        8a446393aaeb0065ee584748c7c03522389921a11ff2bd8cb5800e06a8644eb0:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx2 FP8 Latency
      ngcMetadata:
        a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x1-throughput-bf16-e8quw21o2g
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 B200x1 BF16 Throughput
      ngcMetadata:
        a4c63a91bccf635b570ddb6d14eeb6e7d0acb2389712892b08d21fad2ceaee38:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx2 BF16 Throughput
      ngcMetadata:
        acd73fcee9d91ada305118080138fb3ca4d255adee3312acda38c4487daae476:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:l40sx4-latency-fp8-dm0yeik1qq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 L40Sx4 FP8 Latency
      ngcMetadata:
        bdd0d3cd53fad1130259beea81ab5711fb98f2f1a020b5b26c3c82fd7d43c5af:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 50GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-throughput-fp8-pn0bsx2fww
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 FP8 Throughput
      ngcMetadata:
        c91a755246cb08dd9aa6905bc40b7db552071d141a850be5a791b06eb4fb2ef8:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:a100x4-latency-bf16-htlclkizog
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 A100x4 BF16 Latency
      ngcMetadata:
        d73b7cf2f719d720329fc65fc255ae901bc3beebdc59be9815ede1a07948c1f7:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-latency-fp8-v0ho-fvz0g
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 FP8 Latency
      ngcMetadata:
        e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-latency-bf16-moifcs7ehq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 BF16 Latency
      ngcMetadata:
        f44768c625db71a327cf17e750d5e1a8e60171a8d8ef6b4c1c4b57fe74c9bf46:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx8 BF16
      ngcMetadata:
        1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '8'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 8
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
      - key: TRTLLM BUILDABLE
        value: 'TRUE'
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx2 BF16
      ngcMetadata:
        375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '2'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 2
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
      - key: TRTLLM BUILDABLE
        value: 'TRUE'
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx4 BF16
      ngcMetadata:
        54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
          model: nvidia/llama-3.3-nemotron-super-49b-v1
          release: 1.10.1
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '4'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 4
      - key: NIM VERSION
        value: 1.10.1
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
      - key: TRTLLM BUILDABLE
        value: 'TRUE'
  - variantId: Llama 3.3 Nemotron Super 49B V1.5
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.3-nemotron-super-49b-v1.5
    optimizationProfiles:
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a100x2-throughput-bf16-wcsztflslq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A100x2 BF16 Throughput
      ngcMetadata:
        03fdf4e63960724f08647e43122aab89748cf69f8e180c64fab6370abee11c41:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ae4d6417367534d6b999876248c3591165a546df619a27fe6460b92aa44e7f88
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx4 BF16 Latency
      ngcMetadata:
        0634edcf356b10f286d7a9ff5b5a0798a2616208e5c3b891aed4394fc504b0a1:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4e1be52ab36b863d4abb3e4e549f1f8150d8fe59bf3021012b9eddbb124bf1a8
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-nvfp4-yqo6gpzgtw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 NVFP4 Throughput
      ngcMetadata:
        097e7abb70716b35f220ddfa9f1beafc1872b83d2faae76087c5981875c172d7:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e1bde03fd878742322841e5871f1182069b936b6c4517c9b2d07c94d8c7e8ebf
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-throughput-bf16-lb51ks7uxa
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 BF16 Throughput
      ngcMetadata:
        0d0c380f456551cf0c7d94cba5df94a6679bf13bfcec35518dd4700277c45d6d:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 303af23d9df7615161cd22feb968e97571f32f341e3567ec57a5405fc513e452
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x2-latency-bf16-srzmz11lsq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x2 BF16 Latency
      ngcMetadata:
        0de4288607eed4d3b8fc4437cc7b7660d927d0ba9265f95f4c49191a69701446:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f96591a267ca466ff8d50fe13273091238ce4066f7da0533206572ac09da1eff
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-latency-fp8-csbsvltszw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 FP8 Latency
      ngcMetadata:
        1080a2945bccdf2773330d1ff5041b953088cb90e76c0a29ccddde3edb10fa48:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 76c65c985bc5acb124613d1c2854d8ca1908efc80cb6bdda6ebecf814f6f9932
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 50GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x2-latency-fp8-sowqqe--5a
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x2 FP8 Latency
      ngcMetadata:
        1f01cd4066c857f8982fcd8f7e7d7e4920c1e77ef50c8e0e9451815ec3d6590c:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6418fea1651154d4141be9df22ee889d55ee1e07eb23327386cfd21ed7e48917
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a10gx8-throughput-bf16-4fcffqprja
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A10Gx8 BF16 Throughput
      ngcMetadata:
        282c3be83f0772b985e007af291125cc8ecd4befc2833a96feefecfe49a6a116:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d50bef030c2c86675a058f6a7b4132438d8558afead641fa45c70cb431631be3
            number_of_gpus: '8'
            pp: '2'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-nvfp4-3sifj870lq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 NVFP4 Latency
      ngcMetadata:
        2a721971fe1905d88e8281b2804ffd900bbd20704482e07eb1dee03ca7ee1f26:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 21113f03af084c245046a894ef0cce875ebb362781b1e2d70774b919dfc08b7b
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A100_SXM4_40GBx4 BF16 Throughput
      ngcMetadata:
        2da0154c6a5ddf2d67aae37fd8a276f7fb54d69ebf9c2fe631c9cb9721912c10:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a5b791bd084d0d196d8eab3a5ee30584c4b5154b68e27d4ae27240c572aaa0c3
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx1 FP8 Throughput
      ngcMetadata:
        317edefe0e4f3253972892af7f1f8bb0787c39eaac22e54947bbd21c64c105de:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 93ae1647a06301ebae5535fc2a127f5149c5ffe3f63f99443eac45c342b36bf9
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx1 FP8 Throughput
      ngcMetadata:
        37aa8cad01613034db7185edd866ca513104bf5b87447a9ea373ddc475141a38:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7640e168db96daafc2278c529e4ea7e93a9751774a361437b064f6542fa8400a
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-bf16-b7mc0n5vsq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 BF16 Throughput
      ngcMetadata:
        3a1966db19d49667baa129a4838553168a4c66202dae42b3da82d34e0254dda9:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 56e98fd149cfe53aa5e62c155e6903b2254d7084850bfb5ea65bcd05e9fb416c
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 94GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
      ngcMetadata:
        3e02aabd0df7fb43fd55db667ddc61b9c1c6b2962aa3f2bfd0aa8d2206aa5ccd:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b22fdd19cd522ea34c068f776b07b38474bd419dd4bed6cb6ba3cb56376437fa
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x2-throughput-bf16-sfp5psfsoa
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x2 BF16 Throughput
      ngcMetadata:
        3f000887cbabfb954b87cbdafed85aeec51c82e5c941801c67a0fbb6bdbfbed5:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 037bea81c2da8987458de8a0e326c12c574c09048e1d80a027a73b6f6b553e06
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx1 FP8 Throughput
      ngcMetadata:
        4138603595d590ef014e6b18a034c8d6b6f7addc09e83ce2f97fe3d6b5502658:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3557dd611c5250fc7498c009ad75ec1ffdd75dd591e69de8efdfd0ad379871b5
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx1 BF16 Throughput
      ngcMetadata:
        439a0279d35d96d6b3c8be1f22f92a94d7e874e2476a58dc868b600861c84428:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ab0c91b93211e813ba1ef7fc61abd40d74c1babafe9d323e3dcddc74008f4cf3
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx1 NVFP4 Throughput
      ngcMetadata:
        496a3bcf32f7c7e81e59b1c17395d49b6c412dcb9e94d1bd4675c7ab61ed4b8c:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c93c0eb2422047add4d8c0141d90bab8840448b965f75976ac669b97d7934cca
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx2 BF16 Throughput
      ngcMetadata:
        4eb1789fe7a9ba85b6915c1f6ab6423be03ad2b7660fd17ccadfca11a9cea20e:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 61175440372bb9eb41cd7d5f3de3cb8aa05ab8ab84483ab3bb2580cdf9edb50f
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a100x4-latency-bf16-qfav5fnhta
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A100x4 BF16 Latency
      ngcMetadata:
        4ecfbc0680c47e40c54811d7d056bd8c2cb17410671da1d5a9d94f37e0e9ddd9:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4b36e4728a079ec71833e5b851ba55816893bae8c6b3e028c7092783d51380b6
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-fp8-hh-qiitbsq
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 FP8 Latency
      ngcMetadata:
        5104fad3c90f0e82d48218e2f295ecc76413a75f7828902f6201cdce8e11f119:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: eb379d36e7d269b0f9dedded8c2295fe06009c4792c2faebeee87520382b4a79
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x4-latency-bf16-gwrdidufkg
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x4 BF16 Latency
      ngcMetadata:
        5375ff8c01b5f03cc5226403b75091b280f9ab3b4901e4ddf08effd37f3be185:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 66667c721d5d8a4380827673282e501ca94da891407d35e1c4212606fc217cd4
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 NVFP4 Latency
      ngcMetadata:
        556dcaf16db7138e6cadd8e2a194caed98ad4d5be6c5d2f2638b4517f6d8a2f2:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7f399c329c773521d095cda5f5da78429a9a12497dc5e0a107b30250e7af3c9e
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx2 FP8 Latency
      ngcMetadata:
        557fec5cda76abb3bda2a196e908b91a4f97b18c0bab1fbc1e32927e131722f0:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0eb8ad98ede42e79a11f7439000dbc224363a640c2c03a7c0415d9d84852109c
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-bf16-ypw69-37kw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 BF16 Throughput
      ngcMetadata:
        5c181a5c2c72785a8c062e4f8b197d404caa754117731b76dfc612c4751392a8:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f9bff6c55a835edfed0cf54e1d92d121be400ddbe8bca9a14cae0406b129a700
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 94GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 FP8 Latency
      ngcMetadata:
        610f006b15f3adbdb072da0b4155d8a772332cf1768fb7389ef92a83c31c26dc:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c791be936f92f5cb480fbae429dff3fac2d0e7f1a3d3396e78196029b9a0d395
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        67fefe5a60111523b327e93282aabb0bee010780482d12aed22032fae947e6db:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f677672ff3da6e403ae52655aa3a37c53289547b58bc22c64c39364d755ac363
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-bf16-ql0dncdzug
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 BF16 Latency
      ngcMetadata:
        6988d6b50d4c8c0d12579128b9ceb6dfd239d91ecc1b0dcaf6b2d5235a785f41:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3ba2484ae0c038d20cd5f4add3a088742233193c5f9c7d16c55384ddd5ad1f78
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 96GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-fp8-eqspsgvc4g
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 FP8 Throughput
      ngcMetadata:
        721782adb8e04decd419a5d5fd5138ea578840ce23ae878cd66b5ade58b64860:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6dd43f5bf34d55e342b12dceabe739dc65b70b1c652b32e33158dda0176938b6
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-nvfp4-lzk6scakha
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 NVFP4 Throughput
      ngcMetadata:
        878da3cd983e1c204b447eaf6c2b1fbe15df8e3f8606dba0276dc5db6f1b2ea3:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ed7366f0b3c56148342e9281e92f74ebd0117e45028b50f4b5080474ca08579f
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-latency-bf16-fcnx7qsagw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 BF16 Latency
      ngcMetadata:
        8b3a0a14508070667a00aa2bec26a373d078db79903603585127a2a33a437dcd:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3eebbad6ddd7f86f084cafbaa2774c9b68814be840c5117b1e8f42bd4609a154
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx2 BF16 Latency
      ngcMetadata:
        901ae99dec61c02334df6c00217c665e620b03efaccd7ecbfedee9dd5b919e2c:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0f967f12c738cdeba2e1f6f507f6519b0e70fe691a3d85cc6f275bfa6cebaab0
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x4-latency-bf16-c7ags8vtqa
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x4 BF16 Latency
      ngcMetadata:
        a14acaea6216232b3dd9ff678dd04b239a48f8ef7eec367c8ba121aa93bc3699:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 79c4e912efae2b6e2670be80c6b16cf7d5a8d41658e3bdf6f0d7b72dc5d58634
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x1-throughput-fp8-tnrs6lwhqg
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x1 FP8 Throughput
      ngcMetadata:
        a55bb618b06a37fd61e99000a8ba38375801c0879c67a7a1b5a66cd497e09817:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c8b0bc8703bb921bcde98b731a73ba8a5223b4cc331b1f6ec52c97c0fb7eb334
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx2 FP8 Latency
      ngcMetadata:
        a5b40bd2025de323418db8d8577d91ad1c4c1b2143219fd9661c679e317af0fe:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 77041070f5f0dbe334cd51ed68930e5768eb93f59aff9f374f380e732fb3b078
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-fp8-ueeogrvolw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 FP8 Throughput
      ngcMetadata:
        b29ee8752b78d7d6a588e68487d9dd9f8ceaa2a01964f09c49ae9d7512a0e425:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0c5dc1a2f374f41aba6887d42b8f2497e43e32931426f33220897c481b121300
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx1 BF16 Throughput
      ngcMetadata:
        b3c7e84a0d005d532b307e36b9956be0b169a791283fd5362fa7326c1d442516:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 74e8a2780520f4deb4b75fe91dfb53dc33ab212294b755cb654dfcfbd720bea0
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x2-latency-fp8-kwktcc65kw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x2 FP8 Latency
      ngcMetadata:
        b9cd24c06efe599256f1cbc69e32686bf837e634d6d72754124a3d2db6a69415:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 91ac13ed5c5bcacd46af55350326af80781385cbf9ee70b426583319f1972bcb
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx2 FP8 Latency
      ngcMetadata:
        bee87c5b924821f18e4f18f9b63509e00d105053e9c0ed00440235219cc4c355:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4c34e6ff5408a3c795f72d84ad93d221975854695c77a2c49a03c94e288ebd7e
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx4 BF16 Latency
      ngcMetadata:
        cdc6d143f3c8ae40bef086616fe918badef8b5d8c2f7ed7bf35c46efc664f1d2:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7acb071a5e1043fb94515e5b7a4209955aa7b1a7f9311e43a96d525f36124582
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A100_SXM4_40GBx8 BF16 Latency
      ngcMetadata:
        d1a6703d5e49f81f492115bcd2fbb3d8f654fb74c7871374a0aba53e268f7eb7:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a491d0c85fd9304f23dc12098011ac5a7f06323c7f1bf5a03930512eab8bc661
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 BF16 Throughput
      ngcMetadata:
        d74a0a1011908274b71ca777cadb98fb50eb4d1b03f293c4961dfffd685fa77c:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a43faa67d15febf569c0cc2520243017faa2f85e955b0da68f0819b562b0f746
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-throughput-fp8-grh3fk4vxa
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 FP8 Throughput
      ngcMetadata:
        dd6e06ce56d8c23034792ecfafa9cad84e89381646f1a6b3f61e64d5c7151cca:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c218e34971f85acf3ff928121f744f142c144926bface213142ca6abe6d08527
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 50GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x2-latency-fp8-qionglmjjw
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x2 FP8 Latency
      ngcMetadata:
        e76d9a6e681f5047d58bb835cd1144df8a4c07cbd5e11340d9e841a34639c6ac:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7fd4e15ecac33d4ebf1f8b32433b45177d6701b159d35a262c363fd67aab00ca
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx2 BF16 Latency
      ngcMetadata:
        ecad5bd2fe50b96e275be4aede45e63ccacb4943719a70a76183ac78cb7b2602:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0863fbe7a8909618c897d216a1a1df5e66eb44030a0421496f854e0bc52bb041
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x1-throughput-bf16-jvvivxsong
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x1 BF16 Throughput
      ngcMetadata:
        ee058f1abbfe0cc174b16c966b91cfe886c7bb247fc691d8c7c8fee3dc9c8f41:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 493e3f3ab5031da3fd826eb8ef23ea20e87af83cae500214e295fbeca9003e55
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 94GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a10gx8-latency-bf16-ejd7ve2qag
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 A10Gx8 BF16 Latency
      ngcMetadata:
        ef9c1ac2f14b38895123c608a25f0104c42557f617c91e8ef6e151bc601822de:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7c853ac2150b03fff0d81df21fed77d789c5254f9f440e32844c93d073f5e43f
            number_of_gpus: '8'
            pp: '2'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 100GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x1-throughput-fp8-zmf7sc5wtg
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x1 FP8 Throughput
      ngcMetadata:
        f5e04275ea0d3bd001a2262e85e47de206406d9593d74525074a25475dc47a22:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e96f0bba12e9e5e054f193562c51161b61804d52ba2bff7a49bf8aa267a1c2b2
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 49GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
      framework: TensorRT-LLM
      displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        f97be1c404cf80299a3d85359c32a28710a3251c6ed6eec2dd3f3bdce2ca2903:
          model: nvidia/llama-3.3-nemotron-super-49b-v1.5
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 911352dda31a6b8811db6e5dc7c573094dadfc2354bee8cd0f41e784e79fc6f6
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 93GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Llama
  - Chatbots
  - Virtual Assistants
  - Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
