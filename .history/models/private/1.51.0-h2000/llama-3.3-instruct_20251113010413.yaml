models:
- name: Llama 3.3 70B Instruct
  displayName: Llama 3.3 70B Instruct
  modelHubID: llama-3.3-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.3 70B-Instruct NIM simplifies the deployment of the Llama 3.3 70B instruction tuned model which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://www.llama.com/llama3_3/use-policy/
  - label: License Agreement
    url: https://www.llama.com/llama3_3/license/
  modelVariants:
  - variantId: Llama 3.3 70B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x1-throughput-fp8-r-6bjqwx5a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        02f132ac03fb2ab51b82d88abce83b64feb565c93ad1d54f3b2ab04b7c86b21f:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 70c427b55c83a3c54340d828ce94b546ad566be2ec930f0bd760a00927b4b180
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x1-throughput-nvfp4-1bf1rojpxw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x1 NVFP4 Throughput
      ngcMetadata:
        09fcf7a392fe17c95e87d390742222a4a904b540f79f7b3b3d414bf3a092660b:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 33af5b8bea236de1a255b3108bcbb55e0dad3135b676d809d8ce339956cf67d4
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x2-throughput-bf16-5hyfmddv4a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x2 BF16 Throughput
      ngcMetadata:
        12c295e09aa3a3bac95522db7c0af51e27d6a4283b0402298c98691fc121a8ae:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 517f622a203fd1bdf58c0ba179d9be37fa1917c1f49e0a5aa85c7f5d3b8731b3
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 135GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x2-throughput-bf16-neynbhcsra
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x2 BF16 Throughput
      ngcMetadata:
        12f9ae91afef2d29f5ef4c312f0922ac8ed5aa877c8c49416b0dfaf9dcb902e0:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: fda9c04c123bfcdfae4f8f81847d3aee5eb51698a39dd5905d6581d780b90209
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x4-latency-bf16-h4d-jgziqw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x4 BF16 Latency
      ngcMetadata:
        135406168c0a2540196ed6f8003e35f8326cda374c6beb6f92b8b6f4883fbf0d:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 76e7be2bffcb7a930d207aa6f616ba863f1884672c64680ec0fca11bfc88304b
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-latency-bf16-of3qbtqvsg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Latency
      ngcMetadata:
        168f348ad80045c0a730210c796a66ccf83768df25543f8b0567c1e186be9ad6:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 00a7b1bb5360bc13540061f29a07344a7aa2feefc46f7f7ff355131ba9d4690d
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200_NVLx2 BF16 Throughput
      ngcMetadata:
        195071914f36a70a2b4306853667c37e6dd145c4ed787d099a0be9e75d84c58d:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 651dca39d0943930cc8b7bc0b5cd116294a25601c9f43deab2e362e3c96fde11
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100_SXM4_40GBx8 BF16 Throughput
      ngcMetadata:
        230323019f91e55e7e5ef0f472984bfe38672edc42d5d8f301887842e303e866:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 165e61398618addb727e82b8809cea1215b044020a8568597a31d7bee23b05e8
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx2 BF16 Throughput
      ngcMetadata:
        252cb13923588a782037650b182dcc87562a58a6a1dc48a31519f9964dee57bd:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: adda34b085d63494164d063e4a82677e59bcde4543da432d4a550a84185434e0
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-latency-fp8-n6ww5ulixq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x2 FP8 Latency
      ngcMetadata:
        2d46c8f638e9000b9892b517219356e3b980aabd33f027e7c858386688febd52:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 00103c1174a5863d30a1429e5aba6b251aa676ec57460280f28c6cb61f117d98
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_144GBx2 BF16 Throughput
      ngcMetadata:
        30809103f16d80f0f834cfec8d3a48617ac311a1e13150534e01d1c34b0a5db7:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 70078c4e36e97245d7fe026a7cac6258820c5d8df77bf2d10432c6a35007e7e2
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-latency-bf16-cp-xxbkpta
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x4 BF16 Latency
      ngcMetadata:
        41bc6ff1de6d3dcfe33b8070b32a89946b55b5770c92c82ffb8bb87b8e3fc9d7:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7c9d81be68e9ba750798e8c48585ebbce4d271d36981e30f09019e011d8e389a
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x8-latency-bf16-qfohcfr1iq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x8 BF16 Latency
      ngcMetadata:
        443b4edfa5128abcbc85f57ca43e02053730a3fc22929e4b7864422cf5b12d16:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d8669419688b2ce0f64218aeaa11f4840e272e2d1f5d11fc5e0d1b3f53476e2d
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 147GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_144GBx2 FP8 Latency
      ngcMetadata:
        44edc112b59ec6736bc9fc172d7219b9999f4398e5b61a7ca692a2053e1f4fc0:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d6f8ec1ae3a5910ae26ff689e3416a0947cf1c1c1bcc7dfc8d3186e490bcb36c
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_144GBx2 FP8 Throughput
      ngcMetadata:
        4a4dc27109678a256cf4ae5209280f044a6562ade8c2e5bca3025a096a41c551:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e075a3b9652dae46b800108afda2a6f7c0f6301a35a1db3671dc8af30f1fd5a2
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-throughput-nvfp4-ujocyfzf6a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x1 NVFP4 Throughput
      ngcMetadata:
        4bf0e1bc784ba2c8b1ae399bb1042d1546bac30df98d02663d4e1db60744aabc:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: cf417dfa6ac83cc20cfb5404ec0b2eae321d174bc4808d6007df8562ffee63d8
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-fp8-vl02sw2m-g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Latency
      ngcMetadata:
        52050fe50397b0b158fafe24a0c1e74efad0d04351274757337c86fc99968dd9:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a9d77447899d9eb9de5254bf262250c7321a6522f30d485abd4072fc1de36dcc
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        5b6330f563a4c3f73c9b02dc126295dd85d954c0623581981d1c6179155d9f7b:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0f31befe5670c8fd4ae2429ceaa76edcfcbcdfb96db0375e2671df999e4038c7
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_480GBx1 FP8 Latency
      ngcMetadata:
        5e578516ea42fae60c4f314736e8d3e506c497894e059a6af96bd4c2c84edf23:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 68e492b05ff7304cf14489a9a313eb7049ab552fb27b106d1dc61af71a5b7c29
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-throughput-bf16-rl2yes9ktw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Throughput
      ngcMetadata:
        613255b124f05cbf875c142c5ea7c2e3ebb7754a8a5473ad828d2bb07e2eaa88:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c0f0a6abdd6734299ec6f65611fa66490fd46303035100f9c865dd5d3c1dfb19
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-throughput-bf16-lciwvjwxkw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 BF16 Throughput
      ngcMetadata:
        64878d614ca9a859228cd55d140af0865823c2f3524e43c7be53c01c039481b6:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 824477061f9c69bd79fd248a136a273e8d861d092fb853ede5e06e12510d8188
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx8 BF16 Latency
      ngcMetadata:
        706687e8d19dccfb16a39808c18e54b9e55f7a5d6c2384df2c805453445ee4bb:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 095fa13f893ed4235a19615963e6b18bdb3e599ad5631c493007ae59dfe73f46
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x4-throughput-bf16-lyvveim8va
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x4 BF16 Throughput
      ngcMetadata:
        76e28450af746bb7626af7e5e2db4b57b56f11f5b6632a120eefabba925c2b15:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f14e1bad1a0e78da150aeedfee7919ab3ef21def09825caffef460b93fdde9b7
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-bf16-rhzeshgk8w
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Throughput
      ngcMetadata:
        7cb838de5dad2c42066f0616756d0ad2708939c450b95416d41098e9931470c1:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c419c6ba54c118a6deb6ed9918e9c72e7f151698116c1d3c2bc32042a94d6bbb
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-bf16-m9pz-s1ymq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 BF16 Throughput
      ngcMetadata:
        7ed84ed093e8c5e8d237966262d640c6c2f160a8606df22e869e6f7a5a83cc96:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 5006533ca6b5151e94f18d8e518c68965918f248d0680b23e9fc0e4553e0d9ef
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-fp8-wbna-gqhxw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 FP8 Throughput
      ngcMetadata:
        7f4107d806d19c2c2beb2e870bf01217de37a247f27ee168985fc42a9576c641:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0013e870ea929584ec13dad6948450024cdc6c2f03a865f1b050fb08b9f64312
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100_SXM4_40GBx8 BF16 Latency
      ngcMetadata:
        814d03ce098b7de458602c7bce320c3d06fe898759577c849a34193653a70bbb:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7a207406eaa12a8bb549ea578116338e4e204d3b38ed0ffb6a9d9d789f2cd994
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200_NVLx1 FP8 Throughput
      ngcMetadata:
        829d3e1c28ffd52afed2d35e9374cfc7b605eda5a630bc9b33fbea5500da8fb3:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 34a1cf18c4d7501df008280668fe6df7de1f91ff29daee8d5c80291dd6e51b0e
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-latency-nvfp4-prgjwnsudw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x2 NVFP4 Latency
      ngcMetadata:
        8abcb1c5fc3e57d712a311f08f9b33b59b383196b95f7d7f66c758de85d56567:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 807294ccda05820ac7bbb9cf0471df7494e947226acff080c0782bda0c7d4394
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-latency-fp8-ozazyo6fjw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 FP8 Latency
      ngcMetadata:
        92e9707e66c742310e9a7a6d38e162b2578375c8fe0844939c499a00116a994e:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 138ef4644a3d6477c3deaf2cd22f548d3396925db62f4752fb73b52b7b8a4a29
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-latency-nvfp4-gbqmrrkwrw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x1 NVFP4 Latency
      ngcMetadata:
        a1366af9ab8c32f147d10d0fcc2a43d55b20f2c79178b4a291caa5dec55f966c:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 19ca51edfcfaecd4c68b0950ff57be89e59def4ad003dbcfae4352b43d152223
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-latency-fp8-mg52y2fpwq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Latency
      ngcMetadata:
        a2003c7b2b19b79aefb52cd9daa58fb20f0520dd9759037ff34e67110f384218:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8a5f27c50cf45f7d1a1e504bcd33820eefa80539b94a68bbf015c3f4f4cb2c3f
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 BF16 Throughput
      ngcMetadata:
        a403f6513a44565063a70541681355465810849c0f537c825cd6575c960c2c14:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4896c9f159be7403ca983e4da47959b87841d5fe0034304ab473baf61f3132a1
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-latency-fp8-uepcd7pd4a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x1 FP8 Latency
      ngcMetadata:
        a425a0f4eef147092d6d41acbd7c9c3408614205b8135699274b02f2363b707c:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0cedb0518e3995aa41d37920a83b151ad05bdf2a43beedbff21b709cf696e350
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_144GBx2 BF16 Latency
      ngcMetadata:
        a6f328cf048298b737a05799b74a3f81b4a215f125d71088054c6c32f3446801:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7e9757ebb03d4334fd350490505620d2af6b5329aa8a28df931e0a22e46d55cd
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx2 FP8 Throughput
      ngcMetadata:
        a9f34dd0f8e4fd295b0d04067aa0ecce24aa3707b26305e9ab084d430546975c:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 77ab630b949b0a58ad580a22ea055bc392a30fbf57357d6398814e00775aab8c
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-throughput-fp8-ybdaheki0g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x1 FP8 Throughput
      ngcMetadata:
        af09a13bcaa3650952df251a0dfd03dabaf7700a6d00b6f2264b2c9ef757fbb6:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b6dc07bb5bf5be874355bbe6288ca066c605a43c23d6c537ac9d4929c22d2cdd
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        c7fc979432a42458118ab456c33302cbde984c5d8a0035e9d2c1d07b5f3dc0d9:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 1dea2d2f10ec64c74ca127f73b52bf5253dfdc91c5cd5da07cb742e166e8a795
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-fp8-sx6as-ue-a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Throughput
      ngcMetadata:
        cf120c3ecf2025e6a170cb224802ca6a02cbeec3ad74944a69263b3193a64fa2:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b118ae4fb04a6bbcf439004b94edd4815d2c965a0c692c2b98a790580c9c3f7b
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200_NVLx2 FP8 Latency
      ngcMetadata:
        cf5787bfa25e0f21603c8aa6458d2ae062691d0fa81e684dc219082ba39fb1d9:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 552ad035a0898be37be03c9d539efbda5a7d2f214b2c5950e14bb694ad8329a9
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
      ngcMetadata:
        d650534ce98fea4bfc9924d77c91fbd8dca227321c35557e924297ab6b9008cb:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 19aeb73125023f25e273ed14ccc69b935b2ce5131d4d91d1b78f3e8bdc0366b7
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:gb200x4-latency-bf16-vuvdg5jkzq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct GB200x4 BF16 Latency
      ngcMetadata:
        d7ff5f88620f7fbe0538931af334663b43d15cb2c969e7fc96375ac60108906f:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: be07050242f7ce67689c0d81de40bb1de6967dd251a881bcb784193fb92d8183
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-throughput-bf16-omzr8lu67g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x2 BF16 Throughput
      ngcMetadata:
        e0ac049ec460cc8dfe59feaec6d12ae55807dac2b0bd62396c36679f2674e330:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6d1452af26f860b53df112c90f6b92f22a41156c09dafa2582c2c1194e56a673
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx2 FP8 Throughput
      ngcMetadata:
        e518c22e6d4135300fc5c10bd0c4d195c51ac596e8950172e303bcce84794732:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3035d73242fb579040fb3f341adc36a7073f780419e73dd97edb7ce35cb0f550
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-bf16-rasfmhw4uw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Latency
      ngcMetadata:
        e6d1855d3f24e439b904cf1fd47d3e136bec4af9134c039558c61f9ae34593af:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8747b7e093d3b26e808e8bbebdb50c3ac0a0f82402c58b3430a8760ff96e406e
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 FP8 Latency
      ngcMetadata:
        ee0b992fafa65ffe00e8df84f80f9e417a400ec40b60b6769db81498482610d7:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3140e28251686b824ea3fd4d45a86cef01b156d1737ada0b6783b612ac3b6e92
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx4 BF16 Latency
      ngcMetadata:
        efcb2762954af78c9b84774917daf706fd8d663df3d54c298a1fb9d2fb86a119:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3d2f50e0423aa98250617f6a0dad719bed6892994a47c60e092ce494d93e9bce
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x1-throughput-fp8-xk4doibibg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        f215c1f1608a7818f6c465646f8f8cb412a58b39c99e4a15857466fb9a970aef:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6979353282e6f8421f9ffd76c33eb1e675f796fc7ed036c6038b99a21d649f18
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 NVFP4 Latency
      ngcMetadata:
        f9c5befd972751383a8dfa7b38fb77fd4c69af4e015136f0a194b7db0176ce59:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4f697999cecdc5afc7ff8f588b71a5b7683117aa866f34ab76886db2dbe86dcc
            number_of_gpus: '4'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-bf16-bpwvcpvnsq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 BF16 Throughput
      ngcMetadata:
        fbec99d055ebc70d1261d9520f1f6f854fb0a84771bdadde30668dca1f081c7d:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2eb1d578e4e069c384bf617e5354889d043a1c72b77f432c07e06ffb1b8be36b
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx4 FP8 Latency
      ngcMetadata:
        ff1a26a9837e3e3122a70f91d46181b15f22ba8276c47b0d852cabde8a6a5460:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9b6105c7bf6521bd8eb6fa1badcd239636f35c06317166bf78d58a8cc239411f
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Llama
  - Meta
  - Chat
  - Text Generation
  - Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
