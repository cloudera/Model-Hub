1392d41fe716b7d44e12c77c1df58b8fbdf71c27264e0745926afe3c573b57d8:
  container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
  model: mistralai/mixtral-8x22b-instruct-v0.1
  release: 1.2.2
  tags:
    feat_lora: false
    gpu: H100
    gpu_device: 2330:10de
    llm_engine: tensorrt_llm
    pp: '1'
    precision: int8wo
    profile: latency
    tp: '8'
  workspace: !workspace
    components:
      - dst: ''
        src:
          files:
            - !name 'README.md'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'generation_config.json'
            - !name 'model.safetensors.index.json'
            - !name 'special_tokens_map.json'
            - !name 'tokenizer.json'
            - !name 'tokenizer.model'
            - !name 'tokenizer_config.json'
            - !name 'tool_use_config.json'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
      - dst: trtllm_engine
        src:
          files:
            - !name 'LICENSE.txt'
            - !name 'NOTICE.txt'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'metadata.json'
            - !name 'rank0.engine'
            - !name 'rank1.engine'
            - !name 'rank2.engine'
            - !name 'rank3.engine'
            - !name 'rank4.engine'
            - !name 'rank5.engine'
            - !name 'rank6.engine'
            - !name 'rank7.engine'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-h100x8-int8wo-latency.1.1.2.17607510
28a820fc752f0964280f0e4eba7e0490b95b790b5e3c4fff218ef9d2b12b9f76:
  container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
  model: mistralai/mixtral-8x22b-instruct-v0.1
  release: 1.2.2
  tags:
    feat_lora: false
    gpu: A100
    gpu_device: 20b2:10de
    llm_engine: tensorrt_llm
    pp: '1'
    precision: fp16
    profile: throughput
    tp: '8'
  workspace: !workspace
    components:
      - dst: ''
        src:
          files:
            - !name 'README.md'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'generation_config.json'
            - !name 'model.safetensors.index.json'
            - !name 'special_tokens_map.json'
            - !name 'tokenizer.json'
            - !name 'tokenizer.model'
            - !name 'tokenizer_config.json'
            - !name 'tool_use_config.json'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
      - dst: trtllm_engine
        src:
          files:
            - !name 'LICENSE.txt'
            - !name 'NOTICE.txt'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'metadata.json'
            - !name 'rank0.engine'
            - !name 'rank1.engine'
            - !name 'rank2.engine'
            - !name 'rank3.engine'
            - !name 'rank4.engine'
            - !name 'rank5.engine'
            - !name 'rank6.engine'
            - !name 'rank7.engine'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-a100x8-fp16-throughput.1.1.2.17541679
930ce298c4d2076077f7bd113d908aa9dac4d4b1e0b9f43c3418a84265c4990f:
  container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
  model: mistralai/mixtral-8x22b-instruct-v0.1
  release: 1.2.2
  tags:
    feat_lora: false
    gpu: H100
    gpu_device: 2330:10de
    llm_engine: tensorrt_llm
    pp: '1'
    precision: int8wo
    profile: throughput
    tp: '4'
  workspace: !workspace
    components:
      - dst: ''
        src:
          files:
            - !name 'README.md'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'generation_config.json'
            - !name 'model.safetensors.index.json'
            - !name 'special_tokens_map.json'
            - !name 'tokenizer.json'
            - !name 'tokenizer.model'
            - !name 'tokenizer_config.json'
            - !name 'tool_use_config.json'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
      - dst: trtllm_engine
        src:
          files:
            - !name 'LICENSE.txt'
            - !name 'NOTICE.txt'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'metadata.json'
            - !name 'rank0.engine'
            - !name 'rank1.engine'
            - !name 'rank2.engine'
            - !name 'rank3.engine'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-h100x4-int8wo-throughput.1.1.2.17572569
d792c5a5d326e82a1c06c6ee1b7180d26be6dcb3d5123c9104d768e0e2b3822d:
  container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
  model: mistralai/mixtral-8x22b-instruct-v0.1
  release: 1.2.2
  tags:
    feat_lora: 'false'
    llm_engine: vllm
    precision: bf16
    tp: '8'
  workspace: !workspace
    components:
      - dst: ''
        src:
          files:
            - !name 'README.md'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'generation_config.json'
            - !name 'model-00001-of-00059.safetensors'
            - !name 'model-00002-of-00059.safetensors'
            - !name 'model-00003-of-00059.safetensors'
            - !name 'model-00004-of-00059.safetensors'
            - !name 'model-00005-of-00059.safetensors'
            - !name 'model-00006-of-00059.safetensors'
            - !name 'model-00007-of-00059.safetensors'
            - !name 'model-00008-of-00059.safetensors'
            - !name 'model-00009-of-00059.safetensors'
            - !name 'model-00010-of-00059.safetensors'
            - !name 'model-00011-of-00059.safetensors'
            - !name 'model-00012-of-00059.safetensors'
            - !name 'model-00013-of-00059.safetensors'
            - !name 'model-00014-of-00059.safetensors'
            - !name 'model-00015-of-00059.safetensors'
            - !name 'model-00016-of-00059.safetensors'
            - !name 'model-00017-of-00059.safetensors'
            - !name 'model-00018-of-00059.safetensors'
            - !name 'model-00019-of-00059.safetensors'
            - !name 'model-00020-of-00059.safetensors'
            - !name 'model-00021-of-00059.safetensors'
            - !name 'model-00022-of-00059.safetensors'
            - !name 'model-00023-of-00059.safetensors'
            - !name 'model-00024-of-00059.safetensors'
            - !name 'model-00025-of-00059.safetensors'
            - !name 'model-00026-of-00059.safetensors'
            - !name 'model-00027-of-00059.safetensors'
            - !name 'model-00028-of-00059.safetensors'
            - !name 'model-00029-of-00059.safetensors'
            - !name 'model-00030-of-00059.safetensors'
            - !name 'model-00031-of-00059.safetensors'
            - !name 'model-00032-of-00059.safetensors'
            - !name 'model-00033-of-00059.safetensors'
            - !name 'model-00034-of-00059.safetensors'
            - !name 'model-00035-of-00059.safetensors'
            - !name 'model-00036-of-00059.safetensors'
            - !name 'model-00037-of-00059.safetensors'
            - !name 'model-00038-of-00059.safetensors'
            - !name 'model-00039-of-00059.safetensors'
            - !name 'model-00040-of-00059.safetensors'
            - !name 'model-00041-of-00059.safetensors'
            - !name 'model-00042-of-00059.safetensors'
            - !name 'model-00043-of-00059.safetensors'
            - !name 'model-00044-of-00059.safetensors'
            - !name 'model-00045-of-00059.safetensors'
            - !name 'model-00046-of-00059.safetensors'
            - !name 'model-00047-of-00059.safetensors'
            - !name 'model-00048-of-00059.safetensors'
            - !name 'model-00049-of-00059.safetensors'
            - !name 'model-00050-of-00059.safetensors'
            - !name 'model-00051-of-00059.safetensors'
            - !name 'model-00052-of-00059.safetensors'
            - !name 'model-00053-of-00059.safetensors'
            - !name 'model-00054-of-00059.safetensors'
            - !name 'model-00055-of-00059.safetensors'
            - !name 'model-00056-of-00059.safetensors'
            - !name 'model-00057-of-00059.safetensors'
            - !name 'model-00058-of-00059.safetensors'
            - !name 'model-00059-of-00059.safetensors'
            - !name 'model.safetensors.index.json'
            - !name 'special_tokens_map.json'
            - !name 'tokenizer.json'
            - !name 'tokenizer.model'
            - !name 'tokenizer_config.json'
            - !name 'tool_use_config.json'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
e44c755ef6628cccb74ccf58af4a6efa039f7e49e07a9dd7a27eb17f6500964e:
  container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
  model: mistralai/mixtral-8x22b-instruct-v0.1
  release: 1.2.2
  tags:
    feat_lora: false
    gpu: H100
    gpu_device: 2330:10de
    llm_engine: tensorrt_llm
    pp: '1'
    precision: fp16
    profile: throughput
    tp: '8'
  workspace: !workspace
    components:
      - dst: ''
        src:
          files:
            - !name 'README.md'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'generation_config.json'
            - !name 'model.safetensors.index.json'
            - !name 'special_tokens_map.json'
            - !name 'tokenizer.json'
            - !name 'tokenizer.model'
            - !name 'tokenizer_config.json'
            - !name 'tool_use_config.json'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
      - dst: trtllm_engine
        src:
          files:
            - !name 'LICENSE.txt'
            - !name 'NOTICE.txt'
            - !name 'checksums.blake3'
            - !name 'config.json'
            - !name 'metadata.json'
            - !name 'rank0.engine'
            - !name 'rank1.engine'
            - !name 'rank2.engine'
            - !name 'rank3.engine'
            - !name 'rank4.engine'
            - !name 'rank5.engine'
            - !name 'rank6.engine'
            - !name 'rank7.engine'
          repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-h100x8-fp16-throughput.1.1.2.17572569
