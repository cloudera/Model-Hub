models:
- name: Llama 3.2 Vision Instruct
  displayName: Llama 3.2 Vision Instruct
  modelHubID: llama-3.2-vision-instruct
  category: Image to Text Generation
  type: NGC
  description: The Llama 3.2 Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.2 11B  Vision Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.2-11b-vision-instruct
      optimizationProfiles:
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-bf16-latency.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct H100 BF16 Latency
          sha: 126d5a664ba4b6b4557d5e0225b51a5e2ffbf9e9909bfe25ed203bec421ea2e5
          ngcMetadata:
            126d5a664ba4b6b4557d5e0225b51a5e2ffbf9e9909bfe25ed203bec421ea2e5:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-bf16-latency.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx4-bf16-throughput.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct A10G BF16 Throughput
          sha: 417611b3f9e2c25db671083acfcfd4c2340f511f3533838fc6366bb47960915c
          ngcMetadata:
            417611b3f9e2c25db671083acfcfd4c2340f511f3533838fc6366bb47960915c:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx4-bf16-throughput.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx8-bf16-latency.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct A10G BF16 Latency
          sha: 5a9f2d4459908cf6c5b5222e31b8df053c00354b5866f6ee3b8de7552a695524
          ngcMetadata:
            5a9f2d4459908cf6c5b5222e31b8df053c00354b5866f6ee3b8de7552a695524:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'trtllm_engine/rank4.engine'
                        - !name 'trtllm_engine/rank5.engine'
                        - !name 'trtllm_engine/rank6.engine'
                        - !name 'trtllm_engine/rank7.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx8-bf16-latency.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-latency.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct H100 FP8 Latency
          sha: ab89f816413848c86e311123d2ed98af7bcda0c3624b0a6c4d43704b720585d5
          ngcMetadata:
            ab89f816413848c86e311123d2ed98af7bcda0c3624b0a6c4d43704b720585d5:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-latency.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 12GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x2-bf16-latency.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct A100 BF16 Latency
          sha: ad16e693a234cf8eee85c43dd66ab4502c51ab0bc553af1644477a4f966bf5c6
          ngcMetadata:
            ad16e693a234cf8eee85c43dd66ab4502c51ab0bc553af1644477a4f966bf5c6:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x2-bf16-latency.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx2-bf16-throughput.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct L40S BF16 Throughput
          sha: b16d5969212a8cea632fd6f70928ab514aab835cf217281899564933e6cafa5b
          ngcMetadata:
            b16d5969212a8cea632fd6f70928ab514aab835cf217281899564933e6cafa5b:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx2-bf16-throughput.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-bf16-throughput.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct H100 BF16 Throughput
          sha: b7aa6bf9d9946de665480a5669bb73f981eab7c4fe43ddf7217b672eb11a003a
          ngcMetadata:
            b7aa6bf9d9946de665480a5669bb73f981eab7c4fe43ddf7217b672eb11a003a:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-bf16-throughput.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx4-bf16-latency.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct L40S BF16 Latency
          sha: be5af3c968ce6bc45e740edc985fa05dffd3695abb7cc5723407e1f5e3f12c70
          ngcMetadata:
            be5af3c968ce6bc45e740edc985fa05dffd3695abb7cc5723407e1f5e3f12c70:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx4-bf16-latency.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x1-bf16-throughput.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct A100 BF16 Throughput
          sha: ee1e936b878082dee74574deae5064cc7fba3e11ba155de1198ee544d7c3468a
          ngcMetadata:
            ee1e936b878082dee74574deae5064cc7fba3e11ba155de1198ee544d7c3468a:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x1-bf16-throughput.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 20GB
        - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-fp8-throughput.0.3.20143152
          framework: TensorRT-LLM
          displayName: Llama 3.2 11B Vision Instruct H100 FP8 Throughput
          sha: fa1e1cbf698be85c0cc56d707f8bc5b17044e091136dae3f8e4be694af727c87
          ngcMetadata:
            fa1e1cbf698be85c0cc56d707f8bc5b17044e091136dae3f8e4be694af727c87:
              model: meta/llama-3.2-11b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-fp8-throughput.0.3.20143152
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 12GB
    - variantId: Llama 3.2 90B  Vision Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.2-90b-vision-instruct
      optimizationProfiles:
        - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-bf16-throughput.0.3.20194742
          framework: TensorRT-LLM
          displayName: Llama 3.2 90B Vision Instruct H100 BF16 Throughput
          sha: 42c91902414bc5ea7f4ef4e9a34ef382165b8b65f9adcc5d1abaf195ade2d8fc
          ngcMetadata:
            42c91902414bc5ea7f4ef4e9a34ef382165b8b65f9adcc5d1abaf195ade2d8fc:
              model: meta/llama-3.2-90b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-bf16-throughput.0.3.20194742
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 166GB
        - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-throughput.0.3.20194742
          framework: TensorRT-LLM
          displayName: Llama 3.2 90B Vision Instruct H100 FP8 Throughput
          sha: 6b24bf2e19c23b85f9d2651efdc2de08cd179a03c50f942b1dcd856fa4d4074b
          ngcMetadata:
            6b24bf2e19c23b85f9d2651efdc2de08cd179a03c50f942b1dcd856fa4d4074b:
              model: meta/llama-3.2-90b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-throughput.0.3.20194742
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 85GB
        - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx8-bf16-throughput.0.3.1342
          framework: TensorRT-LLM
          displayName: Llama 3.2 90B Vision Instruct L40S BF16 Throughput
          sha: 7bb72cbd19b5eab69ed21b2e031e4ea18909ff034255471c25b29ab45a99cc8b
          ngcMetadata:
            7bb72cbd19b5eab69ed21b2e031e4ea18909ff034255471c25b29ab45a99cc8b:
              model: meta/llama-3.2-90b-vision-instruct
              release: 1.1.1
              tags:
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'trtllm_engine/rank4.engine'
                        - !name 'trtllm_engine/rank5.engine'
                        - !name 'trtllm_engine/rank6.engine'
                        - !name 'trtllm_engine/rank7.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx8-bf16-throughput.0.3.1342
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 166GB
        - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-fp8-latency.0.3.20194742
          framework: TensorRT-LLM
          displayName: Llama 3.2 90B Vision Instruct H100 FP8 Latency
          sha: a6e9fde5c1edfb4ab4c0b206a536693a6f9b1f95cde1448ddd679fb880fcef71
          ngcMetadata:
            a6e9fde5c1edfb4ab4c0b206a536693a6f9b1f95cde1448ddd679fb880fcef71:
              model: meta/llama-3.2-90b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-fp8-latency.0.3.20194742
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: null
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 87GB
        - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x8-bf16-latency.0.3.20194742
          framework: TensorRT-LLM
          displayName: Llama 3.2 90B Vision Instruct H100 BF16 Latency
          sha: e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83
          ngcMetadata:
            e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83:
              model: meta/llama-3.2-90b-vision-instruct
              release: 1.1.1
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'trtllm_engine/config.json'
                        - !name 'trtllm_engine/metadata.json'
                        - !name 'trtllm_engine/rank0.engine'
                        - !name 'trtllm_engine/rank1.engine'
                        - !name 'trtllm_engine/rank2.engine'
                        - !name 'trtllm_engine/rank3.engine'
                        - !name 'trtllm_engine/rank4.engine'
                        - !name 'trtllm_engine/rank5.engine'
                        - !name 'trtllm_engine/rank6.engine'
                        - !name 'trtllm_engine/rank7.engine'
                        - !name 'visual_engine/config.json'
                        - !name 'visual_engine/metadata.json'
                        - !name 'visual_engine/visual_encoder.engine'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x8-bf16-latency.0.3.20194742
                  - dst: ''
                    src:
                      files:
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'preprocessor_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
                  - dst: ''
                    src:
                      files:
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
                  - dst: visual_engine
                    src:
                      files:
                        - !name 'vision_processor.py'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
                  - dst: ''
                    src:
                      files:
                        - !name 'runtime_params.json'
                      repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.1
            - key: DOWNLOAD SIZE
              value: 166GB
  labels:
    - Llama
    - Meta
    - Chat
    - Large Language Model
    - TensorRT-LLM
    - Vision Instruct
    - Image to Text Generation
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.1 Instruct
  displayName: Llama 3.1 Instruct
  modelHubID: llama-3.1-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.1 70B-Instruct, 8B instruct and 8B base NIM simplifies the deployment of the Llama 3.1 70B-Instruct, 8B instruct and 8B base tuned models which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.1 70B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-70b-instruct-nemo
      optimizationProfiles:
        - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x4-fp8-throughput.1.2.18099809
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100 FP8 Throughput
          sha: 4e0aeeefd4dfeae46ad40f16238bbde8858850ce0cf56c26449f447a02a9ac8f
          ngcMetadata:
            4e0aeeefd4dfeae46ad40f16238bbde8858850ce0cf56c26449f447a02a9ac8f:
              container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
              model: meta/llama-3.1-70b-instruct
              release: 1.2.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x4-fp8-throughput.1.2.18099809
          latestVersionSizeInBytes: 91738571464
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 91GB
        - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x8-fp8-latency.1.2.18099809
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100 FP8 Latency
          sha: 5296eed82c6309b64b13da03fbb843d99c3276effd6a0c51e28ad5bb29f56017
          ngcMetadata:
            5296eed82c6309b64b13da03fbb843d99c3276effd6a0c51e28ad5bb29f56017:
              container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
              model: meta/llama-3.1-70b-instruct
              release: 1.2.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x8-fp8-latency.1.2.18099809
          latestVersionSizeInBytes: 100947599129
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 101GB
        - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x8-bf16-latency.1.1.0.16791804
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100 BF16 Latency
          sha: 5d901178874ec94514eb470ba3a412ff5585ea691b63854653020ea46c838fda
          ngcMetadata:
            5d901178874ec94514eb470ba3a412ff5585ea691b63854653020ea46c838fda:
              container_url: nvcr.io/nim/meta/llama-3_1-70b-instruct:1.0.0
              model: meta/llama-3_1-70b-instruct
              model_type: text_generation
              release: 1.0.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'patch.diff'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-0722
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x8-bf16-latency.1.1.0.16791804
          latestVersionSizeInBytes: 157817895406
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 157GB
        - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x4-bf16-throughput.1.1.0.16791804
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100 BF16 Throughput
          sha: 95f75ec64117af224c819780667ab16b49e939493d59d1e885fd05eda7609dfd
          ngcMetadata:
            95f75ec64117af224c819780667ab16b49e939493d59d1e885fd05eda7609dfd:
              container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
              model: meta/llama-3.1-70b-instruct
              release: 1.2.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x4-bf16-throughput.1.1.0.16791804
          latestVersionSizeInBytes: 148355721341
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 148GB
        - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-l40sx8-bf16-throughput.1.1.0.4258
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct L40S BF16 Throughput
          sha: e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83
          ngcMetadata:
            998336d555bc28bc49069f2e989e4c2e0e2fac2914f2393941dba1e2e047f5c3:
              container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
              model: meta/llama-3.1-70b-instruct
              release: 1.2.0
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-l40sx8-bf16-throughput.1.1.0.4258
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 148GB
    - variantId: Llama 3.1 8B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-8b-instruct-nemo
      optimizationProfiles:
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-latency.1.1.0.16792222
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40S BF16 Latency
          sha: 0494aafce0df9eeaea49bbca6b25fc3013d0e8a752ebcf191a2ddeaab19481ee
          ngcMetadata:
            0494aafce0df9eeaea49bbca6b25fc3013d0e8a752ebcf191a2ddeaab19481ee:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-latency.1.1.0.16792222
          latestVersionSizeInBytes: 17375862511
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x2-fp8-latency.1.2.18099815
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100 FP8 Latency
          sha: 0bc4cc784e55d0a88277f5d1aeab9f6ecb756b9049dd07c1835035211fcfe77e
          ngcMetadata:
            0bc4cc784e55d0a88277f5d1aeab9f6ecb756b9049dd07c1835035211fcfe77e:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x2-fp8-latency.1.2.18099815
          latestVersionSizeInBytes: 11611592007
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 11GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x1-fp8-throughput.1.2.18099815
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100 FP8 Throughput
          sha: 2959f7f0dfeb14631352967402c282e904ff33e1d1fa015f603d9890cf92ca0f
          ngcMetadata:
            2959f7f0dfeb14631352967402c282e904ff33e1d1fa015f603d9890cf92ca0f:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x1-fp8-throughput.1.2.18099815
          latestVersionSizeInBytes: 10481822697
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 10GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x1-bf16-throughput.1.1.0.16803357
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100 BF16 Throughput
          sha: 7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8
          ngcMetadata:
            7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x1-bf16-throughput.1.1.0.16803357
          latestVersionSizeInBytes: 16218130050
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x2-bf16-latency.1.1.0.16792222
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100 BF16 Latency
          sha: 7f98797c334a8b7205d4cbf986558a2b8a181570b46abed9401f7da6d236955e
          ngcMetadata:
            7f98797c334a8b7205d4cbf986558a2b8a181570b46abed9401f7da6d236955e:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x2-bf16-latency.1.1.0.16792222
          latestVersionSizeInBytes: 17294212148
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x1-bf16-throughput.1.1.0.16792222
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100 BF16 Throughput
          sha: 9cff0915527166b2e93c08907afd4f74e168562992034a51db00df802e86518c
          ngcMetadata:
            9cff0915527166b2e93c08907afd4f74e168562992034a51db00df802e86518c:
              container_url: nvcr.io/nim/meta/llama-3_1-8b-instruct:1.0.0
              model: meta/llama-3_1-8b-instruct
              model_type: text_generation
              release: 1.0.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'patch.diff'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-0722
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x1-bf16-throughput.1.1.0.16792222
          latestVersionSizeInBytes: 16148612398
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-throughput.1.1.0.16792222
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40S BF16 Throughput
          sha: a534b0f5e885d747e819fa8b1ad7dc1396f935425a6e0539cb29b0e0ecf1e669
          ngcMetadata:
            a534b0f5e885d747e819fa8b1ad7dc1396f935425a6e0539cb29b0e0ecf1e669:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-throughput.1.1.0.16792222
          latestVersionSizeInBytes: 17366405962
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx2-bf16-throughput.1.1.0.17443761
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A10G BF16 Throughput
          sha: ba515cc44a34ae4db8fe375bd7e5ad30e9a760bd032230827d8a54835a69c409
          ngcMetadata:
            ba515cc44a34ae4db8fe375bd7e5ad30e9a760bd032230827d8a54835a69c409:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx2-bf16-throughput.1.1.0.17443761
          latestVersionSizeInBytes: 17408782025
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x2-bf16-latency.1.1.0.16803357
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100 BF16 Latency
          sha: d880feac6596cfd7a2db23a6bcbbc403673e57dec9b06b6a1add150a713f3fe1
          ngcMetadata:
            d880feac6596cfd7a2db23a6bcbbc403673e57dec9b06b6a1add150a713f3fe1:
              container_url: nvcr.io/nim/meta/llama-3_1-8b-instruct:1.0.0
              model: meta/llama-3_1-8b-instruct
              model_type: text_generation
              release: 1.0.0
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'patch.diff'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-0722
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x2-bf16-latency.1.1.0.16803357
          latestVersionSizeInBytes: 17483962992
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx4-bf16-latency.1.1.0.16813141
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A10G BF16 Latency
          sha: e45b4b991bbc51d0df3ce53e87060fc3a7f76555406ed534a8479c6faa706987
          ngcMetadata:
            e45b4b991bbc51d0df3ce53e87060fc3a7f76555406ed534a8479c6faa706987:
              container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
              model: meta/llama-3.1-8b-instruct
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx4-bf16-latency.1.1.0.16813141
          latestVersionSizeInBytes: 19771439964
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 19GB
  labels:
    - Llama
    - Meta
    - Chat
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Mistral Instruct
  displayName: Mistral Instruct
  modelHubID: mistral-instruct
  category: Text Generation
  type: NGC
  description: Mistral Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. The Mistral Instract Large Language Model (LLM) is an instruct fine-tuned version of the Mistral.
  modelVariants:
    - variantId: Mistral 7B Instruct
      displayName: Mistral 7B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mistral-7b-instruct-v0.3
      optimizationProfiles:
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x1-fp8-throughput.1.1.2.17547653
          displayName: Mistral 7B Instruct H100 FP8 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            08ab4363f225c19e3785b58408fa4dcac472459cca1febcfaffb43f873557e87:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x1-fp8-throughput.1.1.2.17547653
          sha: 08ab4363f225c19e3785b58408fa4dcac472459cca1febcfaffb43f873557e87
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7581039585
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 7GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x2-fp8-latency.1.1.2.17547653
          displayName: Mistral 7B Instruct H100 FP8 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            48004baf4f45ca177aa94abfd3c5c54858808ad728914b1626c3cf038ea85bc4:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x2-fp8-latency.1.1.2.17547653
          sha: 48004baf4f45ca177aa94abfd3c5c54858808ad728914b1626c3cf038ea85bc4
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7683289422
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 7GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx2-fp8-latency.1.1.2.17547653
          displayName: Mistral 7B Instruct L40S FP8 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            5c17c27186b232e834aee9c61d1f5db388874da40053d70b84fd1386421ff577:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx2-fp8-latency.1.1.2.17547653
          sha: 5c17c27186b232e834aee9c61d1f5db388874da40053d70b84fd1386421ff577
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7668082873
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 7GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x2-fp16-latency.1.1.2.17520508
          displayName: Mistral 7B Instruct H100 FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            6064ab4c33a1c6da8058422b8cb0347e72141d203c77ba309ce5c5533f548188:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x2-fp16-latency.1.1.2.17520508
          sha: 6064ab4c33a1c6da8058422b8cb0347e72141d203c77ba309ce5c5533f548188
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14843530523
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x1-fp16-throughput.1.1.2.17520508
          displayName: Mistral 7B Instruct H100 FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            8833b9eba1bd4fbed4f764e64797227adca32e3c1f630c2722a8a52fee2fd1fa:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-h100x1-fp16-throughput.1.1.2.17520508
          sha: 8833b9eba1bd4fbed4f764e64797227adca32e3c1f630c2722a8a52fee2fd1fa
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14534647998
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx1-fp16-throughput.1.1.2.17541679
          displayName: Mistral 7B Instruct L40S FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            95f764b13dca98173068ad7dd9184098e18a04ad803722540a911d35a599378a:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx1-fp16-throughput.1.1.2.17541679
          sha: 95f764b13dca98173068ad7dd9184098e18a04ad803722540a911d35a599378a
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14534535777
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a100x1-fp16-throughput.1.1.2.17541679
          displayName: Mistral 7B Instruct A100 FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            c79561a74f97b157de12066b7a137702a4b09f71f4273ff747efe060881fca92:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a100x1-fp16-throughput.1.1.2.17541679
          sha: c79561a74f97b157de12066b7a137702a4b09f71f4273ff747efe060881fca92
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14533870834
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx1-fp8-throughput.1.1.2.17547653
          displayName: Mistral 7B Instruct L40S FP8 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            cc18942f40e770aa27a0b02c1f5bf1458a6fedd10a1ed377630d30d71a1b36db:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx1-fp8-throughput.1.1.2.17547653
          sha: cc18942f40e770aa27a0b02c1f5bf1458a6fedd10a1ed377630d30d71a1b36db
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7582789228
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 7GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a100x2-fp16-latency.1.1.2.17541679
          displayName: Mistral 7B Instruct A100 FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            dea9af90d5311ff2d651db8c16f752d014053d3b1c550474cbeda241f81c96bd:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a100x2-fp16-latency.1.1.2.17541679
          sha: dea9af90d5311ff2d651db8c16f752d014053d3b1c550474cbeda241f81c96bd
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14841967999
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx2-fp16-latency.1.1.2.17541679
          displayName: Mistral 7B Instruct L40S FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            ef22c7cecbcf2c8b3889bd58a48095e47a8cc0394d221acda1b4087b46c6f3e9:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-l40sx2-fp16-latency.1.1.2.17541679
          sha: ef22c7cecbcf2c8b3889bd58a48095e47a8cc0394d221acda1b4087b46c6f3e9
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14843372758
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a10gx2-fp16-throughput.1.1.2.17520508
          displayName: Mistral 7B Instruct A10G FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            27ffe5614d9d5c8e727bf21b5e7c234086a32b4e9b3423a579f37cef3ad22fc1:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a10gx2-fp16-throughput.1.1.2.17520508
          sha: 27ffe5614d9d5c8e727bf21b5e7c234086a32b4e9b3423a579f37cef3ad22fc1
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
        - profileId: nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a10gx4-fp16-latency.1.1.2.17520508
          displayName: Mistral 7B Instruct A10G FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            900729568c898838585be8e57687f412900530152053c15c17f5085c35c4cb40:
              container_url: nvcr.io/nim/mistralai/mistral-7b-instruct-v03:1.1.2
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.1.2
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'params.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer.model.v3'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:hf-3990259-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mistral-7b-instruct-v03:0.11.1+14957bf8-a10gx4-fp16-latency.1.1.2.17520508
          sha: 900729568c898838585be8e57687f412900530152053c15c17f5085c35c4cb40
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.1.2
            - key: DOWNLOAD SIZE
              value: 14GB
  labels:
    - Mistral
    - Instruct
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: Mistral
  license: NVIDIA AI Foundation Models Community License
- name: Mixtral Instruct
  displayName: Mixtral Instruct
  modelHubID: mixtral-instruct
  category: Text Generation
  type: NGC
  description: The Mixtral Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts model. Mixtral Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. The Mixtral Instruct Large Language Model (LLM) is an instruct fine-tuned version of the Mixtral.
  modelVariants:
    - variantId: Mixtral 8x7B Instruct
      displayName: Mixtral 8x7B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mixtral-8x7b-instruct-v01
      optimizationProfiles:
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a10gx8-fp16-throughput.1.1.2.17537111
          displayName: Mixtral 8x7B Instruct A10G FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            03c5e4ff6a27a2df38cee91e3db5d63451429750086bfb861d1223d39869a931:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a10gx8-fp16-throughput.1.1.2.17537111
          sha: 03c5e4ff6a27a2df38cee91e3db5d63451429750086bfb861d1223d39869a931
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 89GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-fp8-throughput.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 FP8 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            00056b81c2e41eb9b847342ed553ae88614f450f3f15eebfd2ae56174484bacd:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-fp8-throughput.1.1.2.17538847
          sha: 00056b81c2e41eb9b847342ed553ae88614f450f3f15eebfd2ae56174484bacd
          modelFormat: trt-llm
          latestVersionSizeInBytes: 47143615504
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 47GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-int8wo-throughput.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 int8wo Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            01f1ad019f55abb76f10f1687f76ea8e5d2f3d51d6831ddc582d979ff210b4cb:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: int8wo
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-int8wo-throughput.1.1.2.17538847
          sha: 01f1ad019f55abb76f10f1687f76ea8e5d2f3d51d6831ddc582d979ff210b4cb
          modelFormat: trt-llm
          latestVersionSizeInBytes: 47352822039
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: int8wo
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 47GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-fp16-throughput.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            1f859af2be6c57528dc6d32b6062c9852605d8f2d68bbe76a43b65ebc5ac738d:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x2-fp16-throughput.1.1.2.17538847
          sha: 1f859af2be6c57528dc6d32b6062c9852605d8f2d68bbe76a43b65ebc5ac738d
          modelFormat: trt-llm
          latestVersionSizeInBytes: 93808041027
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 94GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a100x2-fp16-throughput.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct A100 FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            9865374899b6ac3a1e25e47644f3d66753288e9d949d883b14c3f55b98fb2ebc:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '2'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a100x2-fp16-throughput.1.1.2.17538847
          sha: 9865374899b6ac3a1e25e47644f3d66753288e9d949d883b14c3f55b98fb2ebc
          modelFormat: trt-llm
          latestVersionSizeInBytes: 93804315823
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 94GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-fp16-latency.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            9972482479f39ecacc3f470aaa7d0de7b982a1b18f907aafdb8517db5643e05a:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-fp16-latency.1.1.2.17538847
          sha: 9972482479f39ecacc3f470aaa7d0de7b982a1b18f907aafdb8517db5643e05a
          modelFormat: trt-llm
          latestVersionSizeInBytes: 94475885022
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 94GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-l40sx4-fp16-throughput.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct L40S FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            ad3c46c1c8d71bb481205732787f2c157a9cfc9b6babef5860518a047e155639:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-l40sx4-fp16-throughput.1.1.2.17538847
          sha: ad3c46c1c8d71bb481205732787f2c157a9cfc9b6babef5860518a047e155639
          modelFormat: trt-llm
          latestVersionSizeInBytes: 94453103580
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 94GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-fp8-latency.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 FP8 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            d37580fa5deabc5a4cb17a2337e8cc672b19eaf2791cf319fd16582065e40816:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-fp8-latency.1.1.2.17538847
          sha: d37580fa5deabc5a4cb17a2337e8cc672b19eaf2791cf319fd16582065e40816
          modelFormat: trt-llm
          latestVersionSizeInBytes: 47320446534
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 47GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a100x4-fp16-latency.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct A100 FP16 Latency
          framework: TensorRT-LLM
          ngcMetadata:
            e249e70e3ee390e606782eab19e7a9cf2aeb865bdbc638aaf0fc580901492841:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a100x4-fp16-latency.1.1.2.17538847
          sha: e249e70e3ee390e606782eab19e7a9cf2aeb865bdbc638aaf0fc580901492841
          modelFormat: trt-llm
          latestVersionSizeInBytes: 9094013963
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-int8wo-latency.1.1.2.17538847
          displayName: Mixtral 8x7B Instruct H100 int8wo Latency
          framework: TensorRT-LLM
          ngcMetadata:
            ee616a54bea8e869009748eefb0d905b168d2095d0cdf66d40f3a5612194d170:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: int8wo
                profile: latency
                tp: '4'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-h100x4-int8wo-latency.1.1.2.17538847
          sha: ee616a54bea8e869009748eefb0d905b168d2095d0cdf66d40f3a5612194d170
          modelFormat: trt-llm
          latestVersionSizeInBytes: 47992100010
          spec:
            - key: PROFILE
              value: Latency
            - key: PRECISION
              value: int8wo
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 47GB
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a10gx8-fp16-throughput.1.1.2.17537111
          displayName: Mixtral 8x7B Instruct A10G FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            03c5e4ff6a27a2df38cee91e3db5d63451429750086bfb861d1223d39869a931:
              container_url: nvcr.io/nim/mistralai/mixtral-8x7b-instruct-v01:1.2.1
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.2.1
              tags:
                feat_lora: false
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'NOTICE'
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-b
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x7b-instruct-v01:0.11.1+14957bf8-a10gx8-fp16-throughput.1.1.2.17537111
          sha: 03c5e4ff6a27a2df38cee91e3db5d63451429750086bfb861d1223d39869a931
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: fp16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10de
            - key: NIM VERSION
              value: 1.2.1
            - key: DOWNLOAD SIZE
              value: 89GB
    - variantId: Mixtral 8x22B Instruct
      displayName: Mixtral 8x22B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mixtral-8x22b-instruct-v01
      optimizationProfiles:
        - profileId: nim/mistralai/mixtral-8x22b-instruct-v01:0.10.1+79a76176-h100x8-int8wo-throughput.1.2.2.16140417
          displayName: Mixtral 8x22B Instruct H100 int8wo Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            4ad9a208ce0f8ec41cd6b8681cd0ddf6fbeb406efb3d9baf6847a3fb8bac5863:
              container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.0.0
              model: mistralai/mixtral-8x22b-instruct-v0.1
              model_type: text_generation
              release: 1.0.0
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: int8wo
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-52572b2
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                        - !name 'trt_llm_config.yaml'
                      repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.10.1+79a76176-h100x8-int8wo-throughput.1.0.0.16140417
          sha: 4ad9a208ce0f8ec41cd6b8681cd0ddf6fbeb406efb3d9baf6847a3fb8bac5863
          modelFormat: trt-llm
          latestVersionSizeInBytes: 144762798586
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: int8wo
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 144GB
        - profileId: nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-h100x8-fp16-throughput.1.1.2.17572569
          displayName: Mixtral 8x22B Instruct H100 FP16 Throughput
          framework: TensorRT-LLM
          ngcMetadata:
            e44c755ef6628cccb74ccf58af4a6efa039f7e49e07a9dd7a27eb17f6500964e:
              container_url: nvcr.io/nim/mistralai/mixtral-8x22b-instruct-v01:1.2.2
              model: mistralai/mixtral-8x22b-instruct-v0.1
              release: 1.2.2
              tags:
                feat_lora: false
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                precision: fp16
                profile: throughput
                tp: '8'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      files:
                        - !name 'README.md'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'generation_config.json'
                        - !name 'model.safetensors.index.json'
                        - !name 'special_tokens_map.json'
                        - !name 'tokenizer.json'
                        - !name 'tokenizer.model'
                        - !name 'tokenizer_config.json'
                        - !name 'tool_use_config.json'
                      repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:hf-1702b01-tool-calling
                  - dst: trtllm_engine
                    src:
                      files:
                        - !name 'LICENSE.txt'
                        - !name 'NOTICE.txt'
                        - !name 'checksums.blake3'
                        - !name 'config.json'
                        - !name 'metadata.json'
                        - !name 'rank0.engine'
                        - !name 'rank1.engine'
                        - !name 'rank2.engine'
                        - !name 'rank3.engine'
                        - !name 'rank4.engine'
                        - !name 'rank5.engine'
                        - !name 'rank6.engine'
                        - !name 'rank7.engine'
                      repo_id: ngc://nim/mistralai/mixtral-8x22b-instruct-v01:0.11.1+14957bf8-h100x8-fp16-throughput.1.1.2.17572569
          sha: e44c755ef6628cccb74ccf58af4a6efa039f7e49e07a9dd7a27eb17f6500964e
          modelFormat: trt-llm
          latestVersionSizeInBytes: 285170977174
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.2
            - key: DOWNLOAD SIZE
              value: 285GB
  labels:
    - Mistral
    - Instruct
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: mistral
  license: NVIDIA AI Foundation Models Community License
- name: E5 Embedding v5
  displayName: E5 Embedding v5
  modelHubID: e5-embedding-v5
  category: Embedding
  type: NGC
  description: NVIDIA NIM for GPU accelerated NVIDIA Retrieval QA E5 Embedding v5 inference
  modelVariants:
    - variantId: E5 Embedding
      displayName: E5 Embedding
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nv-embedqa-e5-v5
      optimizationProfiles:
        - profileId: nim/nvidia/nv-embedqa-e5-v5:5_FP16_onnx
          displayName: Embedding ONNX FP16
          framework: ONNX
          sha: onnx
          ngcMetadata:
            onnx:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-e5-v5
              model_type: embedding
              tags:
                llm_engine: onnx
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_tokenizer
                  - dst: onnx
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_FP16_onnx
          modelFormat: onnx
          latestVersionSizeInBytes: 668847682
          spec:
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-e5-v5:5_FP16_A10_24GB
          displayName: Embedding A10G FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A10G_10.0.1_12
          ngcMetadata:
            NVIDIA-A10G_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-e5-v5
              model_type: embedding
              tags:
                gpu: A10G
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_FP16_A10_24GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 672920180
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-e5-v5:5_FP16_A100_SXM4_80GB
          displayName: Embedding A100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A100_10.0.1_12
          ngcMetadata:
            NVIDIA-A100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-e5-v5
              model_type: embedding
              tags:
                gpu: A100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_FP16_A100_SXM4_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 672515204
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-e5-v5:5_FP16_H100_HBM3_80GB
          displayName: Embedding H100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12
          ngcMetadata:
            NVIDIA-H100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-e5-v5
              model_type: embedding
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-e5-v5:5_FP16_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 675755740
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
  labels:
    - Embedding
  config:
    architectures:
      - Other
    modelType: embedding
  license: NVIDIA AI Foundation Models Community License
- name: Mistral Embedding v2
  displayName: Mistral Embedding v2
  modelHubID: mistral-embedding-v2
  category: Embedding
  type: NGC
  description: NVIDIA NIM for GPU accelerated NVIDIA Retrieval QA Mistral 7B Embedding v2 inference
  modelVariants:
    - variantId: Mistral 7B Embedding
      displayName: Mistral 7B Embedding
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nv-embedqa-mistral-7b-v2
      optimizationProfiles:
        - profileId: nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_onnx
          displayName: Mistral 7B Embedding ONNX FP16
          framework: ONNX
          ngcMetadata:
            onnx:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-mistral-7b-v2
              model_type: embedding
              tags:
                llm_engine: onnx
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_tokenizer_512
                  - dst: onnx
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_onnx
          modelFormat: onnx
          latestVersionSizeInBytes: 14239651604
          spec:
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 4096
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_A100_SXM4_80GB
          displayName: Mistral 7B Embedding A100
          framework: TensorRT-LLM
          sha: NVIDIA-A100_10.0.1_12
          ngcMetadata:
            NVIDIA-A100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-mistral-7b-v2
              model_type: embedding
              tags:
                gpu: A100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_tokenizer_512
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_A100_SXM4_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14254672452
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 4096
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP8_H100_HBM3_80GB
          displayName: Mistral 7B Embedding H100 FP8
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12_FP8
          ngcMetadata:
            NVIDIA-H100_10.0.1_12_FP8:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-mistral-7b-v2
              model_type: embedding
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_tokenizer_512
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP8_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7271196548
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 4096
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_H100_HBM3_80GB
          displayName: Mistral 7B Embedding H100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12
          ngcMetadata:
            NVIDIA-H100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-embedqa-mistral-7b-v2
              model_type: embedding
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_tokenizer_512
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-embedqa-mistral-7b-v2:2_FP16_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 14266992708
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 4096
            - key: NIM VERSION
              value: 1.0.1
  labels:
    - Embedding
    - Mistral
  config:
    architectures:
      - Other
    modelType: embedding
  license: NVIDIA AI Foundation Models Community License
- name: Snowflake Arctic Embed Large Embedding
  displayName: Snowflake Arctic Embed Large Embedding
  modelHubID: snowflake-arctic-embed-large-embedding
  category: Embedding
  type: NGC
  description: NVIDIA NIM for GPU accelerated Snowflake Arctic Embed Large Embedding inference
  modelVariants:
    - variantId: Snowflake Arctic Embed
      displayName: Snowflake Arctic Embed
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/snowflake/containers/arctic-embed-l
      optimizationProfiles:
        - profileId: nim/snowflake/arctic-embed-l:2_FP16_onnx
          displayName: Arctic Embedding ONNX FP16
          framework: ONNX
          sha: onnx
          ngcMetadata:
            onnx:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: snowflake/arctic-embed-l
              model_type: embedding
              tags:
                llm_engine: onnx
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_tokenizer
                  - dst: onnx
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_FP16_onnx
          modelFormat: onnx
          latestVersionSizeInBytes: 668844074
          spec:
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/snowflake/arctic-embed-l:2_TRT_FP16_A10_24GB
          displayName: Arctic Embedding A10G FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A10G_10.0.1_12
          ngcMetadata:
            NVIDIA-A10G_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: snowflake/arctic-embed-l
              model_type: embedding
              tags:
                gpu: A10G
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_TRT_FP16_A10_24GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 672775036
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/snowflake/arctic-embed-l:2_TRT_FP16_A100_SXM4_80GB
          displayName: Arctic Embedding A100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A100_10.0.1_12
          ngcMetadata:
            NVIDIA-A100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: snowflake/arctic-embed-l
              model_type: embedding
              tags:
                gpu: A100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_TRT_FP16_A100_SXM4_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 672504692
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
        - profileId: nim/snowflake/arctic-embed-l:2_TRT_FP16_H100_HBM3_80GB
          displayName: Arctic Embedding H100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12
          ngcMetadata:
            NVIDIA-H100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: snowflake/arctic-embed-l
              model_type: embedding
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_tokenizer
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/snowflake/arctic-embed-l:2_TRT_FP16_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 675743684
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: MAX TOKENS
              value: 512
            - key: Dimension
              value: 1024
            - key: NIM VERSION
              value: 1.0.1
  labels:
    - Embedding
    - Arctic
    - Snowflake
  config:
    architectures:
      - Other
    modelType: embedding
  license: NVIDIA AI Foundation Models Community License
- name: Mistral Rerank v3
  displayName: Mistral Rerank v3
  modelHubID: mistral-rerank-v3
  category: Reranking
  type: NGC
  description: NVIDIA NIM for GPU accelerated NVIDIA Retrieval QA Mistral 4B Reranking v3 inference
  modelVariants:
    - variantId: Mistral 4B Reranking
      displayName: Mistral 4B Reranking
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nv-rerankqa-mistral-4b-v3
      optimizationProfiles:
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_onnx
          displayName: Mistral 4B Reranking ONNX FP16
          framework: ONNX
          sha: onnx
          ngcMetadata:
            onnx:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                llm_engine: onnx
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_onnx
          modelFormat: onnx
          latestVersionSizeInBytes: 7259396025
          spec:
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP8_L40s_48GB
          displayName: Mistral 4B Reranking L40S FP8
          framework: TensorRT-LLM
          sha: NVIDIA-L40S_10.0.1_12_FP8
          ngcMetadata:
            NVIDIA-L40S_10.0.1_12_FP8:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: L40S
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP8_L40s_48GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 3778195436
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP8
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_L40s_48GB
          displayName: Mistral 4B Reranking L40S FP16
          framework: TensorRT-LLM
          sha: NVIDIA-L40S_10.0.1_12
          ngcMetadata:
            NVIDIA-L40S_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: L40S
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_L40s_48GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7268026908
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP8_H100_HBM3_80GB
          displayName: Mistral 4B Reranking H100 FP8
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12_FP8
          ngcMetadata:
            NVIDIA-H100_10.0.1_12_FP8:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP8_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 3775478108
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP8
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_H100_HBM3_80GB
          displayName: Mistral 4B Reranking H100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-H100_10.0.1_12
          ngcMetadata:
            NVIDIA-H100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: H100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_H100_HBM3_80GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7272493940
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_A100_SXM4_40GB
          displayName: Mistral 4B Reranking A100 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A100_10.0.1_12
          ngcMetadata:
            NVIDIA-A100_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: A100
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_A100_SXM4_40GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7266402076
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_A10G_24GB
          displayName: Mistral 4B Reranking A10G FP16
          framework: TensorRT-LLM
          sha: NVIDIA-A10G_10.0.1_12
          ngcMetadata:
            NVIDIA-A10G_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: A10G
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_A10G_24GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7267924540
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
        - profileId: nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_L4_24GB
          displayName: Mistral 4B Reranking L4 FP16
          framework: TensorRT-LLM
          sha: NVIDIA-L4_10.0.1_12
          ngcMetadata:
            NVIDIA-L4_10.0.1_12:
              container_url: https://catalog.ngc.nvidia.com/containers
              model: nvidia/nv-rerankqa-mistral-4b-v3
              model_type: reranking
              tags:
                gpu: L4
                llm_engine: tensorrt_llm
                tp: '1'
              workspace: !workspace
                components:
                  - dst: ''
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_tokenizer_v3
                  - dst: trtllm_engine
                    src:
                      repo_id: ngc://nim/nvidia/nv-rerankqa-mistral-4b-v3:3_FP16_L4_24GB
          modelFormat: trt-llm
          latestVersionSizeInBytes: 7267891932
          spec:
            - key: GPU
              value: L4
            - key: COUNT
              value: 1
            - key: PRECISION
              value: FP16
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: NIM VERSION
              value: 1.0.2
  labels:
    - Reranking
    - Mistral
  config:
    architectures:
      - Other
    modelType: reranking
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.3 Instruct
  displayName: Llama 3.3 Instruct
  modelHubID: llama-3-3-instruct
  category: Text Generation
  type: HF
  description: Meta's Llama 3.3 is an instruction-tuned generative LLM optimized for multilingual dialogue use cases. It outperforms many available open-source and closed chat models on common industry benchmarks.
  modelVariants:
    - variantId: Llama 3.3 70B Instruct
      displayName: Llama 3.3 70B Instruct
      source:
        URL: https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct
      requireToken: true
      requireLicense: true
      licenseAgreements:
        - label: License Agreement
          url: https://www.llama.com/llama3_3/license/
      optimizationProfiles:
        - profileId: meta-llama/Llama-3.3-70B-Instruct
          displayName: Llama 3.3 70B Instruct A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: meta-llama/Llama-3.3-70B-Instruct
          displayName: Llama 3.3 70B Instruct L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 8
  labels:
    - "Llama"
    - "Code Generation"
    - "Meta"
  config:
    architectures:
      - LlamaForCausalLM
    modelType: llama
  license: llama3.3
- name: Google Flan T5
  displayName: Google Flan T5
  modelHubID: google-flan-t5
  category: Text to Text Generation
  type: HF
  description: Flan-T5 is an encoder-decoder model pre-trained on a variety of language tasks developed by Google Researchers. The model has been trained on supervised and unsupervised datasets with the goal of learning mappings between sequences of text, i.e., text-to-text.  The model has knowledge of performing specific tasks such as summarization, classification and translation.
  modelVariants:
    - variantId: Google Flan T5 Base
      displayName: Google Flan T5 Base
      source:
        URL: https://huggingface.co/google/flan-t5-base
      requireToken: false
      requireLicense: false
      optimizationProfiles:
        - profileId: google/flan-t5-base
          displayName: Google Flan T5 Base
          framework: huggingface
          sha: huggingface
          modelFormat: huggingface
          spec:
            - key: A10G
              value: 1
    - variantId: Google Flan T5 Large
      displayName: Google Flan T5 Large
      source:
        URL: https://huggingface.co/google/flan-t5-large
      requireToken: false
      requireLicense: false
      optimizationProfiles:
        - profileId: google/flan-t5-large
          displayName: Google Flan T5 Large
          framework: huggingface
          sha: huggingface
          modelFormat: huggingface
          spec:
            - key: A10G
              value: 1
    - variantId: Google Flan T5 XL
      displayName: Google Flan T5 XL
      source:
        URL: https://huggingface.co/google/flan-t5-xl
      requireToken: false
      requireLicense: false
      optimizationProfiles:
        - profileId: google/flan-t5-xl
          displayName: Google Flan T5 XL
          framework: huggingface
          sha: huggingface
          modelFormat: huggingface
          spec:
            - key: A10G
              value: 1
  labels:
    - T5
    - Google
    - Chat
    - "Text to Text"
    - "Language Conversion"
    - "Text Summarization"
  config:
    architectures:
      - T5ForConditionalGeneration
    modelType: T5
  license: Google AI License
- name: StarCoder
  displayName: StarCoder
  modelHubID: starCoder
  category: Text Generation
  type: HF
  description: The StarCoder models are 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2), with opt-out requests excluded. The model uses Multi Query Attention, a context window of 8192 tokens, and was trained using the Fill-in-the-Middle objective on 1 trillion tokens.
  modelVariants:
    - variantId: StarCoder
      displayName: StarCoder
      source:
        URL: https://huggingface.co/bigcode/starcoder
      requireToken: true
      requireLicense: true
      licenseAgreements:
        - label: License Agreement
          url: https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement
      optimizationProfiles:
        - profileId: bigcode/starcoder
          displayName: starcoder A10G
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
        - profileId: bigcode/starcoder
          displayName: starcoder A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: bigcode/starcoder
          displayName: starcoder L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
  labels:
    - bigCode
    - StarCoder
    - "Code Generation"
    - "Text Generation"
    - "Multilingual support"
  config:
    architectures:
      - GPTBigCodeForCausalLM
    modelType: GPTBigCode
  license: BigCode OpenRAIL-M v1
- name: Gemma 2
  displayName: Gemma 2
  modelHubID: gemma-2
  category: Text Generation
  type: HF
  description: Gemma 2 the second generation of the Google community Gemma lineage.  Gemma 2 is improved with higher performance with significant safety improvements and well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning.
  modelVariants:
    - variantId: Gemma 2 9B
      displayName: Gemma 2 9B
      source:
        URL: https://huggingface.co/google/gemma-2-9b
      requireToken: true
      requireLicense: true
      licenseAgreements:
        - label: License Agreement
          url: https://ai.google.dev/gemma/terms
        - label: Use Policy
          url: https://ai.google.dev/gemma/prohibited_use_policy
      optimizationProfiles:
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 9b A10G
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 9b A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 9b L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
  labels:
    - google
    - Gemma
    - "Text Generation"
    - "Multilingual support"
  config:
    architectures:
      - Gemma2ForCausalLM
    modelType: Gemma2
  license: gemma
- name: Llama 3.1 Nemotron Instruct
  displayName: Llama 3.1 Nemotron Instruct
  modelHubID: llama-3.1-nemotron
  category: Text Generation
  type: HF
  description: Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.
  modelVariants:
    - variantId: Llama 3.1 Nemotron 70B Instruct
      displayName: Llama 3.1 Nemotron 70B Instruct
      source:
        URL: https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
      requireToken: false
      requireLicense: false
      optimizationProfiles:
        - profileId: Nvidia/Llama-3.1-Nemotron
          displayName: Llama 3.1 Nemotron 70B Instruct
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: A100
              value: 4
  labels:
    - Nemotron
    - Nvidia
    - "Text Generation"
  config:
    architectures:
      - LlamaForCausalLM
    modelType: Llama
  license: Llama 3.1
- name: Llama 3 SQLCoder
  displayName: Llama 3 SQLCoder
  modelHubID: llama-3-sqlcoder-8b
  category: Text Generation
  type: HF
  description: A capable language model for text to SQL generation for Postgres, Redshift and Snowflake that is on-par with the most capable generalist frontier models.
  modelVariants:
    - variantId: Llama 3 SQLCoder 8B
      displayName: Llama 3 SQLCoder 8B
      source:
        URL: https://huggingface.co/defog/llama-3-sqlcoder-8b
      requireToken: false
      requireLicense: false
      licenseAgreements:
        - label: License Agreement
          url: https://choosealicense.com/licenses/cc-by-sa-4.0/
      optimizationProfiles:
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B A10G
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
  labels:
    - Llama
    - "Text To SQL"
    - "Code Generation"
    - "Fine Tuned"
  config:
    architectures:
      - LlamaForCausalLM
    modelType: llama
  license: Creative Commons Attribution Share Alike 4.0
