registryVersion: 1.12.0
models:
- name: Llama 3.3 70B Instruct
  displayName: Llama 3.3 70B Instruct
  modelHubID: llama-3.3-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.3 70B-Instruct NIM simplifies the deployment of the Llama 3.3 70B instruction tuned model which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.llama.com/llama3_3/use-policy/
    - label: License Agreement
      url: https://www.llama.com/llama3_3/license/
  modelVariants:
    - variantId: Llama 3.3 70B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct
      optimizationProfiles:
        - profileId: nim/meta/llama-3.3-70b-instruct:h200x1-throughput-fp8-r-6bjqwx5a
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            02f132ac03fb2ab51b82d88abce83b64feb565c93ad1d54f3b2ab04b7c86b21f:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 70c427b55c83a3c54340d828ce94b546ad566be2ec930f0bd760a00927b4b180
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x1-throughput-nvfp4-1bf1rojpxw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x1 NVFP4 Throughput
          ngcMetadata:
            09fcf7a392fe17c95e87d390742222a4a904b540f79f7b3b3d414bf3a092660b:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 33af5b8bea236de1a255b3108bcbb55e0dad3135b676d809d8ce339956cf67d4
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:a100x2-throughput-bf16-5hyfmddv4a
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A100x2 BF16 Throughput
          ngcMetadata:
            12c295e09aa3a3bac95522db7c0af51e27d6a4283b0402298c98691fc121a8ae:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 517f622a203fd1bdf58c0ba179d9be37fa1917c1f49e0a5aa85c7f5d3b8731b3
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 135GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x2-throughput-bf16-neynbhcsra
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x2 BF16 Throughput
          ngcMetadata:
            12f9ae91afef2d29f5ef4c312f0922ac8ed5aa877c8c49416b0dfaf9dcb902e0:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: fda9c04c123bfcdfae4f8f81847d3aee5eb51698a39dd5905d6581d780b90209
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x4-latency-bf16-h4d-jgziqw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x4 BF16 Latency
          ngcMetadata:
            135406168c0a2540196ed6f8003e35f8326cda374c6beb6f92b8b6f4883fbf0d:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 76e7be2bffcb7a930d207aa6f616ba863f1884672c64680ec0fca11bfc88304b
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-latency-bf16-of3qbtqvsg
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Latency
          ngcMetadata:
            168f348ad80045c0a730210c796a66ccf83768df25543f8b0567c1e186be9ad6:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 00a7b1bb5360bc13540061f29a07344a7aa2feefc46f7f7ff355131ba9d4690d
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 150GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200_NVLx2 BF16 Throughput
          ngcMetadata:
            195071914f36a70a2b4306853667c37e6dd145c4ed787d099a0be9e75d84c58d:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 651dca39d0943930cc8b7bc0b5cd116294a25601c9f43deab2e362e3c96fde11
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A100_SXM4_40GBx8 BF16 Throughput
          ngcMetadata:
            230323019f91e55e7e5ef0f472984bfe38672edc42d5d8f301887842e303e866:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 165e61398618addb727e82b8809cea1215b044020a8568597a31d7bee23b05e8
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100_NVLx2 BF16 Throughput
          ngcMetadata:
            252cb13923588a782037650b182dcc87562a58a6a1dc48a31519f9964dee57bd:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: adda34b085d63494164d063e4a82677e59bcde4543da432d4a550a84185434e0
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-latency-fp8-n6ww5ulixq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x2 FP8 Latency
          ngcMetadata:
            2d46c8f638e9000b9892b517219356e3b980aabd33f027e7c858386688febd52:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 00103c1174a5863d30a1429e5aba6b251aa676ec57460280f28c6cb61f117d98
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_144GBx2 BF16 Throughput
          ngcMetadata:
            30809103f16d80f0f834cfec8d3a48617ac311a1e13150534e01d1c34b0a5db7:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 70078c4e36e97245d7fe026a7cac6258820c5d8df77bf2d10432c6a35007e7e2
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-latency-bf16-cp-xxbkpta
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200x4 BF16 Latency
          ngcMetadata:
            41bc6ff1de6d3dcfe33b8070b32a89946b55b5770c92c82ffb8bb87b8e3fc9d7:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7c9d81be68e9ba750798e8c48585ebbce4d271d36981e30f09019e011d8e389a
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 139GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:a100x8-latency-bf16-qfohcfr1iq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A100x8 BF16 Latency
          ngcMetadata:
            443b4edfa5128abcbc85f57ca43e02053730a3fc22929e4b7864422cf5b12d16:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d8669419688b2ce0f64218aeaa11f4840e272e2d1f5d11fc5e0d1b3f53476e2d
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 147GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_144GBx2 FP8 Latency
          ngcMetadata:
            44edc112b59ec6736bc9fc172d7219b9999f4398e5b61a7ca692a2053e1f4fc0:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d6f8ec1ae3a5910ae26ff689e3416a0947cf1c1c1bcc7dfc8d3186e490bcb36c
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_144GBx2 FP8 Throughput
          ngcMetadata:
            4a4dc27109678a256cf4ae5209280f044a6562ade8c2e5bca3025a096a41c551:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e075a3b9652dae46b800108afda2a6f7c0f6301a35a1db3671dc8af30f1fd5a2
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-throughput-nvfp4-ujocyfzf6a
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x1 NVFP4 Throughput
          ngcMetadata:
            4bf0e1bc784ba2c8b1ae399bb1042d1546bac30df98d02663d4e1db60744aabc:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: cf417dfa6ac83cc20cfb5404ec0b2eae321d174bc4808d6007df8562ffee63d8
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-fp8-vl02sw2m-g
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Latency
          ngcMetadata:
            52050fe50397b0b158fafe24a0c1e74efad0d04351274757337c86fc99968dd9:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a9d77447899d9eb9de5254bf262250c7321a6522f30d485abd4072fc1de36dcc
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            5b6330f563a4c3f73c9b02dc126295dd85d954c0623581981d1c6179155d9f7b:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0f31befe5670c8fd4ae2429ceaa76edcfcbcdfb96db0375e2671df999e4038c7
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_480GBx1 FP8 Latency
          ngcMetadata:
            5e578516ea42fae60c4f314736e8d3e506c497894e059a6af96bd4c2c84edf23:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 68e492b05ff7304cf14489a9a313eb7049ab552fb27b106d1dc61af71a5b7c29
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-throughput-bf16-rl2yes9ktw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Throughput
          ngcMetadata:
            613255b124f05cbf875c142c5ea7c2e3ebb7754a8a5473ad828d2bb07e2eaa88:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c0f0a6abdd6734299ec6f65611fa66490fd46303035100f9c865dd5d3c1dfb19
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 150GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-throughput-bf16-lciwvjwxkw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200x2 BF16 Throughput
          ngcMetadata:
            64878d614ca9a859228cd55d140af0865823c2f3524e43c7be53c01c039481b6:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 824477061f9c69bd79fd248a136a273e8d861d092fb853ede5e06e12510d8188
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx8 BF16 Latency
          ngcMetadata:
            706687e8d19dccfb16a39808c18e54b9e55f7a5d6c2384df2c805453445ee4bb:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 095fa13f893ed4235a19615963e6b18bdb3e599ad5631c493007ae59dfe73f46
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:a100x4-throughput-bf16-lyvveim8va
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A100x4 BF16 Throughput
          ngcMetadata:
            76e28450af746bb7626af7e5e2db4b57b56f11f5b6632a120eefabba925c2b15:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f14e1bad1a0e78da150aeedfee7919ab3ef21def09825caffef460b93fdde9b7
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 140GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-bf16-rhzeshgk8w
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Throughput
          ngcMetadata:
            7cb838de5dad2c42066f0616756d0ad2708939c450b95416d41098e9931470c1:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c419c6ba54c118a6deb6ed9918e9c72e7f151698116c1d3c2bc32042a94d6bbb
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 140GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-bf16-m9pz-s1ymq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100x2 BF16 Throughput
          ngcMetadata:
            7ed84ed093e8c5e8d237966262d640c6c2f160a8606df22e869e6f7a5a83cc96:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 5006533ca6b5151e94f18d8e518c68965918f248d0680b23e9fc0e4553e0d9ef
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-fp8-wbna-gqhxw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100x2 FP8 Throughput
          ngcMetadata:
            7f4107d806d19c2c2beb2e870bf01217de37a247f27ee168985fc42a9576c641:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0013e870ea929584ec13dad6948450024cdc6c2f03a865f1b050fb08b9f64312
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct A100_SXM4_40GBx8 BF16 Latency
          ngcMetadata:
            814d03ce098b7de458602c7bce320c3d06fe898759577c849a34193653a70bbb:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7a207406eaa12a8bb549ea578116338e4e204d3b38ed0ffb6a9d9d789f2cd994
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200_NVLx1 FP8 Throughput
          ngcMetadata:
            829d3e1c28ffd52afed2d35e9374cfc7b605eda5a630bc9b33fbea5500da8fb3:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 34a1cf18c4d7501df008280668fe6df7de1f91ff29daee8d5c80291dd6e51b0e
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-latency-nvfp4-prgjwnsudw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x2 NVFP4 Latency
          ngcMetadata:
            8abcb1c5fc3e57d712a311f08f9b33b59b383196b95f7d7f66c758de85d56567:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 807294ccda05820ac7bbb9cf0471df7494e947226acff080c0782bda0c7d4394
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-latency-fp8-ozazyo6fjw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200x2 FP8 Latency
          ngcMetadata:
            92e9707e66c742310e9a7a6d38e162b2578375c8fe0844939c499a00116a994e:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 138ef4644a3d6477c3deaf2cd22f548d3396925db62f4752fb73b52b7b8a4a29
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-latency-nvfp4-gbqmrrkwrw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x1 NVFP4 Latency
          ngcMetadata:
            a1366af9ab8c32f147d10d0fcc2a43d55b20f2c79178b4a291caa5dec55f966c:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 19ca51edfcfaecd4c68b0950ff57be89e59def4ad003dbcfae4352b43d152223
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-latency-fp8-mg52y2fpwq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100x4 FP8 Latency
          ngcMetadata:
            a2003c7b2b19b79aefb52cd9daa58fb20f0520dd9759037ff34e67110f384218:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 8a5f27c50cf45f7d1a1e504bcd33820eefa80539b94a68bbf015c3f4f4cb2c3f
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 BF16 Throughput
          ngcMetadata:
            a403f6513a44565063a70541681355465810849c0f537c825cd6575c960c2c14:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4896c9f159be7403ca983e4da47959b87841d5fe0034304ab473baf61f3132a1
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-latency-fp8-uepcd7pd4a
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x1 FP8 Latency
          ngcMetadata:
            a425a0f4eef147092d6d41acbd7c9c3408614205b8135699274b02f2363b707c:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0cedb0518e3995aa41d37920a83b151ad05bdf2a43beedbff21b709cf696e350
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_144GBx2 BF16 Latency
          ngcMetadata:
            a6f328cf048298b737a05799b74a3f81b4a215f125d71088054c6c32f3446801:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7e9757ebb03d4334fd350490505620d2af6b5329aa8a28df931e0a22e46d55cd
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx2 FP8 Throughput
          ngcMetadata:
            a9f34dd0f8e4fd295b0d04067aa0ecce24aa3707b26305e9ab084d430546975c:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 77ab630b949b0a58ad580a22ea055bc392a30fbf57357d6398814e00775aab8c
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x1-throughput-fp8-ybdaheki0g
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x1 FP8 Throughput
          ngcMetadata:
            af09a13bcaa3650952df251a0dfd03dabaf7700a6d00b6f2264b2c9ef757fbb6:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b6dc07bb5bf5be874355bbe6288ca066c605a43c23d6c537ac9d4929c22d2cdd
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            c7fc979432a42458118ab456c33302cbde984c5d8a0035e9d2c1d07b5f3dc0d9:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 1dea2d2f10ec64c74ca127f73b52bf5253dfdc91c5cd5da07cb742e166e8a795
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-fp8-sx6as-ue-a
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Throughput
          ngcMetadata:
            cf120c3ecf2025e6a170cb224802ca6a02cbeec3ad74944a69263b3193a64fa2:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b118ae4fb04a6bbcf439004b94edd4815d2c965a0c692c2b98a790580c9c3f7b
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H200_NVLx2 FP8 Latency
          ngcMetadata:
            cf5787bfa25e0f21603c8aa6458d2ae062691d0fa81e684dc219082ba39fb1d9:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 552ad035a0898be37be03c9d539efbda5a7d2f214b2c5950e14bb694ad8329a9
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
          ngcMetadata:
            d650534ce98fea4bfc9924d77c91fbd8dca227321c35557e924297ab6b9008cb:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 19aeb73125023f25e273ed14ccc69b935b2ce5131d4d91d1b78f3e8bdc0366b7
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:gb200x4-latency-bf16-vuvdg5jkzq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct GB200x4 BF16 Latency
          ngcMetadata:
            d7ff5f88620f7fbe0538931af334663b43d15cb2c969e7fc96375ac60108906f:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: be07050242f7ce67689c0d81de40bb1de6967dd251a881bcb784193fb92d8183
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-throughput-bf16-omzr8lu67g
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x2 BF16 Throughput
          ngcMetadata:
            e0ac049ec460cc8dfe59feaec6d12ae55807dac2b0bd62396c36679f2674e330:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6d1452af26f860b53df112c90f6b92f22a41156c09dafa2582c2c1194e56a673
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100_NVLx2 FP8 Throughput
          ngcMetadata:
            e518c22e6d4135300fc5c10bd0c4d195c51ac596e8950172e303bcce84794732:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3035d73242fb579040fb3f341adc36a7073f780419e73dd97edb7ce35cb0f550
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-bf16-rasfmhw4uw
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Latency
          ngcMetadata:
            e6d1855d3f24e439b904cf1fd47d3e136bec4af9134c039558c61f9ae34593af:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 8747b7e093d3b26e808e8bbebdb50c3ac0a0f82402c58b3430a8760ff96e406e
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 FP8 Latency
          ngcMetadata:
            ee0b992fafa65ffe00e8df84f80f9e417a400ec40b60b6769db81498482610d7:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3140e28251686b824ea3fd4d45a86cef01b156d1737ada0b6783b612ac3b6e92
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100_NVLx4 BF16 Latency
          ngcMetadata:
            efcb2762954af78c9b84774917daf706fd8d663df3d54c298a1fb9d2fb86a119:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3d2f50e0423aa98250617f6a0dad719bed6892994a47c60e092ce494d93e9bce
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:b200x1-throughput-fp8-xk4doibibg
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct B200x1 FP8 Throughput
          ngcMetadata:
            f215c1f1608a7818f6c465646f8f8cb412a58b39c99e4a15857466fb9a970aef:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6979353282e6f8421f9ffd76c33eb1e675f796fc7ed036c6038b99a21d649f18
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct RTX6000_BLACKWELL_SVx4 NVFP4 Latency
          ngcMetadata:
            f9c5befd972751383a8dfa7b38fb77fd4c69af4e015136f0a194b7db0176ce59:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4f697999cecdc5afc7ff8f588b71a5b7683117aa866f34ab76886db2dbe86dcc
                number_of_gpus: '4'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-bf16-bpwvcpvnsq
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100x4 BF16 Throughput
          ngcMetadata:
            fbec99d055ebc70d1261d9520f1f6f854fb0a84771bdadde30668dca1f081c7d:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2eb1d578e4e069c384bf617e5354889d043a1c72b77f432c07e06ffb1b8be36b
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 139GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.3-70b-instruct:6f6073b423013f6a7d4d9f39144961bfbfbc386b
          framework: TensorRT-LLM
          displayName: Llama 3.3 70B Instruct H100_NVLx4 FP8 Latency
          ngcMetadata:
            ff1a26a9837e3e3122a70f91d46181b15f22ba8276c47b0d852cabde8a6a5460:
              model: meta/llama-3.3-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9b6105c7bf6521bd8eb6fa1badcd239636f35c06317166bf78d58a8cc239411f
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
  labels:
    - Llama
    - Meta
    - Chat
    - Text Generation
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.3 Nemotron Super 49B
  displayName: Llama 3.3 Nemotron Super 49B
  modelHubID: llama-3.3-nemotron-super-49b
  category: Chatbots
  type: NGC
  description: Llama-3.3-Nemotron-Super-49B v1 and v1.5 are language models that can follow instructions, complete requests, and generate creative text formats. The Llama-3.3-Nemotron-Super-49B v1 series of Large Language Models (LLMs) are instruction-tuned versions of the Llama-Nemotron.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Llama 3.3 Nemotron Super 49B V1
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.3-nemotron-super-49b-v1
      optimizationProfiles:
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:a100x2-throughput-bf16-ozhgcnodhw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 A100x2 BF16 Throughput
          ngcMetadata:
            0db3b5e8468c9debf30bcf41cbfea084adc59000885efd6fdcb3bbb902651bd6:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x2-throughput-bf16-aie7yrqp4q
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100x2 BF16 Throughput
          ngcMetadata:
            1617d074ce252f66e96d5f0e331fa5c6cc0a0330519e56b5c66c60eb7d7bf4f9:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-throughput-fp8-hq3hflct5a
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 FP8 Throughput
          ngcMetadata:
            26bd84b107a99415b474267bec4cbcf932fbb28e45d7fb4e4db2971506825888:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx4 BF16 Latency
          ngcMetadata:
            28552abdb2c491d46065d52ca1dc1265b99ba95a5bf8daaee4c5de12511a3b4f:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x1-throughput-bf16-2mmw837ykw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H200x1 BF16 Throughput
          ngcMetadata:
            434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 94GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-latency-fp8-1m3h4ytjug
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 FP8 Latency
          ngcMetadata:
            4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx1 FP8 Throughput
          ngcMetadata:
            5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-latency-bf16-19zfbhbq3g
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 BF16 Latency
          ngcMetadata:
            6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 A100_SXM4_40GBx4 BF16 Throughput
          ngcMetadata:
            6c29727e6e3d48a900c348c1fab181dc40bc926be07b06ca5b8eae42a6bc9901:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x2-latency-fp8-3wbe0ygpmg
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100x2 FP8 Latency
          ngcMetadata:
            6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x4-latency-bf16-9sreahcbuq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100x4 BF16 Latency
          ngcMetadata:
            73f41fabbb60beb5b05ab21c8dcce5c277d99bcabec31abf46a0194d0dd18d04:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h100x1-throughput-fp8-mhpv-tjmtq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100x1 FP8 Throughput
          ngcMetadata:
            7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 A100_SXM4_40GBx8 BF16 Latency
          ngcMetadata:
            8a446393aaeb0065ee584748c7c03522389921a11ff2bd8cb5800e06a8644eb0:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx2 FP8 Latency
          ngcMetadata:
            a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x1-throughput-bf16-e8quw21o2g
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 B200x1 BF16 Throughput
          ngcMetadata:
            a4c63a91bccf635b570ddb6d14eeb6e7d0acb2389712892b08d21fad2ceaee38:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H100_NVLx2 BF16 Throughput
          ngcMetadata:
            acd73fcee9d91ada305118080138fb3ca4d255adee3312acda38c4487daae476:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:l40sx4-latency-fp8-dm0yeik1qq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 L40Sx4 FP8 Latency
          ngcMetadata:
            bdd0d3cd53fad1130259beea81ab5711fb98f2f1a020b5b26c3c82fd7d43c5af:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 50GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-throughput-fp8-pn0bsx2fww
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 FP8 Throughput
          ngcMetadata:
            c91a755246cb08dd9aa6905bc40b7db552071d141a850be5a791b06eb4fb2ef8:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:a100x4-latency-bf16-htlclkizog
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 A100x4 BF16 Latency
          ngcMetadata:
            d73b7cf2f719d720329fc65fc255ae901bc3beebdc59be9815ede1a07948c1f7:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:h200x2-latency-fp8-v0ho-fvz0g
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 H200x2 FP8 Latency
          ngcMetadata:
            e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:b200x2-latency-bf16-moifcs7ehq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 B200x2 BF16 Latency
          ngcMetadata:
            f44768c625db71a327cf17e750d5e1a8e60171a8d8ef6b4c1c4b57fe74c9bf46:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx8 BF16
          ngcMetadata:
            1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '8'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 8
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx2 BF16
          ngcMetadata:
            375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '2'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1:hf-1a2cb80-nim-0613-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1 AnyGPUx4 BF16
          ngcMetadata:
            54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
              model: nvidia/llama-3.3-nemotron-super-49b-v1
              release: 1.10.1
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '4'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 4
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
    - variantId: Llama 3.3 Nemotron Super 49B V1.5
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.3-nemotron-super-49b-v1.5
      optimizationProfiles:
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a100x2-throughput-bf16-wcsztflslq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A100x2 BF16 Throughput
          ngcMetadata:
            03fdf4e63960724f08647e43122aab89748cf69f8e180c64fab6370abee11c41:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ae4d6417367534d6b999876248c3591165a546df619a27fe6460b92aa44e7f88
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx4 BF16 Latency
          ngcMetadata:
            0634edcf356b10f286d7a9ff5b5a0798a2616208e5c3b891aed4394fc504b0a1:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4e1be52ab36b863d4abb3e4e549f1f8150d8fe59bf3021012b9eddbb124bf1a8
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-nvfp4-yqo6gpzgtw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 NVFP4 Throughput
          ngcMetadata:
            097e7abb70716b35f220ddfa9f1beafc1872b83d2faae76087c5981875c172d7:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e1bde03fd878742322841e5871f1182069b936b6c4517c9b2d07c94d8c7e8ebf
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-throughput-bf16-lb51ks7uxa
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 BF16 Throughput
          ngcMetadata:
            0d0c380f456551cf0c7d94cba5df94a6679bf13bfcec35518dd4700277c45d6d:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 303af23d9df7615161cd22feb968e97571f32f341e3567ec57a5405fc513e452
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x2-latency-bf16-srzmz11lsq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x2 BF16 Latency
          ngcMetadata:
            0de4288607eed4d3b8fc4437cc7b7660d927d0ba9265f95f4c49191a69701446:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f96591a267ca466ff8d50fe13273091238ce4066f7da0533206572ac09da1eff
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-latency-fp8-csbsvltszw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 FP8 Latency
          ngcMetadata:
            1080a2945bccdf2773330d1ff5041b953088cb90e76c0a29ccddde3edb10fa48:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 76c65c985bc5acb124613d1c2854d8ca1908efc80cb6bdda6ebecf814f6f9932
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 50GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x2-latency-fp8-sowqqe--5a
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x2 FP8 Latency
          ngcMetadata:
            1f01cd4066c857f8982fcd8f7e7d7e4920c1e77ef50c8e0e9451815ec3d6590c:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6418fea1651154d4141be9df22ee889d55ee1e07eb23327386cfd21ed7e48917
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a10gx8-throughput-bf16-4fcffqprja
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A10Gx8 BF16 Throughput
          ngcMetadata:
            282c3be83f0772b985e007af291125cc8ecd4befc2833a96feefecfe49a6a116:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d50bef030c2c86675a058f6a7b4132438d8558afead641fa45c70cb431631be3
                number_of_gpus: '8'
                pp: '2'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-nvfp4-3sifj870lq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 NVFP4 Latency
          ngcMetadata:
            2a721971fe1905d88e8281b2804ffd900bbd20704482e07eb1dee03ca7ee1f26:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 21113f03af084c245046a894ef0cce875ebb362781b1e2d70774b919dfc08b7b
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A100_SXM4_40GBx4 BF16 Throughput
          ngcMetadata:
            2da0154c6a5ddf2d67aae37fd8a276f7fb54d69ebf9c2fe631c9cb9721912c10:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a5b791bd084d0d196d8eab3a5ee30584c4b5154b68e27d4ae27240c572aaa0c3
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx1 FP8 Throughput
          ngcMetadata:
            317edefe0e4f3253972892af7f1f8bb0787c39eaac22e54947bbd21c64c105de:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 93ae1647a06301ebae5535fc2a127f5149c5ffe3f63f99443eac45c342b36bf9
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx1 FP8 Throughput
          ngcMetadata:
            37aa8cad01613034db7185edd866ca513104bf5b87447a9ea373ddc475141a38:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7640e168db96daafc2278c529e4ea7e93a9751774a361437b064f6542fa8400a
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-bf16-b7mc0n5vsq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 BF16 Throughput
          ngcMetadata:
            3a1966db19d49667baa129a4838553168a4c66202dae42b3da82d34e0254dda9:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 56e98fd149cfe53aa5e62c155e6903b2254d7084850bfb5ea65bcd05e9fb416c
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 94GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
          ngcMetadata:
            3e02aabd0df7fb43fd55db667ddc61b9c1c6b2962aa3f2bfd0aa8d2206aa5ccd:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b22fdd19cd522ea34c068f776b07b38474bd419dd4bed6cb6ba3cb56376437fa
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x2-throughput-bf16-sfp5psfsoa
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x2 BF16 Throughput
          ngcMetadata:
            3f000887cbabfb954b87cbdafed85aeec51c82e5c941801c67a0fbb6bdbfbed5:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 037bea81c2da8987458de8a0e326c12c574c09048e1d80a027a73b6f6b553e06
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx1 FP8 Throughput
          ngcMetadata:
            4138603595d590ef014e6b18a034c8d6b6f7addc09e83ce2f97fe3d6b5502658:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3557dd611c5250fc7498c009ad75ec1ffdd75dd591e69de8efdfd0ad379871b5
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx1 BF16 Throughput
          ngcMetadata:
            439a0279d35d96d6b3c8be1f22f92a94d7e874e2476a58dc868b600861c84428:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ab0c91b93211e813ba1ef7fc61abd40d74c1babafe9d323e3dcddc74008f4cf3
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx1 NVFP4 Throughput
          ngcMetadata:
            496a3bcf32f7c7e81e59b1c17395d49b6c412dcb9e94d1bd4675c7ab61ed4b8c:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c93c0eb2422047add4d8c0141d90bab8840448b965f75976ac669b97d7934cca
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx2 BF16 Throughput
          ngcMetadata:
            4eb1789fe7a9ba85b6915c1f6ab6423be03ad2b7660fd17ccadfca11a9cea20e:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 61175440372bb9eb41cd7d5f3de3cb8aa05ab8ab84483ab3bb2580cdf9edb50f
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a100x4-latency-bf16-qfav5fnhta
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A100x4 BF16 Latency
          ngcMetadata:
            4ecfbc0680c47e40c54811d7d056bd8c2cb17410671da1d5a9d94f37e0e9ddd9:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4b36e4728a079ec71833e5b851ba55816893bae8c6b3e028c7092783d51380b6
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-fp8-hh-qiitbsq
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 FP8 Latency
          ngcMetadata:
            5104fad3c90f0e82d48218e2f295ecc76413a75f7828902f6201cdce8e11f119:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: eb379d36e7d269b0f9dedded8c2295fe06009c4792c2faebeee87520382b4a79
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x4-latency-bf16-gwrdidufkg
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x4 BF16 Latency
          ngcMetadata:
            5375ff8c01b5f03cc5226403b75091b280f9ab3b4901e4ddf08effd37f3be185:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 66667c721d5d8a4380827673282e501ca94da891407d35e1c4212606fc217cd4
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 NVFP4 Latency
          ngcMetadata:
            556dcaf16db7138e6cadd8e2a194caed98ad4d5be6c5d2f2638b4517f6d8a2f2:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7f399c329c773521d095cda5f5da78429a9a12497dc5e0a107b30250e7af3c9e
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx2 FP8 Latency
          ngcMetadata:
            557fec5cda76abb3bda2a196e908b91a4f97b18c0bab1fbc1e32927e131722f0:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0eb8ad98ede42e79a11f7439000dbc224363a640c2c03a7c0415d9d84852109c
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-bf16-ypw69-37kw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 BF16 Throughput
          ngcMetadata:
            5c181a5c2c72785a8c062e4f8b197d404caa754117731b76dfc612c4751392a8:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f9bff6c55a835edfed0cf54e1d92d121be400ddbe8bca9a14cae0406b129a700
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 94GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 FP8 Latency
          ngcMetadata:
            610f006b15f3adbdb072da0b4155d8a772332cf1768fb7389ef92a83c31c26dc:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c791be936f92f5cb480fbae429dff3fac2d0e7f1a3d3396e78196029b9a0d395
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            67fefe5a60111523b327e93282aabb0bee010780482d12aed22032fae947e6db:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f677672ff3da6e403ae52655aa3a37c53289547b58bc22c64c39364d755ac363
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x2-latency-bf16-ql0dncdzug
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x2 BF16 Latency
          ngcMetadata:
            6988d6b50d4c8c0d12579128b9ceb6dfd239d91ecc1b0dcaf6b2d5235a785f41:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3ba2484ae0c038d20cd5f4add3a088742233193c5f9c7d16c55384ddd5ad1f78
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 96GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:gb200x1-throughput-fp8-eqspsgvc4g
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GB200x1 FP8 Throughput
          ngcMetadata:
            721782adb8e04decd419a5d5fd5138ea578840ce23ae878cd66b5ade58b64860:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6dd43f5bf34d55e342b12dceabe739dc65b70b1c652b32e33158dda0176938b6
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-nvfp4-lzk6scakha
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 NVFP4 Throughput
          ngcMetadata:
            878da3cd983e1c204b447eaf6c2b1fbe15df8e3f8606dba0276dc5db6f1b2ea3:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ed7366f0b3c56148342e9281e92f74ebd0117e45028b50f4b5080474ca08579f
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-latency-bf16-fcnx7qsagw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 BF16 Latency
          ngcMetadata:
            8b3a0a14508070667a00aa2bec26a373d078db79903603585127a2a33a437dcd:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3eebbad6ddd7f86f084cafbaa2774c9b68814be840c5117b1e8f42bd4609a154
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx2 BF16 Latency
          ngcMetadata:
            901ae99dec61c02334df6c00217c665e620b03efaccd7ecbfedee9dd5b919e2c:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0f967f12c738cdeba2e1f6f507f6519b0e70fe691a3d85cc6f275bfa6cebaab0
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x4-latency-bf16-c7ags8vtqa
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x4 BF16 Latency
          ngcMetadata:
            a14acaea6216232b3dd9ff678dd04b239a48f8ef7eec367c8ba121aa93bc3699:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 79c4e912efae2b6e2670be80c6b16cf7d5a8d41658e3bdf6f0d7b72dc5d58634
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x1-throughput-fp8-tnrs6lwhqg
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x1 FP8 Throughput
          ngcMetadata:
            a55bb618b06a37fd61e99000a8ba38375801c0879c67a7a1b5a66cd497e09817:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c8b0bc8703bb921bcde98b731a73ba8a5223b4cc331b1f6ec52c97c0fb7eb334
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx2 FP8 Latency
          ngcMetadata:
            a5b40bd2025de323418db8d8577d91ad1c4c1b2143219fd9661c679e317af0fe:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 77041070f5f0dbe334cd51ed68930e5768eb93f59aff9f374f380e732fb3b078
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x1-throughput-fp8-ueeogrvolw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x1 FP8 Throughput
          ngcMetadata:
            b29ee8752b78d7d6a588e68487d9dd9f8ceaa2a01964f09c49ae9d7512a0e425:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0c5dc1a2f374f41aba6887d42b8f2497e43e32931426f33220897c481b121300
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200_NVLx1 BF16 Throughput
          ngcMetadata:
            b3c7e84a0d005d532b307e36b9956be0b169a791283fd5362fa7326c1d442516:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 74e8a2780520f4deb4b75fe91dfb53dc33ab212294b755cb654dfcfbd720bea0
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:b200x2-latency-fp8-kwktcc65kw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 B200x2 FP8 Latency
          ngcMetadata:
            b9cd24c06efe599256f1cbc69e32686bf837e634d6d72754124a3d2db6a69415:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 91ac13ed5c5bcacd46af55350326af80781385cbf9ee70b426583319f1972bcb
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx2 FP8 Latency
          ngcMetadata:
            bee87c5b924821f18e4f18f9b63509e00d105053e9c0ed00440235219cc4c355:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4c34e6ff5408a3c795f72d84ad93d221975854695c77a2c49a03c94e288ebd7e
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100_NVLx4 BF16 Latency
          ngcMetadata:
            cdc6d143f3c8ae40bef086616fe918badef8b5d8c2f7ed7bf35c46efc664f1d2:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7acb071a5e1043fb94515e5b7a4209955aa7b1a7f9311e43a96d525f36124582
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A100_SXM4_40GBx8 BF16 Latency
          ngcMetadata:
            d1a6703d5e49f81f492115bcd2fbb3d8f654fb74c7871374a0aba53e268f7eb7:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a491d0c85fd9304f23dc12098011ac5a7f06323c7f1bf5a03930512eab8bc661
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 RTX6000_BLACKWELL_SVx2 BF16 Throughput
          ngcMetadata:
            d74a0a1011908274b71ca777cadb98fb50eb4d1b03f293c4961dfffd685fa77c:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a43faa67d15febf569c0cc2520243017faa2f85e955b0da68f0819b562b0f746
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:l40sx4-throughput-fp8-grh3fk4vxa
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 L40Sx4 FP8 Throughput
          ngcMetadata:
            dd6e06ce56d8c23034792ecfafa9cad84e89381646f1a6b3f61e64d5c7151cca:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c218e34971f85acf3ff928121f744f142c144926bface213142ca6abe6d08527
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 50GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x2-latency-fp8-qionglmjjw
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x2 FP8 Latency
          ngcMetadata:
            e76d9a6e681f5047d58bb835cd1144df8a4c07cbd5e11340d9e841a34639c6ac:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7fd4e15ecac33d4ebf1f8b32433b45177d6701b159d35a262c363fd67aab00ca
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx2 BF16 Latency
          ngcMetadata:
            ecad5bd2fe50b96e275be4aede45e63ccacb4943719a70a76183ac78cb7b2602:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0863fbe7a8909618c897d216a1a1df5e66eb44030a0421496f854e0bc52bb041
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h200x1-throughput-bf16-jvvivxsong
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H200x1 BF16 Throughput
          ngcMetadata:
            ee058f1abbfe0cc174b16c966b91cfe886c7bb247fc691d8c7c8fee3dc9c8f41:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 493e3f3ab5031da3fd826eb8ef23ea20e87af83cae500214e295fbeca9003e55
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 94GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:a10gx8-latency-bf16-ejd7ve2qag
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 A10Gx8 BF16 Latency
          ngcMetadata:
            ef9c1ac2f14b38895123c608a25f0104c42557f617c91e8ef6e151bc601822de:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7c853ac2150b03fff0d81df21fed77d789c5254f9f440e32844c93d073f5e43f
                number_of_gpus: '8'
                pp: '2'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 100GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:h100x1-throughput-fp8-zmf7sc5wtg
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 H100x1 FP8 Throughput
          ngcMetadata:
            f5e04275ea0d3bd001a2262e85e47de206406d9593d74525074a25475dc47a22:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e96f0bba12e9e5e054f193562c51161b61804d52ba2bff7a49bf8aa267a1c2b2
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 49GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:hf-f091ea1-fix-chat-template-jet
          framework: TensorRT-LLM
          displayName: Llama 3.3 Nemotron Super 49B V1.5 GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            f97be1c404cf80299a3d85359c32a28710a3251c6ed6eec2dd3f3bdce2ca2903:
              model: nvidia/llama-3.3-nemotron-super-49b-v1.5
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 911352dda31a6b8811db6e5dc7c573094dadfc2354bee8cd0f41e784e79fc6f6
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 93GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
  labels:
    - Llama
    - Chatbots
    - Virtual Assistants
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.1 Nemotron Nano
  displayName: Llama 3.1 Nemotron Nano
  modelHubID: llama-3.1-nemotron-nano
  category: Chatbots
  type: NGC
  description: Llama 3.1 Nemotron Nano 8B or 4B is a language model that can follow instructions, complete requests, and generate creative text formats.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.1 Nemotron Nano 4b V1.1
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama3.1-nemotron-nano-4b-v1.1
      optimizationProfiles:
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:a100x1-throughput-bf16-a-zgkhv-7a
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 A100x1 BF16 Throughput
          ngcMetadata:
            222d1729a785201e8a021b226d74d227d01418c41b556283ee1bdbf0a818bd94:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:hf-9f834a8-fix-checksum
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 H100_NVLx1 BF16 Throughput
          ngcMetadata:
            25b5e251d366671a4011eaada9872ad1d02b48acc33aa0637853a3e3c3caa516:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:h200x1-throughput-bf16-6ej0hxqqug
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 H200x1 BF16 Throughput
          ngcMetadata:
            434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:a10gx1-throughput-bf16-kf8s30cw4q
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 A10Gx1 BF16 Throughput
          ngcMetadata:
            74bfd8b2df5eafe452a9887637eef4820779fb4e1edb72a4a7a2a1a2d1e6480b:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:l40sx1-throughput-bf16-ji5fmrct-w
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 L40Sx1 BF16 Throughput
          ngcMetadata:
            ac5071bbd91efcc71dc486fcd5210779570868b3b8328b4abf7a408a58b5e57c:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:l40sx1-throughput-fp8-y0vtnnyy0q
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 L40Sx1 FP8 Throughput
          ngcMetadata:
            ad17776f4619854fccd50354f31132a558a1ca619930698fd184d6ccf5fe3c99:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 6GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:hf-9f834a8-fix-checksum
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 A100_SXM4_40GBx1 BF16 Throughput
          ngcMetadata:
            c6821c013c559912c37e61d7b954c5ca8fe07dda76d8bea0f4a52320e0a54427:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:h100x1-throughput-bf16-n6thxsck2g
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 H100x1 BF16 Throughput
          ngcMetadata:
            e7dbd9a8ce6270d2ec649a0fecbcae9b5336566113525f20aee3809ba5e63856:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:hf-9f834a8-fix-checksum
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 GH200_480GBx1 BF16 Throughput
          ngcMetadata:
            f7f74ecd523cd63065a50016a8786a893b9b1efe0d313bc5bcc54682f56e55fe:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:hf-9f834a8-fix-checksum
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 AnyGPUx2 BF16
          ngcMetadata:
            375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '2'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/nvidia/llama3.1-nemotron-nano-4b-v1.1:hf-9f834a8-fix-checksum
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 4B V1.1 AnyGPUx1 BF16
          ngcMetadata:
            ac34857f8dcbd174ad524974248f2faf271bd2a0355643b2cf1490d0fe7787c2:
              model: nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1
              release: 1.8.5
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '1'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.5
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
    - variantId: Llama 3.1 Nemotron Nano 8b V1
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.1-nemotron-nano-8b-v1
      optimizationProfiles:
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:a100x2-latency-bf16-zxsnn7zu2g
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 A100x2 BF16 Latency
          ngcMetadata:
            2146fcf18ea0412d564c6ed21d2f727281b95361fd78ccfa3d0570ec1716e8db:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:a100x1-throughput-bf16-jfn07bk9ua
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 A100x1 BF16 Throughput
          ngcMetadata:
            222d1729a785201e8a021b226d74d227d01418c41b556283ee1bdbf0a818bd94:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100_NVLx1 BF16 Throughput
          ngcMetadata:
            25b5e251d366671a4011eaada9872ad1d02b48acc33aa0637853a3e3c3caa516:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h200x1-throughput-bf16-hqyhv2wimw
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H200x1 BF16 Throughput
          ngcMetadata:
            434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100_NVLx1 FP8 Throughput
          ngcMetadata:
            5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h200x2-latency-bf16-q6opgs6yja
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H200x2 BF16 Latency
          ngcMetadata:
            6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h100x2-latency-fp8-zsiywmloya
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100x2 FP8 Latency
          ngcMetadata:
            6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h100x1-throughput-fp8-5tn9pkgdbq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100x1 FP8 Throughput
          ngcMetadata:
            7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx4-latency-bf16-k3y094rsxq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx4 BF16 Latency
          ngcMetadata:
            844ebe2b42df8de8ce66cbb6ecf43f90858ea7efc14ddf020cf1ae7450ae0c33:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 19GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:a10gx2-throughput-bf16-htgj9vhmiw
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 A10Gx2 BF16 Throughput
          ngcMetadata:
            8a62b002be0b7f82c407e5ed45c50dabe654deca052b521a920682f918323d0d:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx2-throughput-bf16-qivaletdla
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx2 BF16 Throughput
          ngcMetadata:
            973a6bfbfc5d13fc5eb18f5011fab777a5bd257d5807e97f842a3364e82160dc:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100_NVLx2 FP8 Latency
          ngcMetadata:
            a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx1-throughput-bf16-anodjae0ya
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx1 BF16 Throughput
          ngcMetadata:
            ac5071bbd91efcc71dc486fcd5210779570868b3b8328b4abf7a408a58b5e57c:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx1-throughput-fp8-dbamkqep8q
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx1 FP8 Throughput
          ngcMetadata:
            ad17776f4619854fccd50354f31132a558a1ca619930698fd184d6ccf5fe3c99:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h200x1-throughput-fp8-mafkx9-zmq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H200x1 FP8 Throughput
          ngcMetadata:
            af876a179190d1832143f8b4f4a71f640f3df07b0503259cedee3e3a8363aa96:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h100x2-latency-bf16-iq2eo5lxgw
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100x2 BF16 Latency
          ngcMetadata:
            b3d535c0a7eaaea089b087ae645417c0b32fd01e7e9d638217cc032e51e74fd0:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100_NVLx2 BF16 Latency
          ngcMetadata:
            b7fad3b35b07d623fac6549078305b71d0e6e1d228a86fa0f7cfe4dbeca9151a:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx2-latency-fp8-hkd8uidneq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx2 FP8 Latency
          ngcMetadata:
            c4ff823a8202af4b523274fb8c6cdd73fa8ee5af16391a6d36b17f714a3c71a0:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h200x2-latency-fp8-a3-t7tca3g
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H200x2 FP8 Latency
          ngcMetadata:
            e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:h100x1-throughput-bf16-iugafozvdq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 H100x1 BF16 Throughput
          ngcMetadata:
            e7dbd9a8ce6270d2ec649a0fecbcae9b5336566113525f20aee3809ba5e63856:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:l40sx2-latency-bf16-z1ujefobmq
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 L40Sx2 BF16 Latency
          ngcMetadata:
            fa36c3502e92c50f78a1906242f929864955e702b7dbfbdb19758fb7ee9aa811:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 Generic NVIDIA GPUx2 BF16
          ngcMetadata:
            375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '2'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 Generic NVIDIA GPUx4 BF16
          ngcMetadata:
            54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '4'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 4
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
        - profileId: nim/nvidia/llama-3.1-nemotron-nano-8b-v1:hf-25.03.17-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.1 Nemotron Nano 8B V1 Generic NVIDIA GPUx1 BF16
          ngcMetadata:
            ac34857f8dcbd174ad524974248f2faf271bd2a0355643b2cf1490d0fe7787c2:
              model: nvidia/llama-3.1-nemotron-nano-8b-v1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '1'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 15GB
  labels:
    - Llama
    - Meta
    - Text Generation
    - Large Language Model
    - NVIDIA Validated
    - Nemo
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.1 Instruct
  displayName: Llama 3.1 Instruct
  modelHubID: llama-3.1-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.1 70B-Instruct, 8B instruct and 8B base NIM simplifies the deployment of the Llama 3.1 70B-Instruct, 8B instruct and 8B base tuned models which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.1 8B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-8b-instruct-nemo
      optimizationProfiles:
        - profileId: nim/meta/llama-3.1-8b-instruct:a10gx4-latency-bf16-r3bmpcovtw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A10Gx4 BF16 Latency
          ngcMetadata:
            09fec372bdcfaee0662140bc5ed522900bb0b0da7cc37ceba6209731dc55a689:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a10g
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c0232176c2e5374758e3d88ea13e70aa0edca0862c923428f54b85da208960a9
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 19GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100_NVLx2 FP8 Latency
          ngcMetadata:
            0c87e2871cd7a6ea205a137109c3afde0134ba22c6fe8e978a752287cf561643:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100_nvl
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: cb6ac7eedef673edc08e85f4f3e7525c31f499e5c5f376cbffc05cb8eefe197a
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-fp8-8imkyjutxw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x1 FP8 Throughput
          ngcMetadata:
            0cf8ac8bfbf183d8a891e9023d6aa7a1d93f6720e5bd78e578711e3d5b822c52:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2feaef51b8c016e5c678f39202dfe542c11eb5fc2443749e6c2330f3474aaffe
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h100x2-latency-fp8-cvpqroehhq
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100x2 FP8 Latency
          ngcMetadata:
            0e0a9fb28e4df4f8a2dcaafbcb03ce1e0b9d27a4e00ec273f27bcc47e7572225:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4217e8fa6ba7ac9609ee76470bec904253dadbe7fc33a52f715e08791073c501
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-fp8-i4razlnzqw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x2 FP8 Latency
          ngcMetadata:
            192d34f8204aa5c44b08406f8d98c86c606363ff8a2ca5f608b87a2516313b55:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0222120a0b05a944b22ed6b0d7376bbe89abef1c05fa6ecd7967199500398864
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200_NVLx1 BF16 Throughput
          ngcMetadata:
            1d7b8b2d964254990181ba7a6e93687275c3372b689d66b6494ad5f788a108a6:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200_nvl
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2660946198ebbb837e487b333ef86b2ac4cbc37b907151de45f291596625f919
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_ADAx1 INT4_AWQ Throughput
          ngcMetadata:
            245a4f27515a6291ac239b37f209847384dbadaa5ad155c45d17bcc524594371:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_ada
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4d714aa3567eb6e2d72aa08be91bb5fc632e7bbaa645c265104ea1d65eb28efa
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-bf16-zsf8rdhqtw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x1 BF16 Throughput
          ngcMetadata:
            2465a2b2fc773ea207e312352258ca9a54650fc9ec9740ae96646528556a0916:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 61348d392451059a37d2218d940f4aaf266562d0d6fa156e211f266022d5d26e
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_480GBx1 BF16 Throughput
          ngcMetadata:
            28e1523b3569391509a8e976f17c0b04e21faee7095225076a99636cbb1da858:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_480gb
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 828408fdd397e49bb4256a997d3f85d90c3d9a3e756531b8895cd78a83574aa6
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx5090x1-latency-nvfp4-ykoby0xhrg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX5090x1 NVFP4 Latency
          ngcMetadata:
            354ba4587a553bc92e5ce6caf8623e573bc0c3c5b318f5951102190d2dcfafde:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx5090
                gpu_device: 2b85:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e0aa73ee31c3c8abbd63613ab1b090f884d7b6a26dd132eacd42628b99752b74
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX5090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2B85:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100_SXM4_40GBx1 BF16 Throughput
          ngcMetadata:
            40d4f2dcb13710bf7fcf1d9d41dfeb1b0ff22ba2d266bc2997a81a000fa5d031:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a100_sxm4_40gb
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 72732266ad2f3d3b824f413f11716f81b87ccb602c3cdda972c7341c0d1e60b5
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx4090x1-throughput-int4-awq-h2km-agcia
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX4090x1 INT4_AWQ Throughput
          ngcMetadata:
            4351693dec21e2af27f6309206818eae6ef49a9464d96e043221add168e81d09:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: dbbdb2faa9a306ecf3066820bd37393b1530a725a55a15aed80ce250e3473786
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h100x1-throughput-fp8-rmqqnk9ima
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100x1 FP8 Throughput
          ngcMetadata:
            4411bf23579e41275d6a994cd768d9dc2ebbd523253e2844115f24644a5e86b1:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3950ee02bc0277147b77079c0cc5bc954b9189f7866fbbebc37ece4ec31283f6
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-bf16-px49bz6jka
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x2 BF16 Latency
          ngcMetadata:
            4a7b681f1dc1dcbc0b98f4c4eaa6bdac6557af058dd878039624c68683e2dee3:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 467e29e38751b085aa13fdc92f6eaf1a08a8c360ef19718a92f64bd507221fd8
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-bf16--fupfm1fjg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x2 BF16 Latency
          ngcMetadata:
            4b344f09436a75385ad7c78aa224f685d1f92980ccf7ea52f29a52c1ca646b70:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0a3a8da158191386b506caa79c0bd9787f45009a7e52113b82fcdde0511001d7
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:l40sx2-latency-bf16-aauqggrlkw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40Sx2 BF16 Latency
          ngcMetadata:
            55df9113a4cd134e4ddaeeae43cd33089be30b74380a9bc29d677ed9784a3492:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: l40s
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9b1feaf6e923581317ff4291ca09856eb403efd7acdeee1c8e787d988ced56ce
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h200x2-latency-bf16-zwyr4clzla
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200x2 BF16 Latency
          ngcMetadata:
            588fa4150abaa001f1357112de2ca65c85c1c86322b3f7d0ca9f1451f40baee5:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7b377dc3e02bbcef7ec1c0ccee4afc1d99d2409dc7ab6576f1f386ebbedeabc6
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-nvfp4-urjebtmqkg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x2 NVFP4 Latency
          ngcMetadata:
            5eaaf502f6dab9ce29e7d034182bb56eeeb3e349633f4561018f27b3069189b3:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2693061ea8698de078f95517349178ce8894a51a97db468183032cba22ab04ae
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 6GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100_NVLx1 FP8 Throughput
          ngcMetadata:
            785d7d60df3f153a36413f29a16ac14bc5cfba73004bc7feee2bca9d78b10e6f:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100_nvl
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a0de60706fabf3ee071fef41f0c14225a3d88799bb9728af810e57a7499f038f
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-nvfp4-6zvdbhtdna
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x1 NVFP4 Throughput
          ngcMetadata:
            78fdabce8c3eae38cea72ca3f28aaca02e3cc475c17913d6e8d4e554cba2aaa9:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d07936f83cf22e053e9fe3339050f2e05459ebcde766c94fdb7a6ac90aeb1fda
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 6GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_480GBx1 FP8 Latency
          ngcMetadata:
            7c71f0d6db2e0d52a3fbc34dabd0584ed7a27ef63a49e21aaa394d8746eeb189:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_480gb
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 1fa738c9de9d4b25a298b3cd021b05beab57c2c9ab5a930a3d1efcf7204fc463
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx5090x1-throughput-nvfp4-mtx9sbomjq
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX5090x1 NVFP4 Throughput
          ngcMetadata:
            7ce08f76c0ca314e10e00fed7a67de7067b79bada8abe7734c62f4e15ceba717:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx5090
                gpu_device: 2b85:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ebc97512fc41b1175532b6636aad97e20c356283aaf7bab2eaad5dc4ecb62a71
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX5090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2B85:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h200x1-throughput-fp8-mqkoo4u9fa
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            83fa1ce989c823d1fba445823ac58beb734bb31383a33af261a8b0808495678a:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d7e3e88abee403b365d238441ca9c1172e71745fe43cd7dce511e7d95309d237
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 NVFP4 Throughput
          ngcMetadata:
            882e2041a947f6e0793a600a4470fbbd41e7a3f3363bb4956a2c63aaa7cf51ec:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0852d2d4b6d54d6bc12acf922890bfa19e801e74276ddddcff98034ba0dc4c0f
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 FP8 Latency
          ngcMetadata:
            8855de19ef9d0f55c0213a8786591091cc5965a2c862562cc7b492c712ef09e3:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a11707b8479a7230d31a451c07c5650f0e8ff58948507a983a2e89b846929ecf
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200_NVLx2 BF16 Latency
          ngcMetadata:
            885fb853c59fc5ea3a61554797670d6f61e4b2db23f1acbc69f7e8e98846ce21:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200_nvl
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 362023b28455913264302e9d87593459bc9930c544859af88689346e92085fea
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx4090x1-latency-int4-awq-sepy5e-epg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX4090x1 INT4_AWQ Latency
          ngcMetadata:
            889b6bd58523ef352f53980df73fca1a387b4d37664d251639a3ca183ac6a8f6:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a35f746edb2b2c7dd9bfcf72e7ab8334042de7f4bab51cc2793d4dd7fc10d4c7
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100_SXM4_40GBx2 BF16 Latency
          ngcMetadata:
            88b3c4d52c48162915703053126fe2d2ec64632b4508fb05dd0984904cc4b313:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a100_sxm4_40gb
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 344bc1f6c75518604e27015bf9131a6dc8c5257396806f35575516bb14234706
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-bf16-qsrhtlj33g
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x1 BF16 Throughput
          ngcMetadata:
            8a33858f5392a45aa85acaab0a81601e9831cfd99507249536c63be228f09918:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3cb77524c717d774efbda1f850840b59abc39d9bd46fc2983ebc3dc1f4931ff6
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200_NVLx2 FP8 Latency
          ngcMetadata:
            8b0cd9578c1bf872d35c8da2dc72ed6f2161623840923884a8f50725ec11a4ec:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200_nvl
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3a251730a9c214eea8101d8192f6c4c35b1d321aad615edc1e0a942521b828b0
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h100x2-latency-bf16-xhazfvu8og
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100x2 BF16 Latency
          ngcMetadata:
            8ecf55cfb8e611fb1e1579b57089060c76270bcafb322a872c751cb59ba840bc:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 782d96856a10dac93438804c42286ba3e7d0d7445d7fbd8f8497dd3c80238564
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h100x1-throughput-bf16-tgzhmf3syg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100x1 BF16 Throughput
          ngcMetadata:
            90061152a480ade6c471a982258bf4e42dc51cf29ad9f6642120547c33bdf51f:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 04c9939245eef94e92510642382d6ad26f65a25cf1687b76ccc4e66aba70da39
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_144GBx1 BF16 Throughput
          ngcMetadata:
            9020f539c475f53d364474485cd83728454b7a340c0f1ee2d3cf505ccdcc1189:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_144gb
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ca7f6e7d29a1f514a9d7f4f3d731b0a0d286a9358a96287b12a1045ac9ca590b
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-fp8-hrzafixo7g
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x2 FP8 Latency
          ngcMetadata:
            94420d0c4e672e70e91c15d5a6e23c447fa3b43f1632936eebf9cdd0c845d036:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b1e67d29794a75bf923a7224dd297dbc4aacd4d97273a7fd66dda7e8371a6da8
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 NVFP4 Latency
          ngcMetadata:
            95f587f27ab8c1467d93d12ffb7db8f3920888b4211c2ab82ef4f8de2fca61f5:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9cd258950837575782b24640b90c1cd969334d691131036208cd3c8b0735f927
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200_NVLx1 FP8 Throughput
          ngcMetadata:
            9b0e99f6e9afa6fa529d47662d85b1e6d16b3abadcc2a5e72c10486eb7c87201:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200_nvl
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 93297aebf65f337e982d4ebd8e79f380bd9ad05346cf2e18908c6365de2b2307
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-nvfp4-sgvjjrbeuw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x2 NVFP4 Latency
          ngcMetadata:
            9f558e6681791166fdc01cacf06f2d869b67c26f1d573738f92e5e227f820270:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: efc59c490dab28006a89a5d53a36d4ef5c5d3b0927c7d118f02014d4eb0c29e8
                number_of_gpus: '4'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 6GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:l40sx1-throughput-fp8-xad-wr2scw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40Sx1 FP8 Throughput
          ngcMetadata:
            a3e90cba8e03efc80877da3902607362c851c36e8c45cd92aada9e7cac900765:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: l40s
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7ebba124e3f58d0563b96377f7c85432ef3e2f393efb9e158fd308a8738abcfb
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h200x2-latency-fp8-cftgwz2fda
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200x2 FP8 Latency
          ngcMetadata:
            a826d9d8199abbe4e4084a2f64d3658ef6749b1697ecf21fd0615d1e138e368d:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6bc839be18669cae90a69af4e02503965be03b8c68b1b7ac2cf6b612033abeb8
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx5090x1-throughput-int4-awq-ll9tz8v2cw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX5090x1 INT4_AWQ Throughput
          ngcMetadata:
            a87072ad49cfd71bf350df5757a464c8ee41a88c7df6bb436fd799242191dbf6:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx5090
                gpu_device: 2b85:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 037a33809085ec8ca342250e92024461ffc81a890525269921be8aa0c24b1e13
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX5090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2B85:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:a100x2-latency-bf16-oxfjg8md-a
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100x2 BF16 Latency
          ngcMetadata:
            ad582d87e490e749edcaf041d763e6c3f492962ccdbbe83e9204b48d6cfe7641:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0b1583a74d6516dd30c0bfdce8972835384f10fb4f617df4e0260fdf5092b059
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 17GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-nvfp4-ihgvv-o6wg
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GB200x1 NVFP4 Throughput
          ngcMetadata:
            adbc8a19059852df0c2ac75173b80f123b0901926e524a2c050ce60aa3ae5ca1:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gb200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a381f8cc9d090bc49cb320a47cdefe01b0555dc9409312516194cb19437436d0
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 6GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100_NVLx2 BF16 Latency
          ngcMetadata:
            afc6d2a8f5c1affe8524a39c78d6f083cd56ac678f9cc9f89df33b0e0e530ec5:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100_nvl
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d0040f5636dd8d4baa9c36337ccb4157b58e47ba7118b2d54b36e2ad96061ed0
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            b0c4bcf92286ad2f689805bf411e44a617df5a5455c703ddd8053f354d40b5cb:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_144gb
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0ec33e185e2d8e2e4bd97118f54276dbece4b6744371f895bd4c86e8e4dceedb
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:h200x1-throughput-bf16-6ylo-i-bbw
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H200x1 BF16 Throughput
          ngcMetadata:
            b795f66a018d1278aaded769cb88a79b5565d2fe6497739b03d8f1bad88e75d1:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 673a0a6cdd37cabec7d8dcc8f05f787884c72f2b56fcaad416429dda38238c0b
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_480GBx1 BF16 Latency
          ngcMetadata:
            c11d003373b87576201557974186967205684e4045905b5140a3d92f274cbf5f:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_480gb
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b41e403000a7d5221cdd4f00ab4d8a2ef58aa3470a65db51abd523b245c63ea6
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:l40sx2-latency-fp8-szl6-yje2g
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40Sx2 FP8 Latency
          ngcMetadata:
            c512ff489822b14e13879c4b1cbb849e5a45d453beeb2d9abfe52f029c0639d2:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: l40s
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 570d33681085a88ae5ea6bd28342996817acb2d9b0a5e8486e197bba77b832a1
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_ADAx1 INT4_AWQ Latency
          ngcMetadata:
            c95bbf72a36cc53dd0750074c0307cbc16ef98a8634cd89f94046e226c892ac9:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_ada
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 737909c201e9ccea9bfb138401ed768b71985f2aad636ed91b7ca0712e02cb43
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 BF16 Latency
          ngcMetadata:
            ccfeded811dbe0f17d70c25f83c247d1317114349b5df99ba1044c1fcb79b8ef:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 689cc0a0026ff1fff0e5818d26ffe369c59e7b16f96d9239248504fbab23c28c
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 BF16 Throughput
          ngcMetadata:
            d3ab627cccb5910fbce6396c9d205c84792abee634eb9f334c47086cf5d01b12:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: fa369969c2e20bb29b6b004cde3f63ba17a65056818bd8ad63528141ecb41527
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:a100x1-throughput-bf16-lwcrbwztpq
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A100x1 BF16 Throughput
          ngcMetadata:
            d67b7f59a9a2851e98bce877ee3702e82a3166322418dbf900a6a15e46643472:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2c735fe09841c686ba2f7ace400337d0f11be549d41cdeb9ba1c82688d0688fa
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_144GBx1 BF16 Latency
          ngcMetadata:
            db8a6f9d6f65eaec69ec78ea131cb34ec66bc63df975d23f8d2ccb031806dcc8:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_144gb
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c9d911dd01c8c520784ca0fec350f83855a8ca1ea1a3fed5f707fa642945a3e3
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:rtx5090x1-latency-int4-awq-kxnfajup9a
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX5090x1 INT4_AWQ Latency
          ngcMetadata:
            de3e9db1f9e1c1864e22598536feef42e80b6c33ae1327713a78874dddb2e32c:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx5090
                gpu_device: 2b85:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e01b16995e3845a260c61640c84529f3eac8233a1b72271a8d73f958ca5921d4
                number_of_gpus: '1'
                pp: '1'
                precision: int4_awq
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: INT4_AWQ
            - key: GPU
              value: RTX5090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2B85:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-fp8-i5rbiys4jq
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct B200x1 FP8 Throughput
          ngcMetadata:
            e0b3ee6ce141beca50c67daccbebb1ce7417c14acd08c81346986898042733b6:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: b200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9d7c4bc4201757dcd3f1147712dfb1c83a8f8535405a59e1fa547f17b4a5869b
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 9GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct H100_NVLx1 BF16 Throughput
          ngcMetadata:
            e6c81e90a8ff3f2cf1b1bffbf760b05c7cf12d18c6486a4690b8ab81b6de436d:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: h100_nvl
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b75eb29f401f555ea3d19a6df30861ef874d10760590ee8856ff0542d7ea1e7f
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            ed144c17645499c4cd983b4a2e4bdc23f0f03cc55e19073c357e8eb0ff982dc6:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_480gb
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: aab7bbbbcf3e6f7fb544ee77017dd2ee59aa0b81dc314dec4bb46317def34714
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 FP8 Throughput
          ngcMetadata:
            ee928087f01a5df571cf5e62c96f66fedccaf180524ce1e43cb4b5a23295deb8:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: rtx6000_blackwell_sv
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 60b75ec923fe8a417deb0273d9a21b4fcd4e3e0f8f9ed6e9527a66433cf6030c
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:l40sx1-throughput-bf16-lh60z9g-aq
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct L40Sx1 BF16 Throughput
          ngcMetadata:
            eece8dae913d9055ed8060b6ae1764cefecd6d158dd314851e1ecd15b5d9126d:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: l40s
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ded6e827825103665f5fea2381f04196a88c95525aea31c073556f0204ad9c8e
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 16GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct GH200_144GBx1 FP8 Latency
          ngcMetadata:
            ef8d429a394978d394a8d15ddbdd6666bde4dc68e40f8cb399b188f5b7e59db5:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: gh200_144gb
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 02d2b0459a15ab0a39ec4335caf74e3105e66f51ae577b7bf8a1b64cfcb5c472
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 30GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-8b-instruct:a10gx4-throughput-bf16-g04kznyzwa
          framework: TensorRT-LLM
          displayName: Llama 3.1 8B Instruct A10Gx4 BF16 Throughput
          ngcMetadata:
            f02876a90b3197bcf046fee9ab2beb6f7482b8b35e3ff9ff545d03ba9ba7bb23:
              model: meta/llama-3.1-8b-instruct
              release: 1.13.1
              tags:
                feat_lora: 'false'
                gpu: a10g
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: fda7bc4c0bf1f5eaeecbf29fbdd078ecbf587ac57c62610180d3d5fb90ffcfda
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.13.1
            - key: DOWNLOAD SIZE
              value: 19GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
    - variantId: Llama 3.1 70B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-70b-instruct-nemo
      optimizationProfiles:
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x1-throughput-nvfp4-lissxvpltg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x1 NVFP4 Throughput
          ngcMetadata:
            1b7ebc7f2cd12aa502b3f2bc17fa55a91f304abd992b287c535a59b6536d3e05:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b476c975e5339b67e01a1a9aee137aa1dd80c1d520b62ba160b64e426c8e2e6e
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx8 BF16 Latency
          ngcMetadata:
            266a5944d595ad57b186c01686b30ba7d1fc10f22a5b4fa17ef8d5cd54faf0f8:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 62c6e2eeff50dd4b71f6a31817eed7685778f8d1415340f402e269add0ca102b
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h200x4-latency-bf16-csp1xgtxoq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200x4 BF16 Latency
          ngcMetadata:
            2a56d7a6042e02c5b469f5128c76379973e255caf5b1adc1cde6e03230159077:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 91f8367eac71f0e5731988bac7b8b9ae66747619ed7cea336ff1ad2609b07945
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 139GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A100_SXM4_40GBx8 BF16 Throughput
          ngcMetadata:
            2fdeceaf1b64acf3ab1c2a22b8e23f6c25d639d6a5d7006c51c80b613fb2699b:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ce61710173c15471c4031430bc8de32b94fb1859a9d4d4cced5c09664b9658c3
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-throughput-fp8-ulen5raong
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct L40Sx4 FP8 Throughput
          ngcMetadata:
            3013dcf9b905cbd2f5e23f804fd5d66d183ddc71a8735631d3cad277f7c23897:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ce87554d33c9d66d40c52c15b3a90b5c802ef4b7d05781dc74fd18485a20e15d
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-latency-nvfp4-aiiz15cu0w
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x1 NVFP4 Latency
          ngcMetadata:
            344979e57f70e669d35378bc48ef7d14a13dc6aa0467ce9cb29166b8a8371bcb:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b668500698d48c5aee9f5b591c4383cb62053acb59539cf0b511b8b2d2ae864f
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx2 FP8 Throughput
          ngcMetadata:
            3526ceaf332ec21d4317c0939a99a3862b19593527fa942ffd5a1df2dade47ce:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2a535c9c9ddfb8e328abc28f3b4d9564ecdf9886fa177096f7b38dee7af754ab
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100_NVLx2 BF16 Throughput
          ngcMetadata:
            3684471ad5d007fa1f72bbc672a794107de7b0e8df88214dc1563a24aa99c8b7:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 22af385c5fd7064b011e826d0d78c210b7ac1fe7a9e29eef15e6a5e433b9db9d
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-latency-nvfp4-hrt0sgzswa
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x2 NVFP4 Latency
          ngcMetadata:
            377c705c5682293482c5094b946b8e74ccba5302c324b5ce41f952e9cac29890:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 289f1c679cc71fbadaa8139366458b0c3fc39d49ba067efdb7db9fbf3801ac1c
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-latency-fp8-ctp-cvrc0w
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct L40Sx4 FP8 Latency
          ngcMetadata:
            43160a1132063bf60ef6d7fe17a9b271f03dedbdb3bd1584a2e53707c8faa9ce:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f1a3de57c511586b258f58e7457103c919f8fa4db289d37961cad2468596ee6c
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100_NVLx2 FP8 Throughput
          ngcMetadata:
            44d44ef91639f0c76a1ef4be0022651ed8d42b485c26de00ba99aee570d1768d:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 1d049541d40b0b0407983f0438189a5d21af6652866d6640437e0323c7878361
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x2-throughput-bf16-lo9t8i-qua
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x2 BF16 Throughput
          ngcMetadata:
            45c52f130d8d467fa6e91f4ffee683fff5601e16df41388d4047e63e294e1165:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 706ae15947d58ed243812620f46199e223e7288c6624ccd33d9e9393a7bfb96a
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
          ngcMetadata:
            4b9618100e94fc85d674a89eae960e18d8192163abe5db2a0d2be891d32ea06a:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 54ad694d948a6bd8d413341c0d9476b3756a5553aa8ce8ba5479d3b3cf289e9d
                number_of_gpus: '2'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h100x4-throughput-bf16-wf01-bcefa
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100x4 BF16 Throughput
          ngcMetadata:
            4d9f79288ba78fd61b3cc445c6f9da30362a132ea371798a8ec3dff7bddc3a20:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 22f873ff61f22bd360dc173f0f4a068d4d950c02ea6045570eb7f50ec8f83e93
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 139GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h100x2-throughput-fp8-vjxy5bkroq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100x2 FP8 Throughput
          ngcMetadata:
            4fbe63c3f6f9b928dac05fe81a278ac1ad45ccf329850f66bd6cbc0c2f2c044c:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: bb98ff9885aa439391b057063cce3555833a27f88d982b2c210fd4b752390475
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_144GBx2 BF16 Latency
          ngcMetadata:
            50fe6d2879cabe91e1e0b96314d40695e7ffc9e83a02d63629b9cabfae496dbe:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 21c7fedc20e7b94738606f7f4f8ebb346dc3f087f082dd32b713e4b8e6ed0a06
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200_NVLx2 FP8 Latency
          ngcMetadata:
            592714cb05c8f25c0445fb7467d096956db9bfbee0958eb713c02a5410867bff:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 90dae25f9f80d311b10f61f5772c37bac723422cce689c138396be49db0b82f4
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            5fbbcbeb676751bfdc9b65cca39334f82fbe543070ea66b4756f71de6cfe2b59:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b2d2411595259e3d02add53ce15aaae59cf5bb02731910aecbd8b5b7a3f75adc
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:a100x4-throughput-bf16-ftwaepe7oq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A100x4 BF16 Throughput
          ngcMetadata:
            68aff19a2e5198624143bf25060662c863ecf21039b6f2d4ef3fe7965a8bab96:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 8f849c4baf82033a3bbfba75bd2a6fc379c92079e81f6fca99f978c9d1c04ad1
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 140GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h200x2-latency-fp8-msyzoyixrw
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200x2 FP8 Latency
          ngcMetadata:
            6c27932dc47820a7130505d6bceca05a3ec27628a8416b4603b9b9c8367f161d:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 070c645e1731e5dd9875c800a22cadcd32f9008bf79b768884a331afc9c96e25
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-throughput-bf16-gfrr6smxia
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct L40Sx4 BF16 Throughput
          ngcMetadata:
            6c9c0490830921741f09a61b59d32ff645681d80194b3af37214824d65f05e7e:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e4710ee55a988086fb6dd511b81e989b78d523d951f0da1719cf0328d750a71e
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 140GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x1-throughput-fp8-ktlniezpyw
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x1 FP8 Throughput
          ngcMetadata:
            741556aa43f38761800674e07ff79f5d61136c8301687b3f914f61c78f72ce46:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d8ffe1683a73563951753b8b23c0854020887590f3a2112230e0ad947fe1ae99
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            75e60d670c274c13e9647548bc1c21549d28871432524a0c86becc2b9c73392e:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6a43b054452f258a2315e308da5d8813a4d5c7672764a4f28218373855853197
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 BF16 Throughput
          ngcMetadata:
            76296a7f2a589f543337824f321c38801835885f3a85d9efc3c5b820d7db5228:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4f131424adabbfc81a877f09da0ca3bb31989fc0bed618b8d0c5969faa01f7fe
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:a100x8-latency-bf16-zb8ixw2ong
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A100x8 BF16 Latency
          ngcMetadata:
            7cfa94d868fb7d979659d8418cbf37496cefd480d3b3b3ea06877b08e2868827:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 698871a2af3710aa48027caa8536573c057658a99a89b8d9652e15f19f0c2e12
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 147GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_480GBx1 FP8 Latency
          ngcMetadata:
            88a14e8523e8747165e8574a84cee8c4a580af03ced367e74017bf4046835dd2:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e85188dc62e0c517a93bc24a32bee7b7f27b66fa0c6e3184813a4873369e413f
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x4-latency-bf16-gqr-l-hprg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x4 BF16 Latency
          ngcMetadata:
            8cc3eeb4f2ae763b36bf76a67ed42daea7b533852a65090b522440956de4f327:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3a0889dd10acf4050ccd4fbb878eb5c982c420e3a63df2a2fafaa9fc6c8cf861
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h100x4-latency-fp8-oxqturnvsg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100x4 FP8 Latency
          ngcMetadata:
            9078b6b41878fcfd7e5e9dca2ea0b5c5560d85d31e2cbb9e0e9801d2bb192bfe:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: cc434557f087f390d162cf972e61958ba9e9f09b6112e174e9824b7bcd92e6f4
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200_NVLx1 FP8 Throughput
          ngcMetadata:
            92adc0b1a36388246d3f037e68df053c83b4bfe4d23e1fae59f711e6e451b944:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0e974238d656d94cb79d39fcc0064f619e6606c678fcba61651358275c693e75
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-throughput-nvfp4-w75uvvawyq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x1 NVFP4 Throughput
          ngcMetadata:
            a92446d9168e5b10aabe4d31889c68b90503f2ee9bbefafa7b406ef1f2f2b92b:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c593287a9ac875b3a649fb7725a9f1a1e6816129291594a3783a556296bd8808
                number_of_gpus: '1'
                pp: '1'
                precision: nvfp4
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 41GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-latency-fp8-zkeshhnnug
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x2 FP8 Latency
          ngcMetadata:
            b483bd59b245ec47d9b700691316ed76163f1500d17dcd1fd1fc13ef4fa34dbd:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: daec3db3d904aa6cba1cecd2404867f81d44cf10bb16cc9c9f0ee9a19085bb68
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 69GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100_NVLx4 FP8 Latency
          ngcMetadata:
            b8a18b250c3bd00464dd5194016ecc81756f0121ebc070081bdb2de6dd715a91:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e741999618e5a4d94b595ff13d17028e5f11db1d5ed50644fd584d34d553198b
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_144GBx2 BF16 Throughput
          ngcMetadata:
            bab01e4b4d692d4d879a405cac30bc3830fb4bfed76deaff130bc989bbf70008:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 943e58ca6ffb929366337f69cfc2a49f55a062cb721159a094ae6ade370d2302
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:a10gx8-throughput-bf16-c6h2bujzqq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A10Gx8 BF16 Throughput
          ngcMetadata:
            bb0acd8d341492a58388d49010ebfd53ccf30e9ba61961e68853b7812bdd57d5:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 91af47c6a8cd2c59b5187b47bcb6c3feaef274f685067c0ba391f035ccf265eb
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 150GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_144GBx2 FP8 Latency
          ngcMetadata:
            c02d69cc0542152ece147e75cb33487d9058a83ac94866680455b56c075cede4:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 50fd91ee630703f0af954360b638c997fa7e69b60ed949c129e3ba042ed47b66
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h200x1-throughput-fp8-j-xwy-p6zg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            cb42798192666f9b621fb9a5aeecb342ae389bb6c8992183804aeed016fc1862:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0a504db21e8269006446b7b777218b5fc904fb8308dd5fbba24de96b577d289f
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GH200_144GBx2 FP8 Throughput
          ngcMetadata:
            d40298dbc0f90c12808e7e5becb22e47c284f05012c73dabb9818f03f461cd10:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ceebc0caeb9bdff847a148e0915219590cc463095bfb9545eb265978e4b8eb81
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A100_SXM4_40GBx8 BF16 Latency
          ngcMetadata:
            d847fc6b060db9381d38e6cb59ff183f29c6bb457c402d24c27971e59bad9bf7:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 35500bcc312a974be001478a0b1e2466fea9dac13d7bd087146f70d4c9e854c6
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-latency-fp8-f3rjvlafrw
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x1 FP8 Latency
          ngcMetadata:
            dbcdb5f1412398520d7330cb890aa57f1792596f7dc885cc65a1dc20d390cc9d:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a5a7e9799d92d3e8e2cb39c45acf73dee122f9f65c1bbeaf4eaf7d669745a89c
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-latency-bf16-jhyf9rlszq
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct L40Sx4 BF16 Latency
          ngcMetadata:
            e2b3ba60e795d306cf487ea71c8a5d128769f452eeffb54fada6697f031b556c:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3d65171e66e53a0c6b9d1253a09c393d917cb611ea6de85f7c7abadf7ea934b6
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H100_NVLx4 BF16 Latency
          ngcMetadata:
            e6fcaba4b0c11392cd4ce8e0eddc261fac45e994c7735c3d79734245aac1a68d:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: dbc58664a141b59a060de53a9e4f2d25b4ec41f75fcb791a0f046981b0634fad
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-throughput-fp8-trr9koy1vg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x1 FP8 Throughput
          ngcMetadata:
            e8e4c9317e3e32c8e50d3f4c54019b40df5608a319359ad9f8257d23f2348c2b:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: cb02e92359903bcfa274d5176c8a7a840e58a3df1587ca0f0c734049d4f1d5c8
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 68GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-throughput-bf16-gbt9zmjfla
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct B200x2 BF16 Throughput
          ngcMetadata:
            f078cbf33438ea9b68c5d4eba7bec671246d44730cbb0af6d94dfa1517bf3036:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4db4480cbfa2cd40a70ed784e3bb40e3e7e4d6693b7d275fb0b19b328ea1da0a
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:a10gx8-latency-bf16-mqqdeavnfg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct A10Gx8 BF16 Latency
          ngcMetadata:
            f49e065d985faa3a766163f386395cc53c64429754c58cf9edf553ac0ec96244:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9c2fce4ab72d829d5e3b008b9f6b64a608194a97ee6fc18af7863cf922226107
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 150GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 NVFP4 Latency
          ngcMetadata:
            f66f34808a8fe25ee8a3666427569f3e7119b1af54cd64e31d082282d5d47210:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d7ec938fb438f8d87c58707eb5a60af4e1fb6a9b7ac42eef6738dd9b0d2ff671
                number_of_gpus: '4'
                pp: '1'
                precision: nvfp4
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: NVFP4
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:h200x2-throughput-bf16-9iwul7vevg
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200x2 BF16 Throughput
          ngcMetadata:
            f6d98b286dd43d8a6e677a9a0f218e76928154490a908a2d9f76cbfd2cd043bf:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 583b7cb36984c4bff9e31b3f10937d34d488b2e4e32ac4b0ac5b44e02ef4779b
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 134GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 FP8 Latency
          ngcMetadata:
            f7397c4ee54cefd8fc3cc3b947406ba51947215d77ff58f35aeaa298605db13a:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ead7f13a4122bc78f9624682198bcccbc485345c9a58742601b0bf0e8ed59760
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct H200_NVLx2 BF16 Throughput
          ngcMetadata:
            fa4fbf5af52b66775f63d40cbc3db263304d7844095d1a677d799b8e90bf141b:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d2ae506c5cddf13a3d2f0139dcb6edafd042794999162e7d9623bd4ceabb1b70
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 263GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.1-70b-instruct:gb200x4-latency-bf16-3uozpudciw
          framework: TensorRT-LLM
          displayName: Llama 3.1 70B Instruct GB200x4 BF16 Latency
          ngcMetadata:
            fe20ab9158c65c3e7765e50c5c72ece46ee34a9e184dcdb13eda9bbef78ab300:
              model: meta/llama-3.1-70b-instruct
              release: 1.14.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e6a18cf6935b817ca2968d06e1abd91444d73634b80ff54f3680d152cadc209e
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.14.0
            - key: DOWNLOAD SIZE
              value: 138GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
  labels:
    - Llama
    - Meta
    - Text Generation
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: StarCoder2-7B
  displayName: StarCoder2-7B
  modelHubID: starcoder-2
  category: Language Model
  type: NGC
  description: StarCoder2-7B is a language model that can follow instructions, complete requests, and generate creative text formats.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: StarCoder2-7B
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/bigcode/containers/starcoder2-7b
      optimizationProfiles:
        - profileId: nim/bigcode/starcoder2-7b:h100x1-throughput-bf16-wqtdmrjeda
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H100x1 BF16 Throughput
          ngcMetadata:
            0f40318708a05837c5517a80f06974ff2c353c11bc6e04eb10baabe4436a7522:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7ffe6beb932b6f649191382b440a2ae6a18a3a7c1a883a5c47cb0de89b812266
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:h100x2-throughput-bf16-pag8ayfq7a
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H100x2 BF16 Throughput
          ngcMetadata:
            4753e2649bd3f25d4742969ccea5bb7e6ac2e469ebe811d194565decbb7c91d7:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6de32383a825dc6ff1128099c218896c3fa72b897e3ea0cd559ef2133b20d6c2
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:h100x2-latency-bf16-bcq-c0ggmw
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H100x2 BF16 Latency
          ngcMetadata:
            57280e7f84736bfd89a5fc38bc51f5ef6c0d92ed77ad66c60d897ccd7165ac98:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4f122733d53833b661fddc7ab39bb1b0c188779f2dd945241a7868b1e968dd1d
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:h200x1-throughput-bf16-yir1bzdhja
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H200x1 BF16 Throughput
          ngcMetadata:
            6f7097713b9a9c9e8553347ee7cf28f0c4c7c2bd913166dcb36c666ecc48dad1:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d1b221b1fd69a8f1b0dcd11b964dbf589518034edacf353953316bf9548f5de3
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:h200x2-latency-bf16-a8shrirgma
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H200x2 BF16 Latency
          ngcMetadata:
            70d88d7152538c95bc0dc059470e9f00656d8431c56ed11743d267c1dfccd433:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2758237c2bfa7e1f02183efb7432a82b677b8a29331fe65b97d8e09c2075b51e
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:h200x2-throughput-bf16-lspznbyceg
          framework: TensorRT-LLM
          displayName: Starcoder2 7B H200x2 BF16 Throughput
          ngcMetadata:
            e496963dfd535acf3104a4040e5d0b4a73ab564f0f1c583d3ad153a28200f266:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3e06b5f5b48d0b152e1a73bea3a346274e602f8d4ed0d3151ea215c3f9cbf8fc
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/bigcode/starcoder2-7b:hf-bb9afde
          framework: TensorRT-LLM
          displayName: Starcoder2 7B AnyGPUx1
          ngcMetadata:
            1d76bac39d2ca5f44c35735c615e4758bee6f6964c6db099577cb9000ecb6447:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 43ab4fbb30e1beedda3de8df4244c9fc44fb8fbd8ba0ac23b028abf822bbf637
                pp: '1'
                tp: '1'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/bigcode/starcoder2-7b:hf-bb9afde
          framework: TensorRT-LLM
          displayName: Starcoder2 7B AnyGPUx2
          ngcMetadata:
            ef596a550ec0d61b427e3f7ff26fd21d49b5b1caff72b5bc8f3a5affc2a1d7b9:
              model: bigcode/starcoder2-7b
              release: 1.14.1
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 43ab4fbb30e1beedda3de8df4244c9fc44fb8fbd8ba0ac23b028abf822bbf637
                pp: '1'
                tp: '2'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.14.1
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
  labels:
    - bigCode
    - StarCoder
    - "Code Generation"
    - "Text Generation"
    - "Multilingual support"
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Mistral Instruct
  displayName: Mistral Instruct
  modelHubID: mistral-instruct
  category: Text Generation
  type: NGC
  description: Mistral Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. The Mistral Instract Large Language Model (LLM) is an instruct fine-tuned version of the Mistral.
  modelVariants:
    - variantId: Mistral 7B Instruct
      displayName: Mistral 7B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mistral-7b-instruct-v0.3
      optimizationProfiles:
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200_NVLx1 BF16 Throughput
          ngcMetadata:
            090aed9ae0f4312f525a15003626f36dd30aded5cabb5bfd580cfb88510f7175:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 713cc9e4be3d70c5a99ac45e46c5cd2cb271b5c16228561f1daf992f8feac8ff
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x2-latency-fp8-6ewdxacbyg
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GB200x2 FP8 Latency
          ngcMetadata:
            0c430e8114b7d75876e040eb9e57f94f8780339c06d2afd7d52b8b520fe7d002:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 783069b3e78233c4649dfbd4031e5e32109f7eda1e54e623f39afa6771f69812
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx2-latency-fp8-werjmjtilg
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 L40Sx2 FP8 Latency
          ngcMetadata:
            0dd2f4179304094d417e6326812f71bf5583853f655c71d2992893485208b6c4:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f8c9fdd309012b470e249367853869bb7c38c8adf82866e2e1f02b6ffabc6429
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200_NVLx2 BF16 Latency
          ngcMetadata:
            1c8d8380b88e5e0b9dfa9bd7d9808e7b44533516e015e085121a17bec9f2803a:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9a8267f26d4614a846205cc91d2282acd830762361507abc23e58dfe78cd412c
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x2-latency-fp8-nnktn87ayw
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200x2 FP8 Latency
          ngcMetadata:
            1d71ecae305c2a01b823eac3cac374e0cf882795349b7c9aa045363c82f331a3:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6edfcc1e5567c57e834b36011decd5d2efb559be351273b2ad7c8768bae66e39
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 BF16 Latency
          ngcMetadata:
            21d116fd5db9b38ae613c9ec2117e796e0aeec6d8f24e92928ca1171b5f0db8a:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c78a84fee0362ed61ba62a668240cb6619c459e8c105ba274e13c186512f846d
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x1-throughput-bf16-fii9d12dng
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200x1 BF16 Throughput
          ngcMetadata:
            240f8bb29f20bd7b6f3a76367e82c2182d6f626ac3ac800daac124d6cdce1be6:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9190e11b1ecbdeb46a92c026ca480103519885a8f07638f6d4a21d27a9118141
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A100_SXM4_40GBx2 BF16 Latency
          ngcMetadata:
            31f3565f323b25fb739b4319a054db75e52ad21e1e3adb93de0b7f932de6e954:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b84730aefe89d65c679b93ea096271ba583373eca30f081c680bed7dcff8f7c1
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x1-throughput-bf16-p8aaj1ui3a
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100x1 BF16 Throughput
          ngcMetadata:
            37fe5e59120c01002604cd395d38f91f3c71808c9a76060d772ee8625db8a9aa:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 43b0efb1c318ab00e8740ac496ec18fd55db1d3f50a9c9470408fd5b647ccb0e
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 BF16 Throughput
          ngcMetadata:
            3822e73f5b87aab36b8fa7f67f06b027ee79f259d4a6f6149d6e6e8834e15694:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 99355664e85deab8cef6bcda9b64b62eae3e6cb4fb72654992701318971d9cab
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 BF16 Latency
          ngcMetadata:
            3929f189d9fe09ced84378d555047f329e9b5d22ea05a84dfc27bf4e423ab2ab:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a01faf2c27412adcdcc908764085b24d58398d230a42ecc86b4d0241886d55b6
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            3d2e4a566abec5fdab7016cf1ee4b9f0a28c0bbaf1ab5ba1fbcb739b9fbbfab6:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: dcbbb88340365f3a3ce5006101441492476ef83235d14fb9d2eaf245868f6e51
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx1-throughput-bf16-wgortubrfa
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 L40Sx1 BF16 Throughput
          ngcMetadata:
            3d97e245329239baeda4299616d3379ddbea98f0f30a9fb6a0f97ff3bb593593:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 59b129434dc4805de4e69fc1e786327abcad095b67e099df18a0741700fc3562
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x2-latency-bf16-k0zyvwltfq
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 B200x2 BF16 Latency
          ngcMetadata:
            4369fb715f1d8a01cec62d750cbea038af0b5f5f032a372236fe6cb7ecaad891:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b41d026216b5cc343dc386982bc593595899581dd03e2e608bc13a7d7fe1fb71
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100_NVLx1 FP8 Throughput
          ngcMetadata:
            4c9a845c4a8037390a5d87a8e2db4a9ef8c7cc5c5e613960b771adce3e548deb:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 00ae490b209e488c85835da5990d77b81c03bd111838c6ab188f5b3c1084f5f0
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x2-latency-bf16-wkgtx84w0q
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GB200x2 BF16 Latency
          ngcMetadata:
            514f55258d4cffc08411144a8709add1d6dfda7563894feee671bad11a2be79c:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 054261eb6e99db9b73dd8ff0146b8748e4676c27344512bb070ffd471c54002d
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100_NVLx2 FP8 Latency
          ngcMetadata:
            5165a3e3a29e9d6717869d3960133151f93437c8c34a297c2b6080763bfdcf32:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 20bd7371c735a556fea27dd89285a4bc2bb8cc5630c912da7ba9bdfd4fe0f149
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x1-throughput-bf16-bzgxd7omcg
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 B200x1 BF16 Throughput
          ngcMetadata:
            5a9eef29a1519f40178baec3444a0133990c5ed49ebd6e0ee5de5391f403c25f:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 99677dd60c3849da7d5daab13e7094c8f15c1ed0b324691dcfeb07c340748155
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x1-throughput-fp8-1kujysl0bw
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 B200x1 FP8 Throughput
          ngcMetadata:
            61a13f62e79b27cd7c69c32477b58857196ccc914a1b9f526fb9715238ceaddd:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f9ef3850321d85a46a3267f358c73bc62479d5fd3bd077bfbaa54968926284ab
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 FP8 Latency
          ngcMetadata:
            6bdad363d842f0dc7b89c0bcdbfce49ab7ff3c77a7f1aaf741e10b5a8cfc7b65:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 05684b1b6aeb72f02bd8422d6f4bd2c193e2409465575f3b01fd7fe0ca606056
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 BF16 Latency
          ngcMetadata:
            6e083975f86a7bd245f26d412ca4c0d99bed4a05e85eb516c7bf23d4a8dbc635:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 01c793b12ef404fe8d3d97f17a5851e07af0ce3e1ed7028940203e38020cff5b
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 FP8 Throughput
          ngcMetadata:
            6f9107642dc7198eb0084ba462da560fe696b28a74dc9bd5747f58b2229c0833:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 60a40aa9dddaddacb1f4f7ebbb536b33494d4a252b563fb321152125c6e5be1d
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a10gx1-throughput-bf16-dbarntjrxg
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A10Gx1 BF16 Throughput
          ngcMetadata:
            8aff3c4c1c985c1ab4bd362202c194479652465f22c634e79fead9f935d9f308:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e936f5f6f910166d5a160a10cd1a565e15bac32bd77cdf527f23a97e9a792622
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a100x1-throughput-bf16-ug2ytdn9rq
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A100x1 BF16 Throughput
          ngcMetadata:
            8d844ff4c978b716fb1b3044d4663305081e95fe9e3281ccbc60ebd243137939:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 52c07121ddb1886588c745606458ef1289c479b94c2e1d77b8260c89cb5e40ce
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200_NVLx1 FP8 Throughput
          ngcMetadata:
            8e60a02116ccc9ed3587946a5b2ad0c431826d89e36be714dfa92044e84579de:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e395395c3d17874ecbc16978f25f851e3a8e4b08e6f107f8d1e00dc1f485aad2
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100_NVLx1 BF16 Throughput
          ngcMetadata:
            8f1c5ed6338e2517b1db9987ca4a9cab78ad17acca14801eb301cd52fb60a4e2:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7b2c3bc5c67da0408b365dcde48b64e5ac4c4b316e7061e4da026d8ebfa23c60
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 BF16 Throughput
          ngcMetadata:
            a049a483413cc9fcf09502fb199582de0948a105c7d58ed41023f74fcf46a84a:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6fd41902191734a0e6c6105beef1c9eaec18a21786868ec1f5cf9876f924709f
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x2-latency-bf16-utfzkvbx7q
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200x2 BF16 Latency
          ngcMetadata:
            a2bd430ddfc5a8063daef926241911c1db8503f6b24034483213620ea0d6534c:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: fb34a1eb2c580f06657b13b17ed3fdcebd849fce79f29c090d58c8798bf18df0
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x1-throughput-fp8-3zk3rahgzq
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100x1 FP8 Throughput
          ngcMetadata:
            a91be3d64f314c006fa8f85baacd7a54eda8be911ac8ab66cca6b02044de16a8:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6f2d35f77b6e720ee0f8c950a138b31d739efd3c69094c0d830c7a6e1657575b
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx1-throughput-fp8-kegtu7-f8w
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 L40Sx1 FP8 Throughput
          ngcMetadata:
            a9776f67cf10b8456cb9c6a3cc657310cf6b402b482f75294f89a832813e585d:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a002dbee023af5c15de8bd132e0ad771081f285acdb4196fc77df8e2d5025bf7
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a10gx2-latency-bf16-ultpn-z0fa
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A10Gx2 BF16 Latency
          ngcMetadata:
            b75e85db64643ec2a6fe296828296b6fb2971998445181b3e92bb4edb7028f9c:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2d647a36531389075e6d579d0e030fcaeb428ec3056fdf12e56ad673c99c3e9d
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A100_SXM4_40GBx1 BF16 Throughput
          ngcMetadata:
            c30c03b6c527e5bbc13c9024db7888bd3ef1f81f5437dd5eeb639963e7f956c0:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 1b85347f49cd97c7a43491a4065364128a860973559d1fbb418436cf1d22071f
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 FP8 Latency
          ngcMetadata:
            c5440e61e502d2bde9d8182735ec4b3cb5dc07386768b22e3fd11afb8f9123e1:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c1481c7a0c16fafd6097a18868e47f96bdb3e9bfef14223ed63d4c58b0b41046
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 FP8 Latency
          ngcMetadata:
            c6298bc319a27d0b8ce68b6ff2ee478f4503a532f85281db4e58e09bdc1e828d:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: bb8fc0519d6e093698164f6283010687e2acf7b28c240faeebcb9f6d04f3bdfd
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a100x2-latency-bf16-eao98qqyaq
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 A100x2 BF16 Latency
          ngcMetadata:
            cffacd84594ea7bf5f03f8eaaa107d0e6078dadf84c2b8919c53ecc44ec0a418:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 31efbfeecc0071b15073a663036ed7854fe34edad643248b0b33f1648d396528
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x1-throughput-bf16-b7lzpmozrg
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GB200x1 BF16 Throughput
          ngcMetadata:
            d3e771cdfdccfc6685afb1749f581cbd723b3f4a7180453c366e49fe02201035:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 36332f865d9e636409ef1d780e1e129a7958c56612e251e991090198a71ecca2
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x2-latency-fp8-ubwp9icmag
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100x2 FP8 Latency
          ngcMetadata:
            d4d4737e0a2b76a1409c12d66a70924643f1bfca7448ca7bb9deb7a25f449470:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 5a148e8d8559629ab65b636a3344bd0a6c9d5ea1e7974bcdc5eb9273bc0c3aec
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x2-latency-fp8-dmol-yoeqa
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 B200x2 FP8 Latency
          ngcMetadata:
            d772d81834faf0d0f3021ff92ea6893131a28c7b1eacedff9586b5304c768e16:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d21056b60d5e01083565a8671683b54e86879aa36a36475318838deec4613666
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            e2392b25430a3f1fcec000a51661f633d36450438db8b09765dffaced7fac7e7:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 5ae57ff46795ac07b5bb351fafc5f767a4c62e864a2c283d982e92c8d82273e8
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 BF16 Throughput
          ngcMetadata:
            e2698f06fe02b17f4ac157fb39bd9ae75282d96e0a618c96ca9472a04bd3679b:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e8b647653354c51429e61400d7e38ea59531989d0808b570fa5755b7d6bfe130
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200_NVLx2 FP8 Latency
          ngcMetadata:
            e7014f30a669dca5d114ee37df6385a5453b02a23614832ef7bdb0e7f1622d11:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 43c16ff7a8e64039006342b0ba5d0067d7b3e49f7a913f06e67128585266aa67
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx2-latency-bf16--dooucx8xw
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 L40Sx2 BF16 Latency
          ngcMetadata:
            e93d09fc66b8e716a8370d431143b6d5efa1ab47a3aed691907d3c3d8d85bd4d:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ee18ec1b20cc3bbaff5d95b5e157c2d8ab9dc856df258de26b73ff6ec8e9f98d
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x2-latency-bf16-y5oxwbaufw
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100x2 BF16 Latency
          ngcMetadata:
            f01bf801094b032f87027566ae9036ac0489547a3a650a93bf7af4e12d7975c8:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 87eccccb3d5001d66e004f0e0bd2e26e245774007035b6d3c9a01f120c5d5f02
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 14GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x1-throughput-fp8-ndgj2enqyq
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 GB200x1 FP8 Throughput
          ngcMetadata:
            f76535fba1856c95ce15f11a3228fcb0469242f4921644d94fa682220c518c3f:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c0ef6863d68dbd3c3fdb7f3a0e8f2da9daf77c94757f228736a335de4a1ae628
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H100_NVLx2 BF16 Latency
          ngcMetadata:
            f97a97adc7e9ca1ae225535ac8949af0f306846b429f079946fcc43cf0346f20:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 620affc99411e713b97069819f83de5bb626bf16dcb1d064492ad50dfc9641b7
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 28GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x1-throughput-fp8-ez1figc57w
          framework: TensorRT-LLM
          displayName: Mistral 7B Instruct V0.3 H200x1 FP8 Throughput
          ngcMetadata:
            fd130b01c59445a3967c804d57077fd77a3b2f76048603516402320f809f88ad:
              model: mistralai/mistral-7b-instruct-v0.3
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f830f542f5a36acc42ddf3d7f7823662ed361c4e8e0ee0007cfe70da3df2fb9f
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
  labels:
    - Mistral
    - Instruct
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: Mistral
  license: NVIDIA AI Foundation Models Community License
- name: Mixtral Instruct
  displayName: Mixtral Instruct
  modelHubID: mixtral-instruct
  category: Text Generation
  type: NGC
  description: The Mixtral Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts model. Mixtral Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. The Mixtral Instruct Large Language Model (LLM) is an instruct fine-tuned version of the Mixtral.
  modelVariants:
    - variantId: Mixtral 8x7B Instruct
      displayName: Mixtral 8x7B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mixtral-8x7b-instruct-v01
      optimizationProfiles:
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:a100x2-throughput-bf16-s69xvudfza
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 A100x2 BF16 Throughput
          ngcMetadata:
            0db3b5e8468c9debf30bcf41cbfea084adc59000885efd6fdcb3bbb902651bd6:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h100x2-throughput-bf16-zwhl2fsi5a
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100x2 BF16 Throughput
          ngcMetadata:
            1617d074ce252f66e96d5f0e331fa5c6cc0a0330519e56b5c66c60eb7d7bf4f9:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100_NVLx4 BF16 Latency
          ngcMetadata:
            28552abdb2c491d46065d52ca1dc1265b99ba95a5bf8daaee4c5de12511a3b4f:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:l40sx4-throughput-fp8-hbavqk65yw
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 L40Sx4 FP8 Throughput
          ngcMetadata:
            3d0e5989f2fbc23e7d4504cd69269c9636deb61d0efc12225d3d59d54afea297:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 45GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h200x1-throughput-bf16-00qqbltmrg
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H200x1 BF16 Throughput
          ngcMetadata:
            434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:b200x2-latency-fp8-pwnesuqgxg
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 B200x2 FP8 Latency
          ngcMetadata:
            4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100_NVLx1 FP8 Throughput
          ngcMetadata:
            5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h200x2-latency-bf16-uh6awyzpta
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H200x2 BF16 Latency
          ngcMetadata:
            6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 A100_SXM4_40GBx4 BF16 Throughput
          ngcMetadata:
            6c29727e6e3d48a900c348c1fab181dc40bc926be07b06ca5b8eae42a6bc9901:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h100x2-latency-fp8-4-l0a-rlkq
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100x2 FP8 Latency
          ngcMetadata:
            6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h100x4-latency-bf16-axe5ogfgvq
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100x4 BF16 Latency
          ngcMetadata:
            73f41fabbb60beb5b05ab21c8dcce5c277d99bcabec31abf46a0194d0dd18d04:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h100x1-throughput-fp8-j1x74k--ng
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100x1 FP8 Throughput
          ngcMetadata:
            7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:l40sx4-latency-bf16-qavtgypi5w
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 L40Sx4 BF16 Latency
          ngcMetadata:
            844ebe2b42df8de8ce66cbb6ecf43f90858ea7efc14ddf020cf1ae7450ae0c33:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 A100_SXM4_40GBx8 BF16 Latency
          ngcMetadata:
            8a446393aaeb0065ee584748c7c03522389921a11ff2bd8cb5800e06a8644eb0:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:b200x1-throughput-fp8-ult1akfaqa
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 B200x1 FP8 Throughput
          ngcMetadata:
            8b87146e39b0305ae1d73bc053564d1b4b4c565f81aa5abe3e84385544ca9b60:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:a10gx8-throughput-bf16-jxekvgjfha
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 A10Gx8 BF16 Throughput
          ngcMetadata:
            935ec3ac922bf54106311dfc6b3214a1651a26033b4f5007b6351fffb4058b7a:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 90GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100_NVLx2 FP8 Latency
          ngcMetadata:
            a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:b200x1-throughput-bf16-ftwmzofxbq
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 B200x1 BF16 Throughput
          ngcMetadata:
            a4c63a91bccf635b570ddb6d14eeb6e7d0acb2389712892b08d21fad2ceaee38:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:l40sx4-throughput-bf16-d9jierrahq
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 L40Sx4 BF16 Throughput
          ngcMetadata:
            ab8f2faec3bcafc32efaf05acada4df4d8a171a759b4fb5c44d2d9d43a348764:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H100_NVLx2 BF16 Throughput
          ngcMetadata:
            acd73fcee9d91ada305118080138fb3ca4d255adee3312acda38c4487daae476:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h200x1-throughput-fp8-skjppy5-iw
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H200x1 FP8 Throughput
          ngcMetadata:
            af876a179190d1832143f8b4f4a71f640f3df07b0503259cedee3e3a8363aa96:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:l40sx4-latency-fp8-vmkcxgu3fw
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 L40Sx4 FP8 Latency
          ngcMetadata:
            bdd0d3cd53fad1130259beea81ab5711fb98f2f1a020b5b26c3c82fd7d43c5af:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 45GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:a100x4-latency-bf16-yphkz2bivw
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 A100x4 BF16 Latency
          ngcMetadata:
            d73b7cf2f719d720329fc65fc255ae901bc3beebdc59be9815ede1a07948c1f7:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:h200x2-latency-fp8-skwo6uxqkq
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 H200x2 FP8 Latency
          ngcMetadata:
            e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 44GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:b200x2-latency-bf16-qkpte3pb7w
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 B200x2 BF16 Latency
          ngcMetadata:
            f44768c625db71a327cf17e750d5e1a8e60171a8d8ef6b4c1c4b57fe74c9bf46:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 88GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 AnyGPUx8 BF16
          ngcMetadata:
            1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '8'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 8
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 AnyGPUx2 BF16
          ngcMetadata:
            375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '2'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
        - profileId: nim/mistralai/mixtral-8x7b-instruct-v01:hf-a60832c-0508-tool-use-v2
          framework: TensorRT-LLM
          displayName: Mixtral 8x7b Instruct V0.1 AnyGPUx4 BF16
          ngcMetadata:
            54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
              model: mistralai/mixtral-8x7b-instruct-v0.1
              release: 1.8.4
              tags:
                feat_lora: 'false'
                llm_engine: tensorrt_llm
                pp: '1'
                precision: bf16
                tp: '4'
                trtllm_buildable: 'true'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 4
            - key: NIM VERSION
              value: 1.8.4
            - key: DOWNLOAD SIZE
              value: 87GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
            - key: TRTLLM BUILDABLE
              value: 'TRUE'
  labels:
    - Mistral
    - Instruct
    - Large Language Model
    - TensorRT-LLM
    - Language Generation
    - NeMo
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: mistral
  license: NVIDIA AI Foundation Models Community License
- name: Deepseek R1 Distill Llama
  displayName: Deepseek R1 Distill Llama
  modelHubID: deepseek-r1-distill-llama
  category: Chat Assistant
  type: NGC
  description: The DeepSeek-R1-Distill-Llama-70B NIM simplifies the deployment of a distilled version of the DeepSeek-R1 series, built upon the Llama3.3-70B-Instruct architecture. This model is designed to deliver efficient performance for reasoning, math, and code tasks while maintaining high accuracy. By distilling knowledge from the larger DeepSeek-R1 model, it provides state-of-the-art performance with reduced computational requirements.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Deepseek R1 Distill Llama 70b
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/deepseek-ai/containers/deepseek-r1-distill-llama-70b
      optimizationProfiles:
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:l40sx4-throughput-fp8-46u3lvp6ja
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B L40Sx4 FP8 Throughput
          ngcMetadata:
            23c28e4a1ad4d963c1504f1a33b45afb65bf61b64b20be1a8ea2c8816ea0fc36:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 69GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:h100x4-latency-fp8-k5tlofelyw
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B H100x4 FP8 Latency
          ngcMetadata:
            4696d5c5b44b13bb5e864affcdcfa30ad229390285476315d9921fd0828bda5b:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 69GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:h100x8-latency-fp8-xz3eymtuzq
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B H100x8 FP8 Latency
          ngcMetadata:
            91f2b7c9e719c0c380ba6c1d6c3e5cad61aaf807730de88fa3b6233a39edeeaa:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '8'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 70GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:h100x2-throughput-fp8-8cx2penaia
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B H100x2 FP8 Throughput
          ngcMetadata:
            da94a5c34cf665e85813fa49f321f1e87ca12317722b5e65628cf3ed0371897b:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 69GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:h100x4-throughput-bf16-g31fj2uvrw
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B H100x4 BF16 Throughput
          ngcMetadata:
            e6b8fb8c4c76343b05b9051974593e5bd9110a868770d52e8eb0fe5a3b46dd67:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 138GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-70b:h100x8-latency-bf16-v8q6jmcd9g
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 70B H100x8 BF16 Latency
          ngcMetadata:
            f87605b6d8cfc0ca39fad21b4ec580219f3a3be42884d2c7caad9b8ae4b3c1c7:
              model: deepseek-r1-distill-llama-70b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '8'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '8'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 8
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 147GB
    - variantId: Deepseek R1 Distill Llama 8b
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/deepseek-ai/containers/deepseek-r1-distill-llama-8b
      optimizationProfiles:
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:l40sx1-throughput-fp8-vbqc0btoqg
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B L40Sx1 FP8 Throughput
          ngcMetadata:
            d968c663c710e56275088096bc0dcf823560aaf7dca910bfcb41f5056063ab02:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:h100x1-throughput-fp8-d9grrq-lka
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B H100x1 FP8 Throughput
          ngcMetadata:
            0bdec027404c16d6ca96e159079082f9630a24a277ff519d0c8fea71007222ec:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:h100x2-latency-bf16-7ztok5r0dg
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B H100x2 BF16 Latency
          ngcMetadata:
            0ce355335e6c3aec54e49ab53822e628fa1227091d0326da962bcc4f95b5f602:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:a10gx4-latency-bf16-aiejrysrlw
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B A10Gx4 BF16 Latency
          ngcMetadata:
            1dfac8e12042573dc93536a393902478e1a6a46d1cd742cf0a4251c11f77e253:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '4'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '4'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 4
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 19GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:l40sx2-latency-fp8-fmuoxfbb0q
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B L40Sx2 FP8 Latency
          ngcMetadata:
            c2d4efce2d553c3aa78109b6d5dff0fd34b86bbb3b765aa8afdf12e9d13e8e83:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:h100x1-throughput-bf16-4jcstzx27q
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B H100x1 BF16 Throughput
          ngcMetadata:
            4f6dba657c08280bdb419cbc1c60d265e82731b807ee2ae3c111cb9a91571aa1:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:h100x2-latency-fp8-q8xwzp22aa
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B H100x2 FP8 Latency
          ngcMetadata:
            518edac01f731b63676743a1860fe21861d1399b19cb2e584de3d9a6a3ea6d8e:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 9GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:l40sx1-throughput-bf16-yvbnwvfzew
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B L40Sx1 BF16 Throughput
          ngcMetadata:
            9bc8e8aa12847674fa2840b9c03cbdb0246d7f144a5257510fd53eacc2a9d62f:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:a100x1-throughput-bf16-iq9maz9nkw
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B A100x1 BF16 Throughput
          ngcMetadata:
            c959aa89b69ad9295ccc99a34546819d16bb0e2566a6cfed0985eecf37bcc14b:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 16GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:l40sx2-latency-bf16-tlmx3sgrdw
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B L40Sx2 BF16 Latency
          ngcMetadata:
            20d6bb61a1ee5160c0baed3721f8b580525a0aaaaa3b1333e9a882d4c61b1ed7:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 17GB
        - profileId: nim/deepseek-ai/deepseek-r1-distill-llama-8b:a10gx2-throughput-bf16-uv8ptkf8-g
          framework: TensorRT-LLM
          displayName: Deepseek R1 Distill Llama 8B A10Gx2 BF16 Throughput
          ngcMetadata:
            edbb37d3ef94a5cc38919ab86694b835307c0668ca6d41ea746796b34ced78f1:
              model: deepseek-ai/deepseek-r1-distill-llama-8b
              release: 1.5.2
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.5.2
            - key: DOWNLOAD SIZE
              value: 17GB
  labels:
    - Deepseek
    - Distill
    - Llama
    - Meta
    - Chat
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.2 Instruct
  displayName: Llama 3.2 Instruct
  modelHubID: llama-3.2-instruct
  category: Commercial and Research
  type: NGC
  description: The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pre-trained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3_2/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3_2/license/
  modelVariants:
    - variantId: Llama 3.2 1B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_2-1b-instruct
      optimizationProfiles:
        - profileId: nim/meta/llama-3.2-1b-instruct:b200x1-throughput-bf16-olbx5u2wza
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct B200x1 BF16 Throughput
          ngcMetadata:
            00974a79b608dd9dc2e302879e71708692c9c6304f5905eb4da7d661dadd6ec2:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3190e2309f20a42f1888add452d98f204147634d83e7e5a7bbb401f9e898de2e
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h100x1-throughput-bf16-coy0mruniw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100x1 BF16 Throughput
          ngcMetadata:
            023958aa70e985eb0a0d25c60d7a03732ad5ee7d4f9ac2ebcce17397b172b58c:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 4ba0b194b524b5d78bfa90c76ad9789b54069996b45beca9ce05762a295d871a
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-fp8-q4ene2avnw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            0b900e8d26b11d548f74a903739434bf00fc990439a9245042e344d253481719:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: b771a0a1bf21ee92364a0f1c9db64628d74919517edf09f47b079aab90af963e
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:a10gx1-throughput-bf16-wmuh1shq9q
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A10Gx1 BF16 Throughput
          ngcMetadata:
            0f7eb9e9a9b4470a7b5b6e93b806ad27ff49b1a94c30aa2986ffaf281f6e8d1f:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e28f4aa923af93efab6e6c14dceae117980f3f805e47f871464af69ea1457946
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 BF16 Latency
          ngcMetadata:
            0f87e0f30087419b3a4a74d7902753a6daee998e59c0676d412fefe141f62ffe:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 6582d9bebeaaa8b1cc21b6a10cdde0daf92a198e7f9950b21908a77a90d47c3e
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100_NVLx1 BF16 Throughput
          ngcMetadata:
            0f94ccdaf02fa00a986ba3b2b8ff0351ffa73fe262176e89830445ad81b6bfbc:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 92f394e8f167dca76b9c8eb40b8a09edd896b6fd6ec126ba5609a9c90cc21f59
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_144GBx1 FP8 Latency
          ngcMetadata:
            129db5959331b4c24cae55957a8bef7cce73fcc7571001fe18556c9b691db5d8:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 11d5467289919d18be03dbdd3236e1d2b1fdf81681b52167fadc2af453e8f6ea
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:l40sx1-throughput-bf16-mr-zfjdk9w
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct L40Sx1 BF16 Throughput
          ngcMetadata:
            13d24e5a873aea5df261998c94710c6d00b59074f8389143d94a370762569bf8:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 72a4b35de823e2ba47bc9bac68b3704d0a9eae3db2037458d70d813809c6af78
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 FP8 Latency
          ngcMetadata:
            14389e34e76649cff246559bc0374718143cb5ac1286f7a53f6e0314c70b004b:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 2493505e4182b1596bf60600e22bae9fd94056b3988e591bceace38117523d26
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 BF16 Throughput
          ngcMetadata:
            1d76561dbe108226813651f3fd70416295040612f0cf3c36fd330fc388d9ef60:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 8d4e43ad080af609d17f7c559a838f1e46da4a990bfbee068d540601847951e5
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200_NVLx1 FP8 Throughput
          ngcMetadata:
            280bfbbbf4ea6e6744b706d25032054ad18289814406f251d9f862b044c51c67:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 50ad558f72f96fb5171036046bfaab28fc9eb1157e31488c5da2c3ab0134c020
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200_NVLx1 BF16 Throughput
          ngcMetadata:
            2d1a186f55c204c95b4abd9df2056e3095b148700cd8fdda115ffe7bea3bed60:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 940e6e9a959cdd8829c9cba449c1c8bc83ef2522ce1f263cbc7e1920399fe465
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100_NVLx1 FP8 Throughput
          ngcMetadata:
            2e2ecec7b2d03c998a8bae64e150a5f88bfde56917d372dc91ffc08f94c9d07f:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9fb78395ea4e775bdbf7c8df874ee89b4e084d35fd3ee6f8b105ec6061e8d887
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200_NVLx2 FP8 Latency
          ngcMetadata:
            2e92e2be673e48b2312076393db8caff10c7dae24bf90cd1637b197fe2dda0f2:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: ba433d54af67e3a0d72db4a896acb2e92ba9caa41d731086c34d9e77df019c7d
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:a100x2-latency-bf16-ezdh3qtgsw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A100x2 BF16 Latency
          ngcMetadata:
            345837de17bc4e103174352bc07a86112cef00318470e5477afb24908d09abb6:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f517db32f12098356f9ef902992f57d5362a4e58a8d185c993cc93657f18a3cb
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:a10gx2-latency-bf16-sdcegxqefa
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A10Gx2 BF16 Latency
          ngcMetadata:
            41eb6cd432c8d498926942101511e4da1e913d0d22adbc96ed547a8042d2b7ce:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 071daef17e33c140ef8b82b89004ed3d5412e3eca9b4bedb8b57824dc05e975c
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A100_SXM4_40GBx2 BF16 Latency
          ngcMetadata:
            43a51be16bada864c0ab6acc3e267e333fe69150a05287d5386e7cb39c7c61bb:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 04ee232eb94574469d111ff8001c42836ee881f67fbf9040fbdc582e6b1b1c42
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_144GBx1 BF16 Latency
          ngcMetadata:
            4843f0f1c0b0b410cbc37dbb748396f2793b0eb5ed8ad9f215e06da1e82b98e8:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 736c2ad1750f0504768fb31d97587a07cc473517c232e8454f098e63c0f5de5c
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A100_SXM4_40GBx1 BF16 Throughput
          ngcMetadata:
            4acbbc32a700f17dd483e6a53914ec62688d029120fb0c216420e8481983d0e7:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 10849901781866ddf59b10df9f42464a7c089c5f0a61f41f6b25862f19195a7b
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:l40sx2-latency-fp8-uvobdo54ig
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct L40Sx2 FP8 Latency
          ngcMetadata:
            55be74aa57225eb45db56bda45a2e1ad7a02f8f30d5f8eef9877df8adacc0550:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 0669a60d949ab85b17b5f2a73d7e9f6b131797740da6ed43e29e5f41066d571c
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-fp8--yymwnqgka
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x2 FP8 Latency
          ngcMetadata:
            58db8acdee23b42a43f731e5e6e7d123ff889d70318dd876d8325bfdd9d52023:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d9bafa9974769a2f7539affd5e55acef006ce62c15bc088dc3a55afd818ee124
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:gb200x1-throughput-bf16-zyj-crhkzq
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GB200x1 BF16 Throughput
          ngcMetadata:
            59619a192c8ef4c65e8363642f722508401f1392f64fd007337abb01ecbe7d19:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 35decffe402ab43b965bedff55c8cef9addc05e917187701562af2f4fe213de9
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-bf16-tsa8sfptpw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x1 BF16 Throughput
          ngcMetadata:
            61555d7be4e6de25c9219d7a0bb106d40ce887b31f29ea8df4fee6110e2b853b:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 9b5fee25e36a210bec2865d4ebd5c974a8cf4e4002efacd9ec516642370cbd9c
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:b200x1-throughput-fp8-ys-xbyv-sg
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct B200x1 FP8 Throughput
          ngcMetadata:
            6d0ee85cf622a72848fc5daa170614ce7fcec7167fe53d718878f08eb24cb965:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 5c56717955f737f260b918572f35036dee10c1b54530f4096fa66af19b17ffd5
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            700827bec7ac9724fe295b4bdde657eff97c34de54f3ad504fabfe32e12e3e18:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 8e95c5073de6fd99ffce7014cc733fe55fa894162cfec8c938756de81fa8ecac
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200_NVLx2 BF16 Latency
          ngcMetadata:
            70089c0e01ba82698bed7ab932bafebc141455e40bd15567f7e37496ac7bcf1e:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200_NVL
                gpu_device: 233b:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 3575e95e2064a522faa33fa6dbf9a6c3eddbee6bcf286d0c44315142c402b089
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-bf16-itm2i3hlig
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x2 BF16 Latency
          ngcMetadata:
            7c29442049d0390525e51aaf5d3d3ac7c676bf7222707b7ed29442e2a95227c5:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: f987c70ae752902a0fb500d8f378afd65fc5b47b5eeb88627004b0edb210bcd8
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct RTX6000_BLACKWELL_SVx1 FP8 Throughput
          ngcMetadata:
            85eeb431dec2e7ce1aff645c1e1e08d0a42a644f64874c68a65fd4e07189b902:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: RTX6000_BLACKWELL_SV
                gpu_device: 2bb5:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: d76814b2d2442f8ad709563f653ed4b80e39f5ad1acbd0b84822235fe4e3d1a4
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_BLACKWELL_SV
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:l40sx1-throughput-fp8-wocwu5pweq
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct L40Sx1 FP8 Throughput
          ngcMetadata:
            894221e5032dfb82de8567266ea22114b8597aabc85b93e92ad290508ecd33bf:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 13f1a9e953c8a5320111dc8a580cd3855291326abe1d1e5b5c7dfced9cb6f6ea
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:a100x1-throughput-bf16-dohmk4psfa
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct A100x1 BF16 Throughput
          ngcMetadata:
            8b22a466a5ef2f848151ea4679201cf4f7fe7ebd7094671cfa3df7a25836b4ff:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: c83a64076a4cecd2c6d8d55db86ba5d0b31395c28ab806962828aa291c192b33
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:gb200x2-latency-bf16-2w1oa3-9bw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GB200x2 BF16 Latency
          ngcMetadata:
            930b33fdac9c955b3149d675d262d286f7e4db61503e9c9de17aa18dfe092238:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: e8d3089f177a1641f3b610799a19a3a4c752e1795eca7be92a129e9bae5cbc39
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_480GBx1 BF16 Throughput
          ngcMetadata:
            a416c249ee8f78d2790919c1d5e6f3afa3be9d85f3e77cd635e65335caae4ddb:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: cafc299ec54dd11d527965baac566347feccd9dad56d5a89cfb4e710e56b8b2c
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x1-throughput-fp8-b62hkfmx2a
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            a6780e332aeb2c67ff491b2b1d13f04c58c238bc07bad39af5b0c552d6e3dfae:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7ccea195195ee0642c6785c8d5aa7ab8976737fc4f80f2966f5dcf7c8333391d
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:gb200x1-throughput-fp8-nupr5gs2dw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GB200x1 FP8 Throughput
          ngcMetadata:
            a8d5512071d8c48e62ac709edc231cbf158aacc5faae00040379c8c3bc4f2bf8:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: bc56bf15cfcf13e2c7834d0ce1767a27719c1de7291cee654f6232c35375bf45
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h100x2-latency-fp8-5cyndvc2za
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100x2 FP8 Latency
          ngcMetadata:
            af99cd31d06f9fb19ffe3dfce1e5c053ffbd43f3c7e671d9c4550eccb8dee31e:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 44b31027ddef82c6ddcd49ecfc68f20067975ad0d9b62755ca3667e055f48ab5
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:l40sx2-latency-bf16-wimz1alj0q
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct L40Sx2 BF16 Latency
          ngcMetadata:
            b0833059fa3270d15e7a2ccbd1228fe5a3681b5801395d5c2c306fac3a386534:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a4315018cc1c0f75d76920b73d557daea0e2f4dfbd8b626515adb36e90ebba12
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_144GBx1 FP8 Throughput
          ngcMetadata:
            b4375abbe106a961f61ebfc40ecb73490ca64fadba7b06c156173aeec81ed2fa:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 94f9fdc707b068711db2447004698e4a90be58c6d3329463ba57c85714bff488
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:b200x2-latency-bf16-jvvom3lafg
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct B200x2 BF16 Latency
          ngcMetadata:
            bb8774e429cd06145c3af972a557193da4859bbb406bdd6ab4eba1111b757ee4:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 417053eecdaf868c0db37d64920e90eb29881638168c9781c33309dabd9852c8
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100_NVLx2 FP8 Latency
          ngcMetadata:
            bbc09967e87df528eafcdee9c95946cbc528a004bade8c30e4d655902b4a1eda:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 7ad4d81f5c1ff5bd7171ee75a51e45af792644f3cc45282999e3405adfbec78e
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h100x1-throughput-fp8-tfwwzbhdca
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100x1 FP8 Throughput
          ngcMetadata:
            cad5ff155623a7ed9e6e400347be5d2b1772324a4389585f372d99ab2b18310b:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: fa0733fe89758e6911ee12b330d3bc39d1e933a9cffcd13f80f54f00e44d5808
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GH200_144GBx1 BF16 Throughput
          ngcMetadata:
            cc2a610402f4d5fc1b580b09af8e0f35c4a6214bc5a3da2de66aa1c9eaf00703:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GH200_144GB
                gpu_device: 2348:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 64b5a893869e9c17ddd2a31f28ebe867079c41899f1e00c503cce640fa487128
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:gb200x2-latency-fp8-mj9h4xjlpw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct GB200x2 FP8 Latency
          ngcMetadata:
            d30b476874b44f6d697a81c37a6a5df7747b95d77ec196644b1b288cfa4ebb99:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a79685d119872d802f1fd849c1636665049ff58a7354fb536df1451d42952a75
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h100x2-latency-bf16-kdm6hypmza
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100x2 BF16 Latency
          ngcMetadata:
            d35b0a4879ffc8a4ee620979a9b0306c1d35265c0d0d4917b1079da1bd44c830:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: adb5fe983b732e233035db031b01461e698505aa8db330f00da89ed240b244b3
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:h200x2-latency-fp8-qdlgs44zrw
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H200x2 FP8 Latency
          ngcMetadata:
            ece478a8ed72c4ff1b85bf758b105a30b724f5da2320278a50d7328ae661eaed:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: a14e294573c64a9a49641e82012cb4fa3776f6fe25d9be84092b4ec2476006e1
                number_of_gpus: '4'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-1b-instruct:hf-9213176-tool_calling
          framework: TensorRT-LLM
          displayName: Llama 3.2 1B Instruct H100_NVLx2 BF16 Latency
          ngcMetadata:
            ee50ced41e24f36d4ad7c0bb3504688562be53a94b7f76fa99a867ff8b5d06ca:
              model: meta/llama-3.2-1b-instruct
              release: 1.12.0
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                nim_workspace_hash_v1: 77f4dfe035e443e59bbaf204c6e17b9c52cb16cbb638e426a5eedb0a8b6b2177
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.12.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
    - variantId: Llama 3.2 3B Instruct
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_2-3b-instruct
      optimizationProfiles:
        - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-throughput-fp8-jtgu5wt2yg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX4090x1 FP8 Throughput
          ngcMetadata:
            08cb5b3735b6331f07212bd488639ad1a049dbcf3e96375acbbb83ca861f9ec9:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h20x1-throughput-bf16-hnixelsq-q
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H20x1 BF16 Throughput
          ngcMetadata:
            1cdb4d3f28059cb1aacb005776112ce4f7060a20d25d072932ce60bbe993fabc:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H20
                gpu_device: 2329:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H20
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2329:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:a100x2-latency-bf16-dbue0mkzcw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A100x2 BF16 Latency
          ngcMetadata:
            2146fcf18ea0412d564c6ed21d2f727281b95361fd78ccfa3d0570ec1716e8db:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:a100x1-throughput-bf16-lblsxfeipq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A100x1 BF16 Throughput
          ngcMetadata:
            222d1729a785201e8a021b226d74d227d01418c41b556283ee1bdbf0a818bd94:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100_NVLx1 BF16 Throughput
          ngcMetadata:
            25b5e251d366671a4011eaada9872ad1d02b48acc33aa0637853a3e3c3caa516:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A100_SXM4_40GBx2 BF16 Latency
          ngcMetadata:
            30316e5488489e3c0c2b0e7eee9e4bf5e82655b2a31b66d2e2c5dfa2b4e99bb2:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-latency-fp8-cq5x62ffbg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX4090x1 FP8 Latency
          ngcMetadata:
            33ca5a99fa9b89117df4b610b3f37fdf3462bc2e84a5b96bcf7685e5d839f7f5:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h20x2-latency-bf16-u-xo-smuuq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H20x2 BF16 Latency
          ngcMetadata:
            362bd1de84adb8cc5be888391810dd9cc02ce3f25ad0b70fd500be54f93b9d4c:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H20
                gpu_device: 2329:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H20
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2329:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h200x1-throughput-bf16-frc0n1b7nw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H200x1 BF16 Throughput
          ngcMetadata:
            434e8d336fa23cbe151748d32b71e196d69f20d319ee8b59852a1ca31a48d311:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:b200x2-latency-fp8-04qswl5yla
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct B200x2 FP8 Latency
          ngcMetadata:
            4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 BF16 Latency
          ngcMetadata:
            566962048d4b01afd12f466ae697cf071eed5a46be33d66f3733e978ce99d1e7:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX6000_ADA
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100_NVLx1 FP8 Throughput
          ngcMetadata:
            5811750e70b7e9f340f4d670c72fcbd5282e254aeb31f62fd4f937cfb9361007:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h200x2-latency-bf16--b69z90dgg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H200x2 BF16 Latency
          ngcMetadata:
            6832a9395f54086162fd7b1c6cfaae17c7d1e535a60e2b7675504c9fc7b57689:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h100x2-latency-fp8-r2-4vhtqrq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100x2 FP8 Latency
          ngcMetadata:
            6c3f01dd2b2a56e3e83f70522e4195d3f2add70b28680082204bbb9d6150eb04:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:a10gx1-throughput-bf16-r9bno-v4fw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A10Gx1 BF16 Throughput
          ngcMetadata:
            74bfd8b2df5eafe452a9887637eef4820779fb4e1edb72a4a7a2a1a2d1e6480b:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h100x1-throughput-fp8-kc5b4ag-cg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100x1 FP8 Throughput
          ngcMetadata:
            7b508014e846234db3cabe5c9f38568b4ee96694b60600a0b71c621dc70cacf3:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h20x2-latency-fp8-icgplntjww
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H20x2 FP8 Latency
          ngcMetadata:
            7fba1c034f3ace0a31d7cc345ec44482735555168c62c332bb38121c26345bbd:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H20
                gpu_device: 2329:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H20
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2329:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 FP8 Throughput
          ngcMetadata:
            8620431f3069e2f17f1cf712639ba06d67290d74c4c2e9a0d6e606952de91a88:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX6000_ADA
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h20x1-throughput-fp8-bmppgnfoeq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H20x1 FP8 Throughput
          ngcMetadata:
            86be215b815363c818c00883dd403bd1f4ce5c610037637529a2a7e039973de6:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H20
                gpu_device: 2329:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H20
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2329:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:b200x1-throughput-fp8-pysymm95jq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct B200x1 FP8 Throughput
          ngcMetadata:
            8b87146e39b0305ae1d73bc053564d1b4b4c565f81aa5abe3e84385544ca9b60:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l20x1-throughput-bf16-rpqq5ggd-q
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L20x1 BF16 Throughput
          ngcMetadata:
            91c52b108cd75967df6ed98f3d1d73a34cb0899d625f6f86499089f545ebe458:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L20
                gpu_device: 26ba:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L20
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26BA:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100_NVLx2 FP8 Latency
          ngcMetadata:
            a00ce1e782317cd19ed192dcb0ce26ab8b0c1da8928c33de8893897888ff7580:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 FP8 Latency
          ngcMetadata:
            a1ebfd69da7c3b97aa566387a4f086e563ff848cc5bab442147badc55f63364a:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX6000_ADA
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:b200x1-throughput-bf16-iwdccsjltw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct B200x1 BF16 Throughput
          ngcMetadata:
            a4c63a91bccf635b570ddb6d14eeb6e7d0acb2389712892b08d21fad2ceaee38:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX6000_ADAx1 BF16 Throughput
          ngcMetadata:
            a7b900f860f8770ecf1a982e79395659729010beeec832b522d96e8243b2439a:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX6000_ADA
                gpu_device: 26b1:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l40sx1-throughput-bf16-i09pxvzjbg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L40Sx1 BF16 Throughput
          ngcMetadata:
            ac5071bbd91efcc71dc486fcd5210779570868b3b8328b4abf7a408a58b5e57c:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l40sx1-throughput-fp8-jnzgjqaxuw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L40Sx1 FP8 Throughput
          ngcMetadata:
            ad17776f4619854fccd50354f31132a558a1ca619930698fd184d6ccf5fe3c99:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h200x1-throughput-fp8-r0-6osqtng
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H200x1 FP8 Throughput
          ngcMetadata:
            af876a179190d1832143f8b4f4a71f640f3df07b0503259cedee3e3a8363aa96:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h100x2-latency-bf16-0i4agi9azq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100x2 BF16 Latency
          ngcMetadata:
            b3d535c0a7eaaea089b087ae645417c0b32fd01e7e9d638217cc032e51e74fd0:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100_NVLx2 BF16 Latency
          ngcMetadata:
            b7fad3b35b07d623fac6549078305b71d0e6e1d228a86fa0f7cfe4dbeca9151a:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100_NVL
                gpu_device: 2321:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100_NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l20x2-latency-bf16-acj72sjf5a
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L20x2 BF16 Latency
          ngcMetadata:
            c1c471464263781f56805d7768a50f70c830dbc68d795d641bd5bef18455b6f4:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L20
                gpu_device: 26ba:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L20
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26BA:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l40sx2-latency-fp8-44i4vvrorq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L40Sx2 FP8 Latency
          ngcMetadata:
            c4ff823a8202af4b523274fb8c6cdd73fa8ee5af16391a6d36b17f714a3c71a0:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l20x2-latency-fp8-f2nzfrgyia
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L20x2 FP8 Latency
          ngcMetadata:
            c610b690036f0e8ac96ea3ed1e584ef5c4f8a4cf1253664b8dc08df5b404de48:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L20
                gpu_device: 26ba:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L20
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26BA:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A100_SXM4_40GBx1 BF16 Throughput
          ngcMetadata:
            c6821c013c559912c37e61d7b954c5ca8fe07dda76d8bea0f4a52320e0a54427:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A100_SXM4_40GB
                gpu_device: 20b0:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100_SXM4_40GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B0:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-throughput-bf16-8m--uis3tg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX4090x1 BF16 Throughput
          ngcMetadata:
            c78670b98ba7d5bc4105cbf723eb1cb514e3cb159dacd3d8b997b20c9ceeb1ea:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l20x1-throughput-fp8-fqsk6q2inq
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L20x1 FP8 Throughput
          ngcMetadata:
            d2f14fb35f10d3ffef37a9f198d3c39f37a1452f65a1b523ec0135868fb23ba7:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L20
                gpu_device: 26ba:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L20
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26BA:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h200x2-latency-fp8-zzxu8dlxcw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H200x2 FP8 Latency
          ngcMetadata:
            e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: fp8
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:h100x1-throughput-bf16--lfg89p-ew
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct H100x1 BF16 Throughput
          ngcMetadata:
            e7dbd9a8ce6270d2ec649a0fecbcae9b5336566113525f20aee3809ba5e63856:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:a10gx2-latency-bf16-0ksvrbt0ww
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct A10Gx2 BF16 Latency
          ngcMetadata:
            ee94491ed7167340de93fe9d1c87f10ba424da6f497eeabf83b4edcbeb69364c:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: A10G
                gpu_device: 2237:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2237:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:b200x2-latency-bf16-f-dquqynva
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct B200x2 BF16 Latency
          ngcMetadata:
            f44768c625db71a327cf17e750d5e1a8e60171a8d8ef6b4c1c4b57fe74c9bf46:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct GH200_480GBx1 FP8 Throughput
          ngcMetadata:
            f49b49f3d90159a594def51efd8595f1d618e288bca2721fe08e786a1ac67d04:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: fp8
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:rtx4090x1-latency-bf16-b25uxqlekg
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct RTX4090x1 BF16 Latency
          ngcMetadata:
            f5e266ce2a4692b37b80e0cb6ab2dea59a54d26b80396f1a521921384bd79ffe:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: RTX4090
                gpu_device: 2684:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: RTX4090
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2684:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 7GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:hf-392a143-tool-use-v2
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct GH200_480GBx1 BF16 Throughput
          ngcMetadata:
            f7f74ecd523cd63065a50016a8786a893b9b1efe0d313bc5bcc54682f56e55fe:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: GH200_480GB
                gpu_device: 2342:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '1'
                pp: '1'
                precision: bf16
                profile: throughput
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: THROUGHPUT
            - key: PRECISION
              value: BF16
            - key: GPU
              value: GH200_480GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 12GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
        - profileId: nim/meta/llama-3.2-3b-instruct:l40sx2-latency-bf16-pb6dhqvrgw
          framework: TensorRT-LLM
          displayName: Llama 3.2 3B Instruct L40Sx2 BF16 Latency
          ngcMetadata:
            fa36c3502e92c50f78a1906242f929864955e702b7dbfbdb19758fb7ee9aa811:
              model: meta/llama-3.2-3b-instruct
              release: 1.10.1
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: tensorrt_llm
                number_of_gpus: '2'
                pp: '1'
                precision: bf16
                profile: latency
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: LATENCY
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.10.1
            - key: DOWNLOAD SIZE
              value: 8GB
            - key: LLM ENGINE
              value: TENSORRT_LLM
  labels:
    - Llama
    - Meta
    - Multilingual Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: NeMo Retriever-Parse
  displayName: NeMo Retriever-Parse
  modelHubID: nemoretriever-parse
  category: Text Extraction
  type: NGC
  description: Nemoretriever-parse is a general purpose text-extraction model, specifically designed to handle documents. Given an image, nemoretriever-parse is able to extract formatted-text, with bounding-boxes and the corresponding semantic class. This has downstream benefits for several tasks such as increasing the availability of training-data for Large Language Models (LLMs), improving the accuracy of retriever systems, and enhancing document understanding pipelines.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: nemoretriever-parse:1.2.0
      source:
        URL: https://build.nvidia.com/nvidia/nemoretriever-parse
      optimizationProfiles:
        - profileId: nim/nvidia/nemoretriever-parse:a100x1-throughput-bf16-e9wjao-enw
          framework: TensorRT-LLM
          displayName: nemoretriever-parse A100 BF16 Throughput
          ngcMetadata:
            19c68819d9428cfa494e977f4d2be6378215a8f610cce9bdfc0aa3cdd7d66aa9:
              model: nvidia/nemoretriever-parse
              release: 1.2.0
              tags:
                gpu: A100
                gpu_device: 20b2:10de
                llm_engine: tensorrt_llm
                pp: '1'
                profile: throughput
                precision: bf16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20b2:10de
            - key: NIM VERSION
              value: 1.2.0
            - key: DOWNLOAD SIZE
              value: 600MB
        - profileId: nim/nvidia/nemoretriever-parse:h100x1-throughput-bf16-2apiazbpma
          framework: TensorRT-LLM
          displayName: nemoretriever-parse H100 BF16 Throughput
          ngcMetadata:
            8db6dcd816ca1ce8d07e72d8b9c4682120b3c50799422361e35b4ab87820efd6:
              model: nvidia/nemoretriever-parse
              release: 1.2.0
              tags:
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: tensorrt_llm
                pp: '1'
                profile: throughput
                precision: bf16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10de
            - key: NIM VERSION
              value: 1.2.0
            - key: DOWNLOAD SIZE
              value: 600MB
        - profileId: nim/nvidia/nemoretriever-parse:l40sx1-throughput-bf16-r98ogb1a1a
          framework: TensorRT-LLM
          displayName: nemoretriever-parse L40S BF16 Throughput
          ngcMetadata:
            00c8a43783e7acf3d59a0d773cd78d3d29eaa71fa4412af7af2fbaf20e196a8b:
              model: nvidia/nemoretriever-parse
              release: 1.2.0
              tags:
                gpu: L40S
                gpu_device: 26b5:10de
                llm_engine: tensorrt_llm
                pp: '1'
                profile: throughput
                precision: bf16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: Throughput
            - key: PRECISION
              value: BF16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26b5:10de
            - key: NIM VERSION
              value: 1.2.0
            - key: DOWNLOAD SIZE
              value: 600MB
  labels:
    - NeMo
    - Text Extraction
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Nemoretriever Graphic Elements V1
  displayName: Nemoretriever Graphic Elements V1
  modelHubID: nemoretriever-graphic-elements-v1
  category: Object Detection
  type: NGC
  description: NVIDIA NeMo Retriever NIM for graphic elements v1 is a fine-tuned object detection model, trained specifically for detecting the elements of charts and tables in documents
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Nemoretriever Graphic Elements V1
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nemoretriever-graphic-elements-v1
      optimizationProfiles:
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:a10gx1-trt-fp16-nwnqycg0xg
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 A10Gx1 FP16
          ngcMetadata:
            09231248dff89cf8859d9206931342e468fbddfe469df56334fbe00df7fda1da:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.6'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:b200x1-trt-fp16-jtagdygnhq
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 B200x1 FP16
          ngcMetadata:
            0f3b150544da8a053048c1e2a37a282b2c43f09a99253882578d12bc1f2cfca6:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '10.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:h100x1-trt-fp16-jswckvqtmq
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 H100x1 FP16
          ngcMetadata:
            58adeef41afa742e753314ae51818e9f017f2c92ba0bfdc01befe6234703a54c:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '9.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:rtx6000-blackwell-svx1-trt-fp16-1ted4cchma
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 RTX6000x1 FP16
          ngcMetadata:
            b4cc2f8b3d2dcf1afdcafbee8ea694c53aeee642d76f709ed0e79477b68a8dde:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '12.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: RTX6000
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:l40sx1-trt-fp16-cwnvuqbbna
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 L40Sx1 FP16
          ngcMetadata:
            bc1487bf0ec3430f17595fff029c1bc50668344c7a30f9e5d64ee061c6e2d5fa:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.9'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-graphic-elements-v1:a100x1-trt-fp16-qpwy-4niaa
          framework: TensorRT-LLM
          displayName: Nemoretriever Graphic Elements V1 A100x1 FP16
          ngcMetadata:
            f0fb2f72a66230096c40fc3307872ebb9bce69816cbfc6e2918695ca824bd284:
              model: nvidia/nemoretriever-graphic-elements-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
  labels:
    - signed images
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
    - NSPECT-7OBP-T77C
  config:
    architectures:
      - Other
    modelType: NGC
  license: NVIDIA AI Foundation Models Community License
- name: Nemoretriever Page Elements V2
  displayName: Nemoretriever Page Elements V2
  modelHubID: nemoretriever-page-elements-v2
  category: Object Detection
  type: NGC
  description: NVIDIA NeMo Retriever NIM for page elements v2 is a fine-tuned object detection model, trained specifically for detecting charts, tables, infographics, and titles on a document page.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Nemoretriever Page Elements V2
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nemoretriever-page-elements-v2
      optimizationProfiles:
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:a10gx1-trt-fp16-toixhuroha
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 A10Gx1 FP16
          ngcMetadata:
            09231248dff89cf8859d9206931342e468fbddfe469df56334fbe00df7fda1da:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.6'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:b200x1-trt-fp16-ayukzqdapq
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 B200x1 FP16
          ngcMetadata:
            0f3b150544da8a053048c1e2a37a282b2c43f09a99253882578d12bc1f2cfca6:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '10.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:h100x1-trt-fp16-nuq3ijukrw
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 H100x1 FP16
          ngcMetadata:
            58adeef41afa742e753314ae51818e9f017f2c92ba0bfdc01befe6234703a54c:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '9.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:rtx6000-blackwell-svx1-trt-fp16-xd1wfged5w
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 RTX6000x1 FP16
          ngcMetadata:
            b4cc2f8b3d2dcf1afdcafbee8ea694c53aeee642d76f709ed0e79477b68a8dde:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '12.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: RTX6000
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:l40sx1-trt-fp16-qnrq36wfcw
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 L40Sx1 FP16
          ngcMetadata:
            bc1487bf0ec3430f17595fff029c1bc50668344c7a30f9e5d64ee061c6e2d5fa:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.9'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:a100x1-onnx-fp16-wagmq6-x1q
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 A100x1 FP16
          ngcMetadata:
            edc693c6fccd68d266622eace04225421e353d7ce31e3b207afc5ff35124127b:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                model_type: onnx
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: ONNX
        - profileId: nim/nvidia/nemoretriever-page-elements-v2:a100x1-trt-fp16-yukvwcfl5q
          framework: TensorRT-LLM
          displayName: Nemoretriever Page Elements V2 A100x1 FP16
          ngcMetadata:
            f0fb2f72a66230096c40fc3307872ebb9bce69816cbfc6e2918695ca824bd284:
              model: nvidia/nemoretriever-page-elements-v2
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
  labels:
    - signed images
    - NSPECT-7OBP-T77C
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: Nemoretriever Table Structure V1
  displayName: Nemoretriever Table Structure V1
  modelHubID: nemoretriever-table-structure-v1
  category: Object Detection
  type: NGC
  description: NVIDIA NeMo Retriever NIM for table structure v1 is a fine-tuned object detection model, trained specifically for detecting the structure of complex tables.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Nemoretriever Table Structure V1
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nemoretriever-table-structure-v1
      optimizationProfiles:
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:a10gx1-trt-fp16-ncblfgrrew
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 A10Gx1 FP16
          ngcMetadata:
            09231248dff89cf8859d9206931342e468fbddfe469df56334fbe00df7fda1da:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.6'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:b200x1-trt-fp16--ce2boy2vw
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 B200x1 FP16
          ngcMetadata:
            0f3b150544da8a053048c1e2a37a282b2c43f09a99253882578d12bc1f2cfca6:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '10.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:h100x1-trt-fp16-lnq0nmbo3g
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 H100x1 FP16
          ngcMetadata:
            58adeef41afa742e753314ae51818e9f017f2c92ba0bfdc01befe6234703a54c:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '9.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:rtx6000-blackwell-svx1-trt-fp16-unyitj7ofa
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 RTX6000x1 FP16
          ngcMetadata:
            b4cc2f8b3d2dcf1afdcafbee8ea694c53aeee642d76f709ed0e79477b68a8dde:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '12.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: RTX6000
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:l40sx1-trt-fp16-ddoabmkana
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 L40Sx1 FP16
          ngcMetadata:
            bc1487bf0ec3430f17595fff029c1bc50668344c7a30f9e5d64ee061c6e2d5fa:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.9'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:a100x1-onnx-fp16-l8hnwsbr3g
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 A100x1 FP16
          ngcMetadata:
            edc693c6fccd68d266622eace04225421e353d7ce31e3b207afc5ff35124127b:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                model_type: onnx
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: ONNX
        - profileId: nim/nvidia/nemoretriever-table-structure-v1:a100x1-trt-fp16-jvvssvik-q
          framework: TensorRT-LLM
          displayName: Nemoretriever Table Structure V1 A100x1 FP16
          ngcMetadata:
            f0fb2f72a66230096c40fc3307872ebb9bce69816cbfc6e2918695ca824bd284:
              model: nvidia/nemoretriever-table-structure-v1
              release: 1.6.0
              tags:
                backend: triton
                compute_capability: '8.0'
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.6.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
  labels:
    - signed images
    - NSPECT-7OBP-T77C
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: PaddleOCR
  displayName: PaddleOCR
  modelHubID: paddleocr
  category: Optical Character Recognition
  type: NGC
  description: PaddleOCR is an ultra lightweight Optical Character Recognition (OCR) system by Baidu. PaddleOCR supports a variety of cutting-edge algorithms related to OCR.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: PaddleOCR
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/baidu/containers/paddleocr
      optimizationProfiles:
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA L4x1 FP16
          ngcMetadata:
            49049986fc9bf66bc3674dd5ff7953472d7ec6ae82a64b74b8d33d3e8c077391:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 27b8:10de
                gpu: NVIDIA L4
                gpu_key: l4
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA L4
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA A100-SXM4-80GBx1 FP16
          ngcMetadata:
            495980e0b97395173bd2ddce9f7dec2851c654643e3bdb91c4d8fc24047c4d6a:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 20b2:10de
                gpu: NVIDIA A100-SXM4-80GB
                gpu_key: a100-sxm4-80gb
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA A100-SXM4-80GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA H100 NVLx1 FP16
          ngcMetadata:
            5c2af3e6451d4087fa274ab38bca77845fbb8e0577c176407511154869d2fe26:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 2321:10de
                gpu: NVIDIA H100 NVL
                gpu_key: h100-nvl
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA H100 NVL
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA L40Sx1 FP16
          ngcMetadata:
            631c6b6c76996d8cc04cf7cfde63d15d1b5f57cb323dc129f2a838b35703f1d9:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 26b9:10de
                gpu: NVIDIA L40S
                gpu_key: l40s
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA A100-SXM4-40GBx1 FP16
          ngcMetadata:
            93868053f6713346c8c4f6602b6a981b18d95d6680510bf249fd5b83477bbc52:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 20b0:10de
                gpu: NVIDIA A100-SXM4-40GB
                gpu_key: a100-sxm4-40gb
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA A100-SXM4-40GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA A10Gx1 FP16
          ngcMetadata:
            acba2841622c4da2050811e8c7c4bae4c16996ab61b67d68b089176524d70383:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 2237:10de
                gpu: NVIDIA A10G
                gpu_key: a10g
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA A10G
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA B200x1 FP16
          ngcMetadata:
            b6c8b6aef874d014b535faf2742d759bce6670c32b777ea8762d6264f7d30737:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 2901:10de
                gpu: NVIDIA B200
                gpu_key: b200
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA B200
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/baidu/paddleocr:2_TRT_python_2
          framework: TensorRT-LLM
          displayName: Paddleocr NVIDIA H100 80GB HBM3x1 FP16
          ngcMetadata:
            eaad888e841d6944998862e9ea19050e530701214aa6caa164047bc0fb800a69:
              model: baidu/paddleocr
              release: 1.5.0
              tags:
                backend: triton
                batch_size: '32'
                device_id: 2330:10de
                gpu: NVIDIA H100 80GB HBM3
                gpu_key: h100-hbm3-80gb
                model_type: tensorrt
                precision: fp16
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: NVIDIA H100 80GB HBM3
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 1GB
            - key: BACKEND
              value: TRITON
            - key: MODEL TYPE
              value: TENSORRT
  labels:
    - signed images
    - NSPECT-LDAL-INWI
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.2 NV EmbedQA 1b V2
  displayName: Llama 3.2 NV EmbedQA 1b V2
  modelHubID: llama-3.2-nv-embedqa-v2
  category: Text Embedding
  type: NGC
  description: The NVIDIA Retrieval QA Llama3.2 1b Embedding NIM is an embedding NIM optimized for multilingual and crosslingual text question-answering retrieval.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.2 NV EmbedQA 1b V2
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-embedqa-1b-v2
      optimizationProfiles:
        - profileId: nim/nvidia/llama-3.2-nv-embedqa-1b-v2:onnx-precision.fp16-7c7a1c17
          framework: ONNX
          displayName: Llama 3.2 NV Embedqa 1B V2 ONNX FP16
          ngcMetadata:
            f7391ddbcb95b2406853526b8e489fedf20083a2420563ca3e65358ff417b10f:
              model: nvidia/llama-3.2-nv-embedqa-1b-v2
              release: 1.10.0
              tags:
                backend: onnx
                model_type: onnx
                precision: fp16
                tp: '1'
          modelFormat: onnx
          spec:
            - key: PRECISION
              value: FP16
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.10.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: ONNX
            - key: MODEL TYPE
              value: ONNX
            - key: MAX TOKENS
              value: 8192
            - key: TOTAL PARAMETERS
              value: 1236
            - key: Embedding Dimension
              value: 2048
  labels:
    - Llama
    - Meta
    - Chat
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Llama 3.2 NV RerankQA 1b V2
  displayName: Llama 3.2 NV RerankQA 1b V2
  modelHubID: llama-3.2-nv-rerankqa-v2
  category: Text Embedding
  type: NGC
  description: The NVIDIA Retrieval QA Llama 1B Reranking NIM is a NIM optimized for providing a logit score that represents how relevant a document(s) is to a given query, fine-tuned for multilingual and cross-lingual text question-answering retrieval.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://llama.meta.com/llama3/use-policy/
    - label: License Agreement
      url: https://llama.meta.com/llama3/license/
  modelVariants:
    - variantId: Llama 3.2 NV RerankQA 1b V2
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-rerankqa-1b-v2
      optimizationProfiles:
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:h100x1-trt-fp16--ckqlv3j2g
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA H100 NVLx1 FP16
          ngcMetadata:
            3b1e767e41d02ed0ffa5aa6b46a2edfdd1540edaec2eeda4c00278c838bba38b:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2321:10de
                gpu: NVIDIA H100 NVL
                gpu_key: h100-nvl
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100-NVL
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:a100x1-trt-fp16-dxtbz8wstg
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA A100-SXM4-40GBx1 FP16
          ngcMetadata:
            477500a740ea33ea1419289866bbfd598ce51a806fe034b48dc176db32155f59:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 20b0:10de
                gpu: NVIDIA A100-SXM4-40GB
                gpu_key: a100-sxm4-40gb
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100-SXM4-40GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:l40sx1-trt-fp16-20qsn53gag
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA L40Sx1 FP16
          ngcMetadata:
            49d14b4eaebc6b1f61e48afb3d88535f4ad3758ea55036f5ab3815d1c5a927fc:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 26b9:10de
                gpu: NVIDIA L40S
                gpu_key: l40s
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:a100x1-trt-fp16-dxtbz8wstg
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA A100-SXM4-80GBx1 FP16
          ngcMetadata:
            4ea4624dcc114adeeb29272322897800cddf5dfa873dac467f67d827b7dd9c4d:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 20b2:10de
                gpu: NVIDIA A100-SXM4-80GB
                gpu_key: a100-sxm4-80gb
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100-SXM4-80GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:l40sx1-trt-fp8-4nwnajwq4g
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA L40Sx1 FP8
          ngcMetadata:
            5036ebf412fba4e54511ab4b3822ec7dfb9fd2c256c3100ad2ed9d2b4bda9f79:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 26b9:10de
                gpu: NVIDIA L40S
                gpu_key: l40s
                model_type: tensorrt
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:a10gx1-trt-fp16-fxo3knzn8w
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA A10Gx1 FP16
          ngcMetadata:
            6f21ae4169cfe3c03cc92eb194713f5a3044ac2f61526edf632d0f9a5155b538:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2237:10de
                gpu: NVIDIA A10G
                gpu_key: a10g
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:b200x1-trt-fp16-jiw0-uharg
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA B200x1 FP16
          ngcMetadata:
            75b659320dada86548fb6af5d3adfe386df6c515969d71db4e76cd64375777e1:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2901:10de
                gpu: NVIDIA B200
                gpu_key: b200
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 4GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:h100x1-trt-fp8-bm87q6egvq
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA H100 80GB HBM3x1 FP8
          ngcMetadata:
            774e4d699d318f41630b51b4280cadecb184b9b2755b707aa74232f1ea642b2c:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2330:10de
                gpu: NVIDIA H100 80GB HBM3
                gpu_key: h100-hbm3-80gb
                model_type: tensorrt
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-HBM3-80GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:l4x1-trt-fp16-bajefiwkra
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA L4x1 FP16
          ngcMetadata:
            9278eac727396c9f6ab9b3d421748889b0686afd20a9cef12d1d16c39fcd6a9d:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 27b8:10de
                gpu: NVIDIA L4
                gpu_key: l4
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L4
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:l4x1-trt-fp8-vk0qdpls2w
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA L4x1 FP8
          ngcMetadata:
            a344745c8dbe62413a4e95b4e5718a689c155dfb8743868fb5d13956a621b31e:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 27b8:10de
                gpu: NVIDIA L4
                gpu_key: l4
                model_type: tensorrt
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L4
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:h100x1-trt-fp8-bm87q6egvq
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA H100 NVLx1 FP8
          ngcMetadata:
            b469c56c1a9ac1001151765527d3c7de77f590255b08eea4aa064ee1abf0ef3f:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2321:10de
                gpu: NVIDIA H100 NVL
                gpu_key: h100-nvl
                model_type: tensorrt
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-NVL
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:h100x1-trt-fp16--ckqlv3j2g
          framework: TensorRT-LLM
          displayName: Llama 3.2 NV Rerankqa 1B V2 NVIDIA H100 80GB HBM3x1 FP16
          ngcMetadata:
            ddd9c5d1430631c0bd75c04b0c18e9b620219ad82c808a30d019be9cbcd618bd:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: tensorrt
                device_id: 2330:10de
                gpu: NVIDIA H100 80GB HBM3
                gpu_key: h100-hbm3-80gb
                model_type: tensorrt
                precision: fp16
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100-HBM3-80GB
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 5GB
            - key: BACKEND
              value: TENSORRT
            - key: MODEL TYPE
              value: TENSORRT
        - profileId: nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:onnx-precision.fp16-d03bf375
          framework: ONNX
          displayName: Llama 3.2 NV Rerankqa 1B V2 ONNX FP16
          ngcMetadata:
            f7391ddbcb95b2406853526b8e489fedf20083a2420563ca3e65358ff417b10f:
              model: nvidia/llama-3.2-nv-rerankqa-1b-v2
              release: 1.8.0
              tags:
                backend: onnx
                model_type: onnx
                precision: fp16
                tp: '1'
          modelFormat: onnx
          spec:
            - key: PRECISION
              value: FP16
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.8.0
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: BACKEND
              value: ONNX
            - key: MODEL TYPE
              value: ONNX
  labels:
    - Llama
    - Meta
    - Chat
    - NIM
    - Large Language Model
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Nemotron Nano 12B V2 VL
  displayName: Nemotron Nano 12B V2 VL
  modelHubID: nemotron-nano-12b-v2-vl
  category: VLM
  type: NGC
  description: The Nemotron Nano12B v2 VL model is an advanced autoregressive Visual Language Model (VLM) designed for document transcription from images and videos, outputting text in a reading order.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Nemotron Nano 12B V2 VL
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/nemotron-nano-12b-v2-vl?version=1
      optimizationProfiles:
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H200x2 FP8
          ngcMetadata:
            04571f2160949a968ef4d55573010bb4937adb3055565383e4975d6b579eabb5:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL RTX-PRO-6K-BWE-MAXQx1 FP8
          ngcMetadata:
            124606e1502807f80b51d1bb02eac73130f5f0772333e954cce58e983b51cd8f:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: RTX-PRO-6K-BWE-MAXQ
                gpu_device: 2bb4:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX-PRO-6K-BWE-MAXQ
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB4:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL B200x1 FP8
          ngcMetadata:
            2319f3a24597d85e3997ea5d7904bde6a3172d77ec0f3caf4dd51db4989e8ee0:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL GB200x1 FP8
          ngcMetadata:
            23237e540f5d6eed2e0cbd82ffa671324113254452ff6d2a8de4f525ba119d16:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL GB200x2 FP8
          ngcMetadata:
            2589b47cefde8493906f5134017b790cc08b2d2be613f11ef9597b3915664de5:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: GB200
                gpu_device: 2941:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GB200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL GH200-144GBx1 FP8
          ngcMetadata:
            260e0af1b99e6283a0a76895b5d5e4909f0b22f24f92a837fdfd0b52f85bdbaf:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: GH200-144GB
                gpu_device: 2348:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200-144GB
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL RTX-PRO-6K-BSEx2 FP8
          ngcMetadata:
            38c33abf967522c8e7b944244d4ed8b13eb338a3123ae0b258b19ea93ee0af63:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: RTX-PRO-6K-BSE
                gpu_device: 2bb5:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX-PRO-6K-BSE
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100-PCIEx2 FP8
          ngcMetadata:
            44a56408cfe76bc50ee3c1ed96f06cd267d1248512ad9a865e534e80b190c019:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100-PCIE
                gpu_device: 2331:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-PCIE
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2331:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100-NVLx2 FP8
          ngcMetadata:
            46b31dbe7ba6d101c01faea3c7c9ccdba6480461aa410ca775ddb6250320943f:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100-NVL
                gpu_device: 2321:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100-PCIEx1 FP8
          ngcMetadata:
            6f14f519be3c8fc26ce3f419659df86e271cbb3c1db94293fb975e1f1fd58ee5:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100-PCIE
                gpu_device: 2331:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-PCIE
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2331:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL RTX-PRO-6K-BWEx1 FP8
          ngcMetadata:
            7188e938073f73e7012da9c0b769a567de69b5f5203dfe8ba36769ce179cb822:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: RTX-PRO-6K-BWE
                gpu_device: 2bb1:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX-PRO-6K-BWE
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB1:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL L40Sx1 FP8
          ngcMetadata:
            76775139c252ddbaaf9fd191e94036e43402bc15b87639d3216602eb39eb6463:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H200-NVLx2 FP8
          ngcMetadata:
            7a520b8c8ea2b8a7caee81f2c5fd1e4d9c6d88106d2f3152507a9a8164c4a525:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H200-NVL
                gpu_device: 233b:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200-NVL
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H200-NVLx1 FP8
          ngcMetadata:
            8cc85ddc49fb35402b2bc813804467366404ffad5a1f25e0dd96a9707d797851:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H200-NVL
                gpu_device: 233b:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200-NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 233B:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL GH200x1 FP8
          ngcMetadata:
            9a9699699ec75d96159bc6978e1139fd254403458b15656a5e57e7fbc20acf07:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: GH200
                gpu_device: 2342:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2342:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL B200x2 FP8
          ngcMetadata:
            c5fb44b0cf08feb8bf8efb547071ee22df4d552ad5a901bc352ded2de38946fd:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: B200
                gpu_device: 2901:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: B200
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100-NVLx1 FP8
          ngcMetadata:
            d53f04f82506d15b2d6d22b3e9d9380a125ae9f198d7fc2b93947549ae647128:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100-NVL
                gpu_device: 2321:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100-NVL
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2321:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100x2 FP8
          ngcMetadata:
            d70d4c3bafd1f00ad715ac59c361616460e6eb728669c292cd52f40734badd10:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H200x1 FP8
          ngcMetadata:
            dc1ef5d2e9342285671a8e28c1f04b5cffe3e8fcc929c58557fb563f8c71600a:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H200
                gpu_device: 2335:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2335:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL RTX-PRO-6K-BSEx1 FP8
          ngcMetadata:
            e278c7e2ab8238ef2f75762356e587052e3a743fa768d40f372f60aac3532a4b:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: RTX-PRO-6K-BSE
                gpu_device: 2bb5:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: RTX-PRO-6K-BSE
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2BB5:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL L40Sx2 FP8
          ngcMetadata:
            e2cb05e0c0218d13be144321bbf58817ae680d9b1a9fc7f0e8c619aeb19d19b7:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: L40S
                gpu_device: 26b9:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: L40S
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL H100x1 FP8
          ngcMetadata:
            e93d865568e4f60dd391994e84fe298808dadf3aa0e03f928618e6d5f9c14fe6:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: H100
                gpu_device: 2330:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-fp8-hf
          framework: TensorRT-LLM
          displayName: Nemotron Nano 12B V2 VL GH200-144GBx2 FP8
          ngcMetadata:
            f1274100b8089ab334a01209d6d9d59e10d7f998eeb476602d6c0c2073a5e84f:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                gpu: GH200-144GB
                gpu_device: 2348:10de
                llm_engine: vllm
                nim_workspace_hash_v1: e8c7512e9b274dafd93c1f5e7a120e47ffb424c6806463769c2365dfc998eed1
                pp: '1'
                precision: fp8
                tp: '2'
          modelFormat: trt-llm
          spec:
            - key: PRECISION
              value: FP8
            - key: GPU
              value: GH200-144GB
            - key: COUNT
              value: 2
            - key: GPU DEVICE
              value: 2348:10DE
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 15GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-bf16-hf
          framework: VLLM
          displayName: Nemotron Nano 12B V2 VL Generic NVIDIA GPUx1 BF16
          ngcMetadata:
            06a217a1099a72e5d86a12a31fd39eaba9d7c00d3d311589557d2dc720b59358:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: d943a0e2491f1abaae2e3c2532bc3b70535b0d8637d7b1aeed4e686f0e3e0f61
                pp: '1'
                precision: bf16
                tp: '1'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 25GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/nvidia/nemotron-nano-12b-v2-vl:1.5.0-bf16-hf
          framework: VLLM
          displayName: Nemotron Nano 12B V2 VL Generic NVIDIA GPUx2 BF16
          ngcMetadata:
            97aae95b218c9838fea29548ebaa771a922a8c9781c8450e542e323e2a76a937:
              model: nvidia/nemotron-nano-12b-v2-vl
              release: 1.5.0
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: d943a0e2491f1abaae2e3c2532bc3b70535b0d8637d7b1aeed4e686f0e3e0f61
                pp: '1'
                precision: bf16
                tp: '2'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: BF16
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.5.0
            - key: DOWNLOAD SIZE
              value: 25GB
            - key: LLM ENGINE
              value: VLLM
  labels:
    - signed images
    - NSPECT-P1Z6-6PVL
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: Riva ASR Whisper Large v3
  displayName: Riva ASR Whisper Large v3
  modelHubID: riva-asr-whisper-large-v3
  category: Text-Prompt
  type: NGC
  description: This model is used to transcribe short-form audio files and is designed to be compatible with OpenAI's sequential long-form transcription algorithm. Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labeled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. Whisper-large-v3 is one of the 5 configurations of the model with 1550M parameters. This model version is optimized to run with NVIDIA TensorRT-LLM. This model is ready for commercial use.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Riva ASR Whisper Large v3
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/whisper_large
      optimizationProfiles:
        - profileId: nim/nvidia/whisper-large-v3:ofl-rmir-25.06
          framework: TensorRT-LLM
          displayName: Riva ASR Whisper Large v3 Generic NVIDIA GPUx1
          ngcMetadata:
            5e44fa6d8cd80ad46a089089157ff4565974f0a64fd37c594265c61f00418ae0:
              model: nvidia/riva-asr/whisper
              release: 1.3.1
              tags:
                mode: ofl
                model_type: rmir
                name: whisper-large-v3
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.3.1
            - key: DOWNLOAD SIZE
              value: 3GB
            - key: MODEL TYPE
              value: RMIR
            - key: MODE
              value: OFL
        - profileId: nim/nvidia/whisper-large-v3:h100x1-ofl-25.08-fp16-mnz4pnn0pw
          framework: TensorRT-LLM
          displayName: Riva ASR Whisper Large v3 H100 FP16
          ngcMetadata:
            72232937075119887298deb92b5e58f4d98a0ce0948df60d424f0d97b05da55e:
              model: nvidia/riva-asr/whisper
              release: 1.3.1
              tags:
                gpu_device: '2330'
                mode: ofl
                model_type: prebuilt
                name: whisper-large-v3
                gpu: H100
                tp: '1'
          modelFormat: trt-llm
          spec:
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330
            - key: NIM VERSION
              value: 1.3.1
            - key: DOWNLOAD SIZE
              value: 2GB
            - key: MODEL TYPE
              value: PREBUILT
            - key: MODE
              value: OFL
  labels:
    - Transformer
    - TensorRT-LLM
    - Audio
    - NVIDIA Validated
  config:
    architectures:
      - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
- name: Boltz2
  displayName: Boltz2
  modelHubID: boltz2
  category: Biology Foundation Model
  type: NGC
  description: Boltz-2 NIM is a next-generation structural biology foundation model that shows strong performance for both structure and affinity prediction.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: Boltz2
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mit/containers/boltz2
      optimizationProfiles:
        - profileId: nim/mit/boltz2:1.3.0-gpuh100_sm90_v1
          framework: TensorRT-LLM
          displayName: Boltz2 H100x1 SM90 V1 FP16 Trt
          ngcMetadata:
            0901e344383119d8d4a5160d4d63933fd350e6aa92a56b925a77ecc32378d4a5:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: H100
                gpu_device: 2330:10de
                nim_workspace_hash_v1: 41c01d6bb5cc24cc98a2e59b7a367d197951ad5684f03ed939a35c45dbafd514
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '90'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: H100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2330:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '90'
            - key: V
              value: '1'
        - profileId: nim/mit/boltz2:1.3.0-gpua100_sm80_v1
          framework: TensorRT-LLM
          displayName: Boltz2 A100x1 SM80 V1 FP16 Trt
          ngcMetadata:
            3fbc1c2eb885b24f631f8a1d0c58704cca1c7cf1cd2db4b791c7e6d7201aaa5c:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: A100
                gpu_device: 20b2:10de
                nim_workspace_hash_v1: 1cbe7ff69de2ff435540d9ba81052291e9d9f6fdcd6c580b4db556b5e0adf542
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '80'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 20B2:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '80'
            - key: V
              value: '1'
        - profileId: nim/mit/boltz2:1.3.0-gpurtx6000_ada_sm86_v1
          framework: TensorRT-LLM
          displayName: Boltz2 RTX6000_ADAx1 SM86 V1 FP16 Trt
          ngcMetadata:
            a49907753de80032ade9659c95ef20be5e93af4166b4451531ecac61247ae4b3:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: RTX6000_ADA
                gpu_device: 26b1:10de
                nim_workspace_hash_v1: 8d2989817b603a609a1da17a59010e28c15dd22b51a047d48596d892ff4a1d1a
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '86'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: RTX6000_ADA
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B1:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '86'
            - key: V
              value: '1'
        - profileId: nim/mit/boltz2:1.3.0-gpul40s_sm89_v1
          framework: TensorRT-LLM
          displayName: Boltz2 L40Sx1 SM89 V1 FP16 Trt
          ngcMetadata:
            baffed15a6e497b2a6a18437bca323a2f9c42f269d3f733a1b7fba0020eb9b02:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: L40S
                gpu_device: 26b9:10de
                nim_workspace_hash_v1: 41fcfb105bfe999210b6cf66cc28a8ecfaa4e513ca13b7b2616c88cd80094bf5
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '89'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 26B9:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '89'
            - key: V
              value: '1'
        - profileId: nim/mit/boltz2:1.3.0-gpub200_sm100_v1
          framework: TensorRT-LLM
          displayName: Boltz2 B200x1 SM100 V1 FP16 Trt
          ngcMetadata:
            ca0fa87fc9c52aea7475339eab9fbcec7637a304b261b4ba4450c085a7af4c4d:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: B200
                gpu_device: 2901:10de
                nim_workspace_hash_v1: 9bf86f1e8426e435b6319e0e0d1b6e0a954aced6b59aaa4ed5075de4a7fc52d0
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '100'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: B200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2901:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '100'
            - key: V
              value: '1'
        - profileId: nim/mit/boltz2:1.3.0-gpugb200_sm100_v1
          framework: TensorRT-LLM
          displayName: Boltz2 GB200x1 SM100 V1 FP16 Trt
          ngcMetadata:
            f27c6b6a5dc860324bcc06dcc0ae502d9840546188e69238ebf58376d26f0539:
              model: mit/boltz2
              release: 1.3.0
              tags:
                feat_lora: 'False'
                gpu: GB200
                gpu_device: 2941:10de
                nim_workspace_hash_v1: 9b199cebb2c954abbc94f5ebf37b0052988a7aa8987617c9271605d5e2e2f0b5
                number_of_gpus: '1'
                pp: '1'
                precision: fp16
                profile: trt
                sm: '100'
                tp: '1'
                v: '1'
          modelFormat: trt-llm
          spec:
            - key: PROFILE
              value: TRT
            - key: PRECISION
              value: FP16
            - key: GPU
              value: GB200
            - key: COUNT
              value: 1
            - key: GPU DEVICE
              value: 2941:10DE
            - key: NIM VERSION
              value: 1.3.0
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: SM
              value: '100'
            - key: V
              value: '1'
  labels:
    - Biology Foundation Model
    - signed images
    - NSPECT-D4IX-8I2O
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: GPT-OSS
  displayName: GPT-OSS
  modelHubID: gpt-oss
  category: Text Generation
  type: NGC
  description: The GPT-OSS NIM simplifies the deployment of the GPT-OSS-120B and GPT-OSS-20B tuned models which are optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
    - label: Use Policy
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/
    - label: License Agreement
      url: https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/
  modelVariants:
    - variantId: GPT-OSS 120B
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/openai/containers/gpt-oss-120b
      optimizationProfiles:
        - profileId: nim/openai/gpt-oss-120b:hf-8b193b0-nim
          framework: VLLM
          displayName: Gpt Oss 120B AnyGPUx8 MXFP4
          ngcMetadata:
            650450b7f0c9fb164c4e7e03fca53a2e781718930eb23d23b730ffaff2056685:
              model: openai/gpt-oss-120b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: 8d1357e1888e26523f732140e20c1562434517e6f8e5fa12bc9a67bebf202d33
                pp: '1'
                precision: mxfp4
                tp: '8'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 8
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 61GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-120b:hf-8b193b0-nim
          framework: VLLM
          displayName: Gpt Oss 120B AnyGPUx4 MXFP4
          ngcMetadata:
            9af7e80ca3e26c05e61e22b2f1f88314f03964a30b1f5ebdbe103704d5e48d8f:
              model: openai/gpt-oss-120b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: 8d1357e1888e26523f732140e20c1562434517e6f8e5fa12bc9a67bebf202d33
                pp: '1'
                precision: mxfp4
                tp: '4'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 4
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 61GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-120b:hf-8b193b0-nim
          framework: VLLM
          displayName: Gpt Oss 120B AnyGPUx2 MXFP4
          ngcMetadata:
            b8a95a1d502de2bd02c311f4b590ee8b645eaf4b93584c75314d80a4fd719c57:
              model: openai/gpt-oss-120b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: 8d1357e1888e26523f732140e20c1562434517e6f8e5fa12bc9a67bebf202d33
                pp: '1'
                precision: mxfp4
                tp: '2'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 61GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-120b:hf-8b193b0-nim
          framework: VLLM
          displayName: Gpt Oss 120B AnyGPUx1 MXFP4
          ngcMetadata:
            fc1df044c94b466d0ebd561df47556bc23a01ac8147d68dc49f04238a6cfcd7f:
              model: openai/gpt-oss-120b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: 8d1357e1888e26523f732140e20c1562434517e6f8e5fa12bc9a67bebf202d33
                pp: '1'
                precision: mxfp4
                tp: '1'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 61GB
            - key: LLM ENGINE
              value: VLLM
    - variantId: GPT-OSS 20B
      source:
        URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/openai/containers/gpt-oss-20b
      optimizationProfiles:
        - profileId: nim/openai/gpt-oss-20b:hf-d666cf3-nim
          framework: VLLM
          displayName: Gpt Oss 20B AnyGPUx4 MXFP4
          ngcMetadata:
            653e98d21f9274306416d736519e1c0442d9dad9d8756ff1134cbededfd43323:
              model: openai/gpt-oss-20b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: bef4d428df8c3e67ebe56ba2050a0f50216e82c0172407b43c99c1f6befc9fc5
                pp: '1'
                precision: mxfp4
                tp: '4'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 4
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-20b:hf-d666cf3-nim
          framework: VLLM
          displayName: Gpt Oss 20B AnyGPUx8 MXFP4
          ngcMetadata:
            66b8ec445352535aa8c640435d6f7b00fb2cabb70f8d39fc371adb00322907df:
              model: openai/gpt-oss-20b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: bef4d428df8c3e67ebe56ba2050a0f50216e82c0172407b43c99c1f6befc9fc5
                pp: '1'
                precision: mxfp4
                tp: '8'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 8
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-20b:hf-d666cf3-nim
          framework: VLLM
          displayName: Gpt Oss 20B AnyGPUx1 MXFP4
          ngcMetadata:
            66fb3113efd2aae1b0a3bfa2a375de5fe1cc1b557abac4eb271730482a26ae8e:
              model: openai/gpt-oss-20b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: bef4d428df8c3e67ebe56ba2050a0f50216e82c0172407b43c99c1f6befc9fc5
                pp: '1'
                precision: mxfp4
                tp: '1'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 1
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: LLM ENGINE
              value: VLLM
        - profileId: nim/openai/gpt-oss-20b:hf-d666cf3-nim
          framework: VLLM
          displayName: Gpt Oss 20B AnyGPUx2 MXFP4
          ngcMetadata:
            c3035169e189674226b284a07173f495b6ce13f2a06d5ea204f1e505c2fac2be:
              model: openai/gpt-oss-20b
              release: 1.12.4
              tags:
                feat_lora: 'false'
                llm_engine: vllm
                nim_workspace_hash_v1: bef4d428df8c3e67ebe56ba2050a0f50216e82c0172407b43c99c1f6befc9fc5
                pp: '1'
                precision: mxfp4
                tp: '2'
          modelFormat: vllm
          spec:
            - key: PRECISION
              value: MXFP4
            - key: COUNT
              value: 2
            - key: NIM VERSION
              value: 1.12.4
            - key: DOWNLOAD SIZE
              value: 13GB
            - key: LLM ENGINE
              value: VLLM
  labels:
    - OpenAI
    - signed images
    - NSPECT-LJGD-9W15
    - NVIDIA AI Enterprise Supported
    - NVIDIA NIM
  config:
    architectures:
      - Other
    modelType: NIM
  license: NVIDIA AI Foundation Models Community License
- name: Gemma 2
  displayName: Gemma 2
  modelHubID: gemma-2
  category: Text Generation
  type: HF
  description: Gemma 2 the second generation of the Google community Gemma lineage.  Gemma 2 is improved with higher performance with significant safety improvements and well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning.
  modelVariants:
    - variantId: Gemma 2 9B
      displayName: Gemma 2 9B
      source:
        URL: https://huggingface.co/google/gemma-2-9b
      requireToken: true
      requireLicense: true
      licenseAgreements:
        - label: License Agreement
          url: https://ai.google.dev/gemma/terms
        - label: Use Policy
          url: https://ai.google.dev/gemma/prohibited_use_policy
      optimizationProfiles:
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 9b A10G
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: google/gemma-2-9b
          displayName: Gemma 2 9b L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
  labels:
    - google
    - Gemma
    - "Text Generation"
    - "Multilingual support"
  config:
    architectures:
      - Gemma2ForCausalLM
    modelType: Gemma2
  license: gemma
- name: Llama 3 SQLCoder
  displayName: Llama 3 SQLCoder
  modelHubID: llama-3-sqlcoder-8b
  category: Text Generation
  type: HF
  description: A capable language model for text to SQL generation for Postgres, Redshift and Snowflake that is on-par with the most capable generalist frontier models.
  modelVariants:
    - variantId: Llama 3 SQLCoder 8B
      displayName: Llama 3 SQLCoder 8B
      source:
        URL: https://huggingface.co/defog/llama-3-sqlcoder-8b
      requireToken: false
      requireLicense: false
      licenseAgreements:
        - label: License Agreement
          url: https://choosealicense.com/licenses/cc-by-sa-4.0/
      optimizationProfiles:
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B A10G
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A10G
            - key: COUNT
              value: 1
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B A100
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: A100
            - key: COUNT
              value: 1
        - profileId: Defog/Llama-3-sqlcoder-8B
          displayName: Llama 3 SQLCoder 8B L40S
          framework: vllm
          sha: vllm
          modelFormat: vllm
          spec:
            - key: GPU
              value: L40S
            - key: COUNT
              value: 1
  labels:
    - Llama
    - "Text To SQL"
    - "Code Generation"
    - "Fine Tuned"
  config:
    architectures:
      - LlamaForCausalLM
    modelType: llama
  license: Creative Commons Attribution Share Alike 4.0
