models:
- name: Llama 3.3 70B Instruct
  displayName: Llama 3.3 70B Instruct
  modelHubID: llama-3.3-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.3 70B-Instruct NIM simplifies the deployment of the Llama 3.3 70B instruction tuned model which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://www.llama.com/llama3_3/use-policy/
  - label: License Agreement
    url: https://www.llama.com/llama3_3/license/
  modelVariants:
  - variantId: Llama 3.3 70B Instruct
    modelCard: {
    "accessType": "NOT_LISTED",
    "application": "Other",
    "bias": "",
    "canGuestDownload": false,
    "createdDate": "2025-01-08T04:54:23.525Z",
    "description": "# **Llama-3.3-70B-Instruct Overview**\n\n## **Description:**\n\n**Llama-3.3-70B-Instruct** is an auto-regressive language model that uses an optimized transformer architecture. It is designed for text-based tasks such as multilingual chat, coding assistance, and synthetic data generation, and is particularly optimized for dialogue-based use cases. With 70 billion parameters, it provides strong performance that is comparable to larger models but with lower hardware requirements, and it does not process images or audio.\n\nThis model is ready for commercial/non-commercial use.\n\nThis version introduces support for GB200 NVL72, GH200 NVL2, B200 and NVFP4. CUDA updated to version 12.9. For detailed information, refer to Release [Notes for NVIDIA NIM for LLMs LLM 1.12](https://docs.nvidia.com/nim/large-language-models/latest/release-notes.html). \n\n## **Third-Party Community Consideration**\n\nThis model is not owned or developed by NVIDIA. This model has been developed and built to a third-party's requirements for this application and use case; see link to Non-NVIDIA\\[meta-llama/Llama-3.3-70B-Instruct\\]  \n([https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)). \n\n## **License/Terms of Use:**\n\n**GOVERNING TERMS:** The NIM container is governed by the [NVIDIA Software License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the [Product-Specific Terms for NVIDIA AI Products](https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/); and the model is governed by the [NVIDIA AI Foundation Models Community License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-ai-foundation-models-community-license-agreement/). \n\n\n**ADDITIONAL INFORMATION**: [Llama 3.3 Community License Agreement](https://www.llama.com/llama3_3/license/). Built with Llama.\n\n## **Get Help**\n\n### Enterprise Support\nGet access to knowledge base articles and support cases or [submit a ticket](https://www.nvidia.com/en-us/data-center/products/ai-enterprise-suite/support/).\n\nYou are responsible for ensuring that your use of NVIDIA provided models complies with all applicable laws.\n\n## **Deployment Geography:**\n\nGlobal \n\n## **Use Case:**\n\nThis model is intended for developers, researchers, and enterprises. They would integrate it into applications and workflows for a variety of advanced text-based tasks.\n\n* For Conversational AI: Building sophisticated and natural-sounding chatbots for customer service, multilingual virtual assistants, and interactive dialogue systems.  \n* For Software Development: Engineers might use the model as a powerful coding assistant for generating code, debugging, explaining complex algorithms, and writing documentation.  \n* For Content Creation and Analysis: Businesses and content creators might use the model  to draft emails, generate marketing copy, summarize long documents, and create synthetic text data to train other machine learning models.\n\n## **Release Date:**\n\nBuild.Nvidia.com 12/17/2024 via  \n[llama-3.3-70b-instruct Model by Meta | NVIDIA NIM](https://build.nvidia.com/meta/llama-3_3-70b-instruct)\n\nGithub 12/13/2024 via   \n[https://github.blog/changelog/2024-12-13-llama-3-3-70b-instruct-is-now-available-on-github-models-ga/](https://github.blog/changelog/2024-12-13-llama-3-3-70b-instruct-is-now-available-on-github-models-ga/)\n\nHuggingface 12/06/2024 via   \n[https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) \n\n**Reference(s):** \n\n[https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)\n\n## **Model Architecture:** \n\nArchitecture Type: Transformer  \nNetwork Architecture: Llama-3.3-70B\n\nThis model was developed based on Meta-Llama-3.3-70B  \n[https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct).\n\nNumber of model parameters: 7.06*10^10\n\n## **Input:**\n\nInput Type(s): Text \n\nInput Format(s): String \n\nInput Parameters: One-Dimensional (1D)\n\nOther Properties Related to Input: The model processes input as tokens. The maximum context length is 8,192 tokens. Input text strings must be pre-processed by the model's specific Tiktoken tokenizer before being fed into the model.\n\n## **Output:**\n\nOutput Type(s): Text \n\nOutput Format(s): String\n\nOutput Parameters: One-Dimensional (1D)\n\nOther Properties Related to Output: The model generates text as a sequence of tokens. The length of the generated output can be controlled by inference parameters. The raw token output requires post-processing (de-tokenization) to be converted into a human-readable string.\n\nOur AI models are designed and/or optimized to run on NVIDIA GPU-accelerated systems. By leveraging NVIDIA's hardware (e.g. GPU cores) and software frameworks (e.g., CUDA libraries), the model achieves faster training and inference times compared to CPU-only solutions.\n\n## **Software Integration:**\n\nRuntime Engine: vLLM, TensorRT\n\nSupported Hardware Microarchitecture Compatibility:\n\nNVIDIA Ampere  \nNVIDIA Blackwell  \nNVIDIA Hopper  \nNVIDIA Lovelace \n\nPreferred Operating System(s):\n\nLinux   \nWindows\n\nThe integration of foundation and fine-tuned models into AI systems requires additional testing using use-case-specific data to ensure safe and effective deployment. Following the V-model methodology, iterative testing and validation at both unit and system levels are essential to mitigate risks, meet technical and functional requirements, and ensure compliance with safety and ethical standards before deployment.\n\n## **Model Version(s):**\n\nLlama-3.3-70B-Instruct\n\n## **Usage**\n\n### **Use with transformers**\n\nStarting with transformers \\>= 4.45.0 onward, you can run conversational inference using the Transformers pipeline abstraction or by leveraging the Auto classes with the generate() function.\n\nMake sure to update your transformers installation via pip install \\--upgrade transformers.\n\nSee the snippet below for usage with Transformers:\n\n```\nimport transformers\nimport torch\n\nmodel_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\n\noutputs = pipeline(\n    messages,\n    max_new_tokens=256,\n)\nprint(outputs[0][\"generated_text\"][-1])\n```\n\n### **Tool use with transformers**\n\nLLaMA-3.3 supports multiple tool use formats. You can see a full guide to prompt formatting [here](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/).\n\nTool use is also supported through [chat templates](https://huggingface.co/docs/transformers/main/chat_templating#advanced-tool-use--function-calling) in Transformers. Here is a quick example showing a single simple tool:\n\n```\n# First, define a tool\ndef get_current_temperature(location: str) -> float:\n    \"\"\"\n    Get the current temperature at a location.\n    \n    Args:\n        location: The location to get the temperature for, in the format \"City, Country\"\n    Returns:\n        The current temperature at the specified location in the specified units, as a float.\n    \"\"\"\n    return 22.  # A real function should probably actually get the temperature!\n\n# Next, create a chat and apply the chat template\nmessages = [\n  {\"role\": \"system\", \"content\": \"You are a bot that responds to weather queries.\"},\n  {\"role\": \"user\", \"content\": \"Hey, what's the temperature in Paris right now?\"}\n]\n\ninputs = tokenizer.apply_chat_template(messages, tools=[get_current_temperature], add_generation_prompt=True)\n```\n\nYou can then generate text from this input as normal. If the model generates a tool call, you should add it to the chat like so:\n\n```\ntool_call = {\"name\": \"get_current_temperature\", \"arguments\": {\"location\": \"Paris, France\"}}\nmessages.append({\"role\": \"assistant\", \"tool_calls\": [{\"type\": \"function\", \"function\": tool_call}]})\n```\n\nand then call the tool and append the result, with the tool role, like so:\n\n```\nmessages.append({\"role\": \"tool\", \"name\": \"get_current_temperature\", \"content\": \"22.0\"})\n```\n\nAfter that, you can generate() again to let the model use the tool result in the chat. Note that this was a very brief introduction to tool calling \\- for more information, see the [LLaMA prompt format docs](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/) and the Transformers [tool use documentation](https://huggingface.co/docs/transformers/main/chat_templating#advanced-tool-use--function-calling).\n\n### **Use with bitsandbytes**\n\nThe model checkpoints can be used in 8-bit and 4-bit for further memory optimisations using bitsandbytes and transformers\n\nSee the snippet below for usage:\n\n```\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_id = \"meta-llama/Llama-3.3-70B-Instruct\"\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\n\nquantized_model = AutoModelForCausalLM.from_pretrained(\n    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=quantization_config)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ninput_text = \"What are we having for dinner?\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n\noutput = quantized_model.generate(**input_ids, max_new_tokens=10)\n\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n```\n\nTo load in 4-bit simply pass load\\_in\\_4bit=True\n\n### **Use with llama**\n\nPlease, follow the instructions in the [repository](https://github.com/meta-llama/llama).\n\nTo download Original checkpoints, see the example command below leveraging huggingface-cli:\n\n```\nhuggingface-cli download meta-llama/Llama-3.3-70B-Instruct --include \"original/*\" --local-dir Llama-3.3-70B-Instruct\n```\n\n## **Training, Testing, and Evaluation Datasets:**\n\n### **Training Dataset**\n\n**Data Modality:** Text \n\n\n**Link:** Undisclosed\n\n**Data Collection Method:** Hybrid: Human, Synthetic, Automated\n\n**Labeling Method:** Hybrid: Human, Synthetic\n\n**Properties:** \n\nThe pre-training dataset contains over 15 trillion (15T) tokens from a diverse mix of publicly available online sources. The fine-tuning dataset consists of prompts and preference-ranked responses designed to improve helpfulness and safety.\n\n### **Testing Dataset**\n\n**Link:** Undisclosed\n\n**Data Collection Method:** Hybrid: Human, Synthetic, Automated\n\n**Labeling Method:** Hybrid: Human, Automated\n\n**Properties:** \n\nThe public datasets cover a wide range of tasks including massive multitask language understanding (MMLU), problem-solving (GSM8K), and code generation (HumanEval). Meta's internal evaluation set contains over 2,000 prompts designed to test for safety and helpfulness across various potentially risky categories. \n\n### **Evaluation Dataset**\n\n**Link:** Undisclosed\n\n**Data Collection Method:** Hybrid: Automated, Human, Synthetic\n\n**Labeling Method:** Hybrid: Human, Automated\n\n**Properties:** \n\nThe public datasets are industry-standard benchmarks designed to evaluate diverse capabilities like general knowledge, reasoning, coding, and math. For example, MMLU tests multitask knowledge, HumanEval tests code generation, and GSM8K tests grade-school math word problems. Meta's private evaluation set contains over 2,000 prompts for assessing safety and helpfulness.\n\n**Detailed Performance:**\n\n| Category | Benchmark | \\# Shots | Metric | Llama 3.1 8B Instruct | Llama 3.1 70B Instruct | Llama-3.3 70B Instruct | Llama 3.1 405B Instruct |\n| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |\n|  | MMLU (CoT) | 0 | macro\\_avg/acc | 73.0 | 86.0 | 86.0 | 88.6 |\n|  | MMLU Pro (CoT) | 5 | macro\\_avg/acc | 48.3 | 66.4 | 68.9 | 73.3 |\n| Steerability | IFEval |  |  | 80.4 | 87.5 | 92.1 | 88.6 |\n| Reasoning | GPQA Diamond (CoT) | 0 | acc | 31.8 | 48.0 | 50.5 | 49.0 |\n| Code | HumanEval | 0 | pass@1 | 72.6 | 80.5 | 88.4 | 89.0 |\n|  | MBPP EvalPlus (base) | 0 | pass@1 | 72.8 | 86.0 | 87.6 | 88.6 |\n| Math | MATH (CoT) | 0 | sympy\\_intersection\\_score | 51.9 | 68.0 | 77.0 | 73.8 |\n| Tool Use | BFCL v2 | 0 | overall\\_ast\\_summary/macro\\_avg/valid | 65.4 | 77.5 | 77.3 | 81.1 |\n| Multilingual | MGSM | 0 | em | 68.9 | 86.9 | 91.1 | 91.6 |\n\n## **Technical Limitations** \n\nTesting conducted to date has not covered, nor could it cover, all scenarios. For these reasons, as with all LLMs, the model's potential outputs cannot be predicted in advance, and the model may in some instances produce inaccurate, biased or other objectionable responses to user prompts. Therefore, before deploying this model in any applications, developers should perform safety testing and tuning tailored to their specific applications. Please refer to available resources including the [Responsible Use Guide](https://llama.meta.com/responsible-use-guide), [Trust and Safety](https://llama.meta.com/trust-and-safety/) solutions, and other [resources](https://llama.meta.com/docs/get-started/) to learn more about responsible development. \n\n## **Inference:**\n\n**Acceleration Engine:** vLLM, TensorRT \n\n**Test Hardware:** \n   \n* B200 SXM   \n* H200 SXM  \n* H100 SXM  \n* A100 SXM 80GB  \n* A100 SXM 40GB  \n* L40S PCIe  \n* A10G  \n* H100 NVL  \n* H200 NVL  \n* GH200 96GB    \n* GB200 NVL72\n* GH200 NVL2\n* RTX 5090  \n* RTX 4090  \n* RTX 6000 Ada\n\n## **Ethical Considerations:**\n\nNVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications. When downloaded or used in accordance with our terms of service, developers should work with their internal model team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse. Please report security vulnerabilities or NVIDIA AI Concerns [here](https://www.nvidia.com/en-us/support/submit-security-vulnerability/).\n\nYou are responsible for ensuring that your use of NVIDIA provided models complies with all applicable laws.",
    "displayName": "Llama-3.3-70B-Instruct",
    "explainability": "",
    "framework": "Other",
    "hasPlayground": false,
    "hasSignedVersion": true,
    "isPlaygroundEnabled": false,
    "isPublic": false,
    "isReadOnly": true,
    "labels": [
        "NSPECT-L26U-IFIN",
        "nvaie:model:nvaie_supported",
        "nvidia_nim:model:nimmcro_nvidia_nim",
        "productNames:nim-dev",
        "productNames:nv-ai-enterprise"
    ],
    "latestVersionIdStr": "rtx6000-blackwell-svx4-throughput-bf16-jdijd32qrq",
    "latestVersionSizeInBytes": 148279696110,
    "logo": "https://assets.ngc.nvidia.com/products/api-catalog/images/llama-3_3-70b-instruct.jpg",
    "modelFormat": "N/A",
    "name": "llama-3.3-70b-instruct",
    "orgName": "nim",
    "precision": "N/A",
    "privacy": "",
    "productNames": [
        "nim-dev",
        "nv-ai-enterprise"
    ],
    "publicDatasetUsed": {},
    "publisher": "Meta",
    "safetyAndSecurity": "",
    "shortDescription": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out).",
    "teamName": "meta",
    "updatedDate": "2025-10-28T20:37:46.241Z"
}
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x1-throughput-fp8-r-6bjqwx5a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        02f132ac03fb2ab51b82d88abce83b64feb565c93ad1d54f3b2ab04b7c86b21f:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 70c427b55c83a3c54340d828ce94b546ad566be2ec930f0bd760a00927b4b180
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x2-throughput-bf16-5hyfmddv4a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x2 BF16 Throughput
      ngcMetadata:
        12c295e09aa3a3bac95522db7c0af51e27d6a4283b0402298c98691fc121a8ae:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 517f622a203fd1bdf58c0ba179d9be37fa1917c1f49e0a5aa85c7f5d3b8731b3
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 135GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-latency-bf16-of3qbtqvsg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Latency
      ngcMetadata:
        168f348ad80045c0a730210c796a66ccf83768df25543f8b0567c1e186be9ad6:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 00a7b1bb5360bc13540061f29a07344a7aa2feefc46f7f7ff355131ba9d4690d
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-latency-bf16-cp-xxbkpta
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x4 BF16 Latency
      ngcMetadata:
        41bc6ff1de6d3dcfe33b8070b32a89946b55b5770c92c82ffb8bb87b8e3fc9d7:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7c9d81be68e9ba750798e8c48585ebbce4d271d36981e30f09019e011d8e389a
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-fp8-vl02sw2m-g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Latency
      ngcMetadata:
        52050fe50397b0b158fafe24a0c1e74efad0d04351274757337c86fc99968dd9:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a9d77447899d9eb9de5254bf262250c7321a6522f30d485abd4072fc1de36dcc
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a10gx8-throughput-bf16-rl2yes9ktw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx8 BF16 Throughput
      ngcMetadata:
        613255b124f05cbf875c142c5ea7c2e3ebb7754a8a5473ad828d2bb07e2eaa88:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c0f0a6abdd6734299ec6f65611fa66490fd46303035100f9c865dd5d3c1dfb19
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-throughput-bf16-lciwvjwxkw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 BF16 Throughput
      ngcMetadata:
        64878d614ca9a859228cd55d140af0865823c2f3524e43c7be53c01c039481b6:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 824477061f9c69bd79fd248a136a273e8d861d092fb853ede5e06e12510d8188
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x4-throughput-bf16-lyvveim8va
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x4 BF16 Throughput
      ngcMetadata:
        76e28450af746bb7626af7e5e2db4b57b56f11f5b6632a120eefabba925c2b15:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f14e1bad1a0e78da150aeedfee7919ab3ef21def09825caffef460b93fdde9b7
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-bf16-rhzeshgk8w
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Throughput
      ngcMetadata:
        7cb838de5dad2c42066f0616756d0ad2708939c450b95416d41098e9931470c1:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c419c6ba54c118a6deb6ed9918e9c72e7f151698116c1d3c2bc32042a94d6bbb
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-bf16-m9pz-s1ymq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 BF16 Throughput
      ngcMetadata:
        7ed84ed093e8c5e8d237966262d640c6c2f160a8606df22e869e6f7a5a83cc96:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 5006533ca6b5151e94f18d8e518c68965918f248d0680b23e9fc0e4553e0d9ef
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-fp8-wbna-gqhxw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 FP8 Throughput
      ngcMetadata:
        7f4107d806d19c2c2beb2e870bf01217de37a247f27ee168985fc42a9576c641:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0013e870ea929584ec13dad6948450024cdc6c2f03a865f1b050fb08b9f64312
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-latency-fp8-ozazyo6fjw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 FP8 Latency
      ngcMetadata:
        92e9707e66c742310e9a7a6d38e162b2578375c8fe0844939c499a00116a994e:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 138ef4644a3d6477c3deaf2cd22f548d3396925db62f4752fb73b52b7b8a4a29
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-latency-fp8-mg52y2fpwq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Latency
      ngcMetadata:
        a2003c7b2b19b79aefb52cd9daa58fb20f0520dd9759037ff34e67110f384218:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8a5f27c50cf45f7d1a1e504bcd33820eefa80539b94a68bbf015c3f4f4cb2c3f
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-fp8-sx6as-ue-a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Throughput
      ngcMetadata:
        cf120c3ecf2025e6a170cb224802ca6a02cbeec3ad74944a69263b3193a64fa2:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b118ae4fb04a6bbcf439004b94edd4815d2c965a0c692c2b98a790580c9c3f7b
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-latency-bf16-rasfmhw4uw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 BF16 Latency
      ngcMetadata:
        e6d1855d3f24e439b904cf1fd47d3e136bec4af9134c039558c61f9ae34593af:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8747b7e093d3b26e808e8bbebdb50c3ac0a0f82402c58b3430a8760ff96e406e
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-bf16-bpwvcpvnsq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 BF16 Throughput
      ngcMetadata:
        fbec99d055ebc70d1261d9520f1f6f854fb0a84771bdadde30668dca1f081c7d:
          model: meta/llama-3.3-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2eb1d578e4e069c384bf617e5354889d043a1c72b77f432c07e06ffb1b8be36b
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Llama
  - Meta
  - Chat
  - Text Generation
  - Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
