models:
- name: Llama 3.3 70B Instruct
  displayName: Llama 3.3 70B Instruct
  modelHubID: llama-3-3-70b-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.3 70B-Instruct NIM simplifies the deployment of the Llama 3.3 70B instruction tuned model which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://www.llama.com/llama3_3/use-policy/
  - label: License Agreement
    url: https://www.llama.com/llama3_3/license/
  modelVariants:
  - variantId: Llama 3.3 70B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-latency-fp8-z88enisl8a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 FP8 Latency
      ngcMetadata:
        233973ff86b33b1076b8d8dfbf1b1c292ad224ae2d9c8b18f28a44b6f6f42768:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 70GB
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-fp8-daydbgtrgg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Throughput
      ngcMetadata:
        3d0e5989f2fbc23e7d4504cd69269c9636deb61d0efc12225d3d59d54afea297:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx8-throughput-bf16-essm4-kcrg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx8 BF16 Throughput
      ngcMetadata:
        60b95dfcc3a17bf00cabb2da1a264f5e8757763d0ebe2a3a073c5c0fc7c078ec:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 151GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-latency-fp8-tkp3aadetg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Latency
      ngcMetadata:
        6d6d2aebdecec52d7982746f98b00421cf53e10295a9ac7f993e4554fa164d10:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-latency-bf16-kwqeyhgvua
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 BF16 Latency
      ngcMetadata:
        758482618a1f166cc4e620228600410a6f05649a05c1838d5a93572d44289b95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 147GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-fp8-cqigo1kenw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Throughput
      ngcMetadata:
        7d8a02f47911fb7ddf1a6f6b09438f621b6057cb21098999484f09d5a5bb7b23:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-fp8--pwiqokzsa
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 FP8 Throughput
      ngcMetadata:
        7ee2258631ed9d51ebfe5ab44bd547ae5777217686d87cc89c15d06ccdca4047:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-bf16-ygpeeau-0q
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 BF16 Throughput
      ngcMetadata:
        7f99ed5107c79b938b0ef4fcf2dd21aac27281f71d41a0a7c46d649879d374f0:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 138GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-throughput-bf16-2i0l24npsg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 BF16 Throughput
      ngcMetadata:
        d128c772583bd10da4f31bf8e961893eb2b62363f3cecb94b5ef67d8bbd54665:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 147GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx8 BF16
      ngcMetadata:
        1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '8'
            trtllm_buildable: 'true'
            gpu: A10G
            gpu_device: 2237:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx8 BF16
      ngcMetadata:
        1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '8'
            trtllm_buildable: 'true'
            gpu: L40S
            gpu_device: 26b9:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 BF16
      ngcMetadata:
        1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '8'
            trtllm_buildable: 'true'
            gpu: H100
            gpu_device: 2330:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx2 BF16
      ngcMetadata:
        375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '2'
            trtllm_buildable: 'true'
            gpu: A10G
            gpu_device: 2237:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx2 BF16
      ngcMetadata:
        375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '2'
            trtllm_buildable: 'true'
            gpu: L40S
            gpu_device: 26b9:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 BF16
      ngcMetadata:
        375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '2'
            trtllm_buildable: 'true'
            gpu: H100
            gpu_device: 2330:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A10Gx4 BF16
      ngcMetadata:
        54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '4'
            trtllm_buildable: 'true'
            gpu: A10G
            gpu_device: 2237:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 BF16
      ngcMetadata:
        54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '4'
            trtllm_buildable: 'true'
            gpu: L40S
            gpu_device: 26b9:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 BF16
      ngcMetadata:
        54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '4'
            trtllm_buildable: 'true'
            gpu: H100
            gpu_device: 2330:10de
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
  labels:
  - Llama
  - Meta
  - Chat
  - Text Generation
  - Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
