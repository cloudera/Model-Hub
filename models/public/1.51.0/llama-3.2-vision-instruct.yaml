models:
- name: Llama 3.2 Vision Instruct
  displayName: Llama 3.2 Vision Instruct
  modelHubID: llama-3.2-vision-instruct
  category: Image to Text Generation
  type: NGC
  description: The Llama 3.2 Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://llama.meta.com/llama3/use-policy/
  - label: License Agreement
    url: https://llama.meta.com/llama3/license/
  modelVariants:
  - variantId: Llama 3.2 11B  Vision Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.2-11b-vision-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-bf16-latency.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct H100 BF16 Latency
      sha: 126d5a664ba4b6b4557d5e0225b51a5e2ffbf9e9909bfe25ed203bec421ea2e5
      ngcMetadata:
        126d5a664ba4b6b4557d5e0225b51a5e2ffbf9e9909bfe25ed203bec421ea2e5:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-bf16-latency.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx4-bf16-throughput.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct A10G BF16 Throughput
      sha: 417611b3f9e2c25db671083acfcfd4c2340f511f3533838fc6366bb47960915c
      ngcMetadata:
        417611b3f9e2c25db671083acfcfd4c2340f511f3533838fc6366bb47960915c:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx4-bf16-throughput.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2237:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx8-bf16-latency.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct A10G BF16 Latency
      sha: 5a9f2d4459908cf6c5b5222e31b8df053c00354b5866f6ee3b8de7552a695524
      ngcMetadata:
        5a9f2d4459908cf6c5b5222e31b8df053c00354b5866f6ee3b8de7552a695524:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'trtllm_engine/rank4.engine'
                - !name 'trtllm_engine/rank5.engine'
                - !name 'trtllm_engine/rank6.engine'
                - !name 'trtllm_engine/rank7.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a10gx8-bf16-latency.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-latency.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct H100 FP8 Latency
      sha: ab89f816413848c86e311123d2ed98af7bcda0c3624b0a6c4d43704b720585d5
      ngcMetadata:
        ab89f816413848c86e311123d2ed98af7bcda0c3624b0a6c4d43704b720585d5:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-latency.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 12GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x2-bf16-latency.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct A100 BF16 Latency
      sha: ad16e693a234cf8eee85c43dd66ab4502c51ab0bc553af1644477a4f966bf5c6
      ngcMetadata:
        ad16e693a234cf8eee85c43dd66ab4502c51ab0bc553af1644477a4f966bf5c6:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x2-bf16-latency.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20b2:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx2-bf16-throughput.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct L40S BF16 Throughput
      sha: b16d5969212a8cea632fd6f70928ab514aab835cf217281899564933e6cafa5b
      ngcMetadata:
        b16d5969212a8cea632fd6f70928ab514aab835cf217281899564933e6cafa5b:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx2-bf16-throughput.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-bf16-throughput.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct H100 BF16 Throughput
      sha: b7aa6bf9d9946de665480a5669bb73f981eab7c4fe43ddf7217b672eb11a003a
      ngcMetadata:
        b7aa6bf9d9946de665480a5669bb73f981eab7c4fe43ddf7217b672eb11a003a:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-bf16-throughput.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx4-bf16-latency.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct L40S BF16 Latency
      sha: be5af3c968ce6bc45e740edc985fa05dffd3695abb7cc5723407e1f5e3f12c70
      ngcMetadata:
        be5af3c968ce6bc45e740edc985fa05dffd3695abb7cc5723407e1f5e3f12c70:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx4-bf16-latency.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x1-bf16-throughput.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct A100 BF16 Throughput
      sha: ee1e936b878082dee74574deae5064cc7fba3e11ba155de1198ee544d7c3468a
      ngcMetadata:
        ee1e936b878082dee74574deae5064cc7fba3e11ba155de1198ee544d7c3468a:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-a100x1-bf16-throughput.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20b2:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 20GB
    - profileId: nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-fp8-throughput.0.3.20143152
      framework: TensorRT-LLM
      displayName: Llama 3.2 11B Vision Instruct H100 FP8 Throughput
      sha: fa1e1cbf698be85c0cc56d707f8bc5b17044e091136dae3f8e4be694af727c87
      ngcMetadata:
        fa1e1cbf698be85c0cc56d707f8bc5b17044e091136dae3f8e4be694af727c87:
          model: meta/llama-3.2-11b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x1-fp8-throughput.0.3.20143152
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:hf-cee5b78-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-11b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 12GB
  - variantId: Llama 3.2 90B  Vision Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.2-90b-vision-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-bf16-throughput.0.3.20194742
      framework: TensorRT-LLM
      displayName: Llama 3.2 90B Vision Instruct H100 BF16 Throughput
      sha: 42c91902414bc5ea7f4ef4e9a34ef382165b8b65f9adcc5d1abaf195ade2d8fc
      ngcMetadata:
        42c91902414bc5ea7f4ef4e9a34ef382165b8b65f9adcc5d1abaf195ade2d8fc:
          model: meta/llama-3.2-90b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-bf16-throughput.0.3.20194742
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 166GB
    - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-throughput.0.3.20194742
      framework: TensorRT-LLM
      displayName: Llama 3.2 90B Vision Instruct H100 FP8 Throughput
      sha: 6b24bf2e19c23b85f9d2651efdc2de08cd179a03c50f942b1dcd856fa4d4074b
      ngcMetadata:
        6b24bf2e19c23b85f9d2651efdc2de08cd179a03c50f942b1dcd856fa4d4074b:
          model: meta/llama-3.2-90b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x2-fp8-throughput.0.3.20194742
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 85GB
    - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx8-bf16-throughput.0.3.1342
      framework: TensorRT-LLM
      displayName: Llama 3.2 90B Vision Instruct L40S BF16 Throughput
      sha: 7bb72cbd19b5eab69ed21b2e031e4ea18909ff034255471c25b29ab45a99cc8b
      ngcMetadata:
        7bb72cbd19b5eab69ed21b2e031e4ea18909ff034255471c25b29ab45a99cc8b:
          model: meta/llama-3.2-90b-vision-instruct
          release: 1.1.1
          tags:
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'trtllm_engine/rank4.engine'
                - !name 'trtllm_engine/rank5.engine'
                - !name 'trtllm_engine/rank6.engine'
                - !name 'trtllm_engine/rank7.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-l40sx8-bf16-throughput.0.3.1342
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 166GB
    - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-fp8-latency.0.3.20194742
      framework: TensorRT-LLM
      displayName: Llama 3.2 90B Vision Instruct H100 FP8 Latency
      sha: a6e9fde5c1edfb4ab4c0b206a536693a6f9b1f95cde1448ddd679fb880fcef71
      ngcMetadata:
        a6e9fde5c1edfb4ab4c0b206a536693a6f9b1f95cde1448ddd679fb880fcef71:
          model: meta/llama-3.2-90b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x4-fp8-latency.0.3.20194742
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: null
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 87GB
    - profileId: nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x8-bf16-latency.0.3.20194742
      framework: TensorRT-LLM
      displayName: Llama 3.2 90B Vision Instruct H100 BF16 Latency
      sha: e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83
      ngcMetadata:
        e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83:
          model: meta/llama-3.2-90b-vision-instruct
          release: 1.1.1
          tags:
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'trtllm_engine/config.json'
                - !name 'trtllm_engine/metadata.json'
                - !name 'trtllm_engine/rank0.engine'
                - !name 'trtllm_engine/rank1.engine'
                - !name 'trtllm_engine/rank2.engine'
                - !name 'trtllm_engine/rank3.engine'
                - !name 'trtllm_engine/rank4.engine'
                - !name 'trtllm_engine/rank5.engine'
                - !name 'trtllm_engine/rank6.engine'
                - !name 'trtllm_engine/rank7.engine'
                - !name 'visual_engine/config.json'
                - !name 'visual_engine/metadata.json'
                - !name 'visual_engine/visual_encoder.engine'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:0.15.0.dev2024102300+ea8391c56-h100x8-bf16-latency.0.3.20194742
            - dst: ''
              src:
                files:
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'preprocessor_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b
            - dst: ''
              src:
                files:
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:hf-0a6d69b-tok
            - dst: visual_engine
              src:
                files:
                - !name 'vision_processor.py'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:vision-processor
            - dst: ''
              src:
                files:
                - !name 'runtime_params.json'
                repo_id: ngc://nim/meta/llama-3.2-90b-vision-instruct:runtime-params-trtllm
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.1.1
      - key: DOWNLOAD SIZE
        value: 166GB
  labels:
  - Llama
  - Meta
  - Chat
  - Large Language Model
  - TensorRT-LLM
  - Vision Instruct
  - Image to Text Generation
  - Language Generation
  - NeMo
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
