models:
- name: Llama 3.1 Instruct
  displayName: Llama 3.1 Instruct
  modelHubID: llama-3.1-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.1 70B-Instruct, 8B instruct and 8B base NIM simplifies the deployment of the Llama 3.1 70B-Instruct, 8B instruct and 8B base tuned models which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://llama.meta.com/llama3/use-policy/
  - label: License Agreement
    url: https://llama.meta.com/llama3/license/
  modelVariants:
  - variantId: Llama 3.1 70B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-70b-instruct-nemo
    optimizationProfiles:
    - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x4-fp8-throughput.1.2.18099809
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100 FP8 Throughput
      sha: 4e0aeeefd4dfeae46ad40f16238bbde8858850ce0cf56c26449f447a02a9ac8f
      ngcMetadata:
        4e0aeeefd4dfeae46ad40f16238bbde8858850ce0cf56c26449f447a02a9ac8f:
          container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
          model: meta/llama-3.1-70b-instruct
          release: 1.2.0
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x4-fp8-throughput.1.2.18099809
      latestVersionSizeInBytes: 91738571464
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.1
      - key: DOWNLOAD SIZE
        value: 91GB
    - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x8-fp8-latency.1.2.18099809
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100 FP8 Latency
      sha: 5296eed82c6309b64b13da03fbb843d99c3276effd6a0c51e28ad5bb29f56017
      ngcMetadata:
        5296eed82c6309b64b13da03fbb843d99c3276effd6a0c51e28ad5bb29f56017:
          container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
          model: meta/llama-3.1-70b-instruct
          release: 1.2.0
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: latency
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                - !name 'rank4.engine'
                - !name 'rank5.engine'
                - !name 'rank6.engine'
                - !name 'rank7.engine'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+14957bf8-h100x8-fp8-latency.1.2.18099809
      latestVersionSizeInBytes: 100947599129
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.1
      - key: DOWNLOAD SIZE
        value: 101GB
    - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x8-bf16-latency.1.1.0.16791804
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100 BF16 Latency
      sha: 5d901178874ec94514eb470ba3a412ff5585ea691b63854653020ea46c838fda
      ngcMetadata:
        5d901178874ec94514eb470ba3a412ff5585ea691b63854653020ea46c838fda:
          container_url: nvcr.io/nim/meta/llama-3_1-70b-instruct:1.0.0
          model: meta/llama-3_1-70b-instruct
          model_type: text_generation
          release: 1.0.0
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'README.md'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'patch.diff'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-0722
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                - !name 'rank4.engine'
                - !name 'rank5.engine'
                - !name 'rank6.engine'
                - !name 'rank7.engine'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x8-bf16-latency.1.1.0.16791804
      latestVersionSizeInBytes: 157817895406
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.1
      - key: DOWNLOAD SIZE
        value: 157GB
    - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x4-bf16-throughput.1.1.0.16791804
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100 BF16 Throughput
      sha: 95f75ec64117af224c819780667ab16b49e939493d59d1e885fd05eda7609dfd
      ngcMetadata:
        95f75ec64117af224c819780667ab16b49e939493d59d1e885fd05eda7609dfd:
          container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
          model: meta/llama-3.1-70b-instruct
          release: 1.2.0
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-h100x4-bf16-throughput.1.1.0.16791804
      latestVersionSizeInBytes: 148355721341
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.1
      - key: DOWNLOAD SIZE
        value: 148GB
    - profileId: nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-l40sx8-bf16-throughput.1.1.0.4258
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct L40S BF16 Throughput
      sha: e994500d8b0e10f63a08e6a90143a60c360d004f6d5ea8bdb4d38d215eb3fa83
      ngcMetadata:
        998336d555bc28bc49069f2e989e4c2e0e2fac2914f2393941dba1e2e047f5c3:
          container_url: nvcr.io/nim/meta/llama-3.1-70b-instruct:1.2.0
          model: meta/llama-3.1-70b-instruct
          release: 1.2.0
          tags:
            feat_lora: false
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:hf-1d54af3-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                - !name 'rank4.engine'
                - !name 'rank5.engine'
                - !name 'rank6.engine'
                - !name 'rank7.engine'
                repo_id: ngc://nim/meta/llama-3_1-70b-instruct:0.11.1+ba20956e-l40sx8-bf16-throughput.1.1.0.4258
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.2.1
      - key: DOWNLOAD SIZE
        value: 148GB
  - variantId: Llama 3.1 8B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-8b-instruct-nemo
    optimizationProfiles:
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-latency.1.1.0.16792222
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40S BF16 Latency
      sha: 0494aafce0df9eeaea49bbca6b25fc3013d0e8a752ebcf191a2ddeaab19481ee
      ngcMetadata:
        0494aafce0df9eeaea49bbca6b25fc3013d0e8a752ebcf191a2ddeaab19481ee:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-latency.1.1.0.16792222
      latestVersionSizeInBytes: 17375862511
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 17GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x2-fp8-latency.1.2.18099815
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100 FP8 Latency
      sha: 0bc4cc784e55d0a88277f5d1aeab9f6ecb756b9049dd07c1835035211fcfe77e
      ngcMetadata:
        0bc4cc784e55d0a88277f5d1aeab9f6ecb756b9049dd07c1835035211fcfe77e:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x2-fp8-latency.1.2.18099815
      latestVersionSizeInBytes: 11611592007
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 11GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x1-fp8-throughput.1.2.18099815
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100 FP8 Throughput
      sha: 2959f7f0dfeb14631352967402c282e904ff33e1d1fa015f603d9890cf92ca0f
      ngcMetadata:
        2959f7f0dfeb14631352967402c282e904ff33e1d1fa015f603d9890cf92ca0f:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+14957bf8-h100x1-fp8-throughput.1.2.18099815
      latestVersionSizeInBytes: 10481822697
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 10GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x1-bf16-throughput.1.1.0.16803357
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100 BF16 Throughput
      sha: 7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8
      ngcMetadata:
        7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x1-bf16-throughput.1.1.0.16803357
      latestVersionSizeInBytes: 16218130050
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20b2:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 16GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x2-bf16-latency.1.1.0.16792222
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100 BF16 Latency
      sha: 7f98797c334a8b7205d4cbf986558a2b8a181570b46abed9401f7da6d236955e
      ngcMetadata:
        7f98797c334a8b7205d4cbf986558a2b8a181570b46abed9401f7da6d236955e:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x2-bf16-latency.1.1.0.16792222
      latestVersionSizeInBytes: 17294212148
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 17GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x1-bf16-throughput.1.1.0.16792222
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100 BF16 Throughput
      sha: 9cff0915527166b2e93c08907afd4f74e168562992034a51db00df802e86518c
      ngcMetadata:
        9cff0915527166b2e93c08907afd4f74e168562992034a51db00df802e86518c:
          container_url: nvcr.io/nim/meta/llama-3_1-8b-instruct:1.0.0
          model: meta/llama-3_1-8b-instruct
          model_type: text_generation
          release: 1.0.0
          tags:
            feat_lora: false
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'patch.diff'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-0722
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-h100x1-bf16-throughput.1.1.0.16792222
      latestVersionSizeInBytes: 16148612398
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 16GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-throughput.1.1.0.16792222
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40S BF16 Throughput
      sha: a534b0f5e885d747e819fa8b1ad7dc1396f935425a6e0539cb29b0e0ecf1e669
      ngcMetadata:
        a534b0f5e885d747e819fa8b1ad7dc1396f935425a6e0539cb29b0e0ecf1e669:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: L40S
            gpu_device: 26b5:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-l40sx2-bf16-throughput.1.1.0.16792222
      latestVersionSizeInBytes: 17366405962
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26b5:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 17GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx2-bf16-throughput.1.1.0.17443761
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A10G BF16 Throughput
      sha: ba515cc44a34ae4db8fe375bd7e5ad30e9a760bd032230827d8a54835a69c409
      ngcMetadata:
        ba515cc44a34ae4db8fe375bd7e5ad30e9a760bd032230827d8a54835a69c409:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx2-bf16-throughput.1.1.0.17443761
      latestVersionSizeInBytes: 17408782025
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Throughput
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2237:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 17GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x2-bf16-latency.1.1.0.16803357
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100 BF16 Latency
      sha: d880feac6596cfd7a2db23a6bcbbc403673e57dec9b06b6a1add150a713f3fe1
      ngcMetadata:
        d880feac6596cfd7a2db23a6bcbbc403673e57dec9b06b6a1add150a713f3fe1:
          container_url: nvcr.io/nim/meta/llama-3_1-8b-instruct:1.0.0
          model: meta/llama-3_1-8b-instruct
          model_type: text_generation
          release: 1.0.0
          tags:
            feat_lora: false
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'patch.diff'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-0722
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a100x2-bf16-latency.1.1.0.16803357
      latestVersionSizeInBytes: 17483962992
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20b2:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 17GB
    - profileId: nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx4-bf16-latency.1.1.0.16813141
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A10G BF16 Latency
      sha: e45b4b991bbc51d0df3ce53e87060fc3a7f76555406ed534a8479c6faa706987
      ngcMetadata:
        e45b4b991bbc51d0df3ce53e87060fc3a7f76555406ed534a8479c6faa706987:
          container_url: nvcr.io/nim/meta/llama-3.1-8b-instruct:1.2.0
          model: meta/llama-3.1-8b-instruct
          release: 1.2.2
          tags:
            feat_lora: false
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
          workspace: !workspace
            components:
            - dst: ''
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'generation_config.json'
                - !name 'model.safetensors.index.json'
                - !name 'special_tokens_map.json'
                - !name 'tokenizer.json'
                - !name 'tokenizer_config.json'
                - !name 'tool_use_config.json'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:hf-8c22764-nim1.2
            - dst: trtllm_engine
              src:
                files:
                - !name 'LICENSE.txt'
                - !name 'NOTICE.txt'
                - !name 'checksums.blake3'
                - !name 'config.json'
                - !name 'metadata.json'
                - !name 'rank0.engine'
                - !name 'rank1.engine'
                - !name 'rank2.engine'
                - !name 'rank3.engine'
                repo_id: ngc://nim/meta/llama-3_1-8b-instruct:0.11.1+ba20956e-a10gx4-bf16-latency.1.1.0.16813141
      latestVersionSizeInBytes: 19771439964
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: Latency
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2237:10de
      - key: NIM VERSION
        value: 1.2.2
      - key: DOWNLOAD SIZE
        value: 19GB
  labels:
  - Llama
  - Meta
  - Chat
  - Large Language Model
  - TensorRT-LLM
  - Language Generation
  - NeMo
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
