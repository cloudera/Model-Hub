models:
- name: Llama 3.1 Instruct
  displayName: Llama 3.1 Instruct
  modelHubID: llama-3.1-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.1 70B-Instruct, 8B instruct and 8B base NIM simplifies the deployment of the Llama 3.1 70B-Instruct, 8B instruct and 8B base tuned models which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://llama.meta.com/llama3/use-policy/
  - label: License Agreement
    url: https://llama.meta.com/llama3/license/
  modelVariants:
  - variantId: Llama 3.1 8B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-8b-instruct-nemo
    optimizationProfiles:
    - profileId: nim/meta/llama-3.1-8b-instruct:a10gx4-latency-bf16-r3bmpcovtw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A10Gx4 BF16 Latency
      ngcMetadata:
        09fec372bdcfaee0662140bc5ed522900bb0b0da7cc37ceba6209731dc55a689:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c0232176c2e5374758e3d88ea13e70aa0edca0862c923428f54b85da208960a9
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 19GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100_NVLx2 FP8 Latency
      ngcMetadata:
        0c87e2871cd7a6ea205a137109c3afde0134ba22c6fe8e978a752287cf561643:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: cb6ac7eedef673edc08e85f4f3e7525c31f499e5c5f376cbffc05cb8eefe197a
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-fp8-8imkyjutxw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x1 FP8 Throughput
      ngcMetadata:
        0cf8ac8bfbf183d8a891e9023d6aa7a1d93f6720e5bd78e578711e3d5b822c52:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2feaef51b8c016e5c678f39202dfe542c11eb5fc2443749e6c2330f3474aaffe
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h100x2-latency-fp8-cvpqroehhq
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100x2 FP8 Latency
      ngcMetadata:
        0e0a9fb28e4df4f8a2dcaafbcb03ce1e0b9d27a4e00ec273f27bcc47e7572225:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4217e8fa6ba7ac9609ee76470bec904253dadbe7fc33a52f715e08791073c501
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-fp8-i4razlnzqw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x2 FP8 Latency
      ngcMetadata:
        192d34f8204aa5c44b08406f8d98c86c606363ff8a2ca5f608b87a2516313b55:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0222120a0b05a944b22ed6b0d7376bbe89abef1c05fa6ecd7967199500398864
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200_NVLx1 BF16 Throughput
      ngcMetadata:
        1d7b8b2d964254990181ba7a6e93687275c3372b689d66b6494ad5f788a108a6:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2660946198ebbb837e487b333ef86b2ac4cbc37b907151de45f291596625f919
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_ADAx1 INT4_AWQ Throughput
      ngcMetadata:
        245a4f27515a6291ac239b37f209847384dbadaa5ad155c45d17bcc524594371:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4d714aa3567eb6e2d72aa08be91bb5fc632e7bbaa645c265104ea1d65eb28efa
            number_of_gpus: '1'
            pp: '1'
            precision: int4_awq
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: INT4_AWQ
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-bf16-zsf8rdhqtw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x1 BF16 Throughput
      ngcMetadata:
        2465a2b2fc773ea207e312352258ca9a54650fc9ec9740ae96646528556a0916:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 61348d392451059a37d2218d940f4aaf266562d0d6fa156e211f266022d5d26e
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_480GBx1 BF16 Throughput
      ngcMetadata:
        28e1523b3569391509a8e976f17c0b04e21faee7095225076a99636cbb1da858:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 828408fdd397e49bb4256a997d3f85d90c3d9a3e756531b8895cd78a83574aa6
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100_SXM4_40GBx1 BF16 Throughput
      ngcMetadata:
        40d4f2dcb13710bf7fcf1d9d41dfeb1b0ff22ba2d266bc2997a81a000fa5d031:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 72732266ad2f3d3b824f413f11716f81b87ccb602c3cdda972c7341c0d1e60b5
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h100x1-throughput-fp8-rmqqnk9ima
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100x1 FP8 Throughput
      ngcMetadata:
        4411bf23579e41275d6a994cd768d9dc2ebbd523253e2844115f24644a5e86b1:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3950ee02bc0277147b77079c0cc5bc954b9189f7866fbbebc37ece4ec31283f6
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-bf16-px49bz6jka
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x2 BF16 Latency
      ngcMetadata:
        4a7b681f1dc1dcbc0b98f4c4eaa6bdac6557af058dd878039624c68683e2dee3:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 467e29e38751b085aa13fdc92f6eaf1a08a8c360ef19718a92f64bd507221fd8
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-bf16--fupfm1fjg
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x2 BF16 Latency
      ngcMetadata:
        4b344f09436a75385ad7c78aa224f685d1f92980ccf7ea52f29a52c1ca646b70:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0a3a8da158191386b506caa79c0bd9787f45009a7e52113b82fcdde0511001d7
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:l40sx2-latency-bf16-aauqggrlkw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40Sx2 BF16 Latency
      ngcMetadata:
        55df9113a4cd134e4ddaeeae43cd33089be30b74380a9bc29d677ed9784a3492:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9b1feaf6e923581317ff4291ca09856eb403efd7acdeee1c8e787d988ced56ce
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h200x2-latency-bf16-zwyr4clzla
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200x2 BF16 Latency
      ngcMetadata:
        588fa4150abaa001f1357112de2ca65c85c1c86322b3f7d0ca9f1451f40baee5:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7b377dc3e02bbcef7ec1c0ccee4afc1d99d2409dc7ab6576f1f386ebbedeabc6
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-nvfp4-urjebtmqkg
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x2 NVFP4 Latency
      ngcMetadata:
        5eaaf502f6dab9ce29e7d034182bb56eeeb3e349633f4561018f27b3069189b3:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2693061ea8698de078f95517349178ce8894a51a97db468183032cba22ab04ae
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 6GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100_NVLx1 FP8 Throughput
      ngcMetadata:
        785d7d60df3f153a36413f29a16ac14bc5cfba73004bc7feee2bca9d78b10e6f:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a0de60706fabf3ee071fef41f0c14225a3d88799bb9728af810e57a7499f038f
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-nvfp4-6zvdbhtdna
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x1 NVFP4 Throughput
      ngcMetadata:
        78fdabce8c3eae38cea72ca3f28aaca02e3cc475c17913d6e8d4e554cba2aaa9:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d07936f83cf22e053e9fe3339050f2e05459ebcde766c94fdb7a6ac90aeb1fda
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 6GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_480GBx1 FP8 Latency
      ngcMetadata:
        7c71f0d6db2e0d52a3fbc34dabd0584ed7a27ef63a49e21aaa394d8746eeb189:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 1fa738c9de9d4b25a298b3cd021b05beab57c2c9ab5a930a3d1efcf7204fc463
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h200x1-throughput-fp8-mqkoo4u9fa
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        83fa1ce989c823d1fba445823ac58beb734bb31383a33af261a8b0808495678a:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d7e3e88abee403b365d238441ca9c1172e71745fe43cd7dce511e7d95309d237
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 NVFP4 Throughput
      ngcMetadata:
        882e2041a947f6e0793a600a4470fbbd41e7a3f3363bb4956a2c63aaa7cf51ec:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0852d2d4b6d54d6bc12acf922890bfa19e801e74276ddddcff98034ba0dc4c0f
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 FP8 Latency
      ngcMetadata:
        8855de19ef9d0f55c0213a8786591091cc5965a2c862562cc7b492c712ef09e3:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a11707b8479a7230d31a451c07c5650f0e8ff58948507a983a2e89b846929ecf
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200_NVLx2 BF16 Latency
      ngcMetadata:
        885fb853c59fc5ea3a61554797670d6f61e4b2db23f1acbc69f7e8e98846ce21:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 362023b28455913264302e9d87593459bc9930c544859af88689346e92085fea
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100_SXM4_40GBx2 BF16 Latency
      ngcMetadata:
        88b3c4d52c48162915703053126fe2d2ec64632b4508fb05dd0984904cc4b313:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 344bc1f6c75518604e27015bf9131a6dc8c5257396806f35575516bb14234706
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-bf16-qsrhtlj33g
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x1 BF16 Throughput
      ngcMetadata:
        8a33858f5392a45aa85acaab0a81601e9831cfd99507249536c63be228f09918:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3cb77524c717d774efbda1f850840b59abc39d9bd46fc2983ebc3dc1f4931ff6
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200_NVLx2 FP8 Latency
      ngcMetadata:
        8b0cd9578c1bf872d35c8da2dc72ed6f2161623840923884a8f50725ec11a4ec:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3a251730a9c214eea8101d8192f6c4c35b1d321aad615edc1e0a942521b828b0
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h100x2-latency-bf16-xhazfvu8og
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100x2 BF16 Latency
      ngcMetadata:
        8ecf55cfb8e611fb1e1579b57089060c76270bcafb322a872c751cb59ba840bc:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 782d96856a10dac93438804c42286ba3e7d0d7445d7fbd8f8497dd3c80238564
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h100x1-throughput-bf16-tgzhmf3syg
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100x1 BF16 Throughput
      ngcMetadata:
        90061152a480ade6c471a982258bf4e42dc51cf29ad9f6642120547c33bdf51f:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 04c9939245eef94e92510642382d6ad26f65a25cf1687b76ccc4e66aba70da39
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_144GBx1 BF16 Throughput
      ngcMetadata:
        9020f539c475f53d364474485cd83728454b7a340c0f1ee2d3cf505ccdcc1189:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ca7f6e7d29a1f514a9d7f4f3d731b0a0d286a9358a96287b12a1045ac9ca590b
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x2-latency-fp8-hrzafixo7g
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x2 FP8 Latency
      ngcMetadata:
        94420d0c4e672e70e91c15d5a6e23c447fa3b43f1632936eebf9cdd0c845d036:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b1e67d29794a75bf923a7224dd297dbc4aacd4d97273a7fd66dda7e8371a6da8
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 NVFP4 Latency
      ngcMetadata:
        95f587f27ab8c1467d93d12ffb7db8f3920888b4211c2ab82ef4f8de2fca61f5:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9cd258950837575782b24640b90c1cd969334d691131036208cd3c8b0735f927
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200_NVLx1 FP8 Throughput
      ngcMetadata:
        9b0e99f6e9afa6fa529d47662d85b1e6d16b3abadcc2a5e72c10486eb7c87201:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 93297aebf65f337e982d4ebd8e79f380bd9ad05346cf2e18908c6365de2b2307
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x2-latency-nvfp4-sgvjjrbeuw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x2 NVFP4 Latency
      ngcMetadata:
        9f558e6681791166fdc01cacf06f2d869b67c26f1d573738f92e5e227f820270:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: efc59c490dab28006a89a5d53a36d4ef5c5d3b0927c7d118f02014d4eb0c29e8
            number_of_gpus: '4'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 6GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:l40sx1-throughput-fp8-xad-wr2scw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40Sx1 FP8 Throughput
      ngcMetadata:
        a3e90cba8e03efc80877da3902607362c851c36e8c45cd92aada9e7cac900765:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7ebba124e3f58d0563b96377f7c85432ef3e2f393efb9e158fd308a8738abcfb
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h200x2-latency-fp8-cftgwz2fda
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200x2 FP8 Latency
      ngcMetadata:
        a826d9d8199abbe4e4084a2f64d3658ef6749b1697ecf21fd0615d1e138e368d:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6bc839be18669cae90a69af4e02503965be03b8c68b1b7ac2cf6b612033abeb8
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:a100x2-latency-bf16-oxfjg8md-a
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100x2 BF16 Latency
      ngcMetadata:
        ad582d87e490e749edcaf041d763e6c3f492962ccdbbe83e9204b48d6cfe7641:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0b1583a74d6516dd30c0bfdce8972835384f10fb4f617df4e0260fdf5092b059
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 17GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:gb200x1-throughput-nvfp4-ihgvv-o6wg
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GB200x1 NVFP4 Throughput
      ngcMetadata:
        adbc8a19059852df0c2ac75173b80f123b0901926e524a2c050ce60aa3ae5ca1:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a381f8cc9d090bc49cb320a47cdefe01b0555dc9409312516194cb19437436d0
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 6GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100_NVLx2 BF16 Latency
      ngcMetadata:
        afc6d2a8f5c1affe8524a39c78d6f083cd56ac678f9cc9f89df33b0e0e530ec5:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d0040f5636dd8d4baa9c36337ccb4157b58e47ba7118b2d54b36e2ad96061ed0
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        b0c4bcf92286ad2f689805bf411e44a617df5a5455c703ddd8053f354d40b5cb:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0ec33e185e2d8e2e4bd97118f54276dbece4b6744371f895bd4c86e8e4dceedb
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:h200x1-throughput-bf16-6ylo-i-bbw
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H200x1 BF16 Throughput
      ngcMetadata:
        b795f66a018d1278aaded769cb88a79b5565d2fe6497739b03d8f1bad88e75d1:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 673a0a6cdd37cabec7d8dcc8f05f787884c72f2b56fcaad416429dda38238c0b
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_480GBx1 BF16 Latency
      ngcMetadata:
        c11d003373b87576201557974186967205684e4045905b5140a3d92f274cbf5f:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b41e403000a7d5221cdd4f00ab4d8a2ef58aa3470a65db51abd523b245c63ea6
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:l40sx2-latency-fp8-szl6-yje2g
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40Sx2 FP8 Latency
      ngcMetadata:
        c512ff489822b14e13879c4b1cbb849e5a45d453beeb2d9abfe52f029c0639d2:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 570d33681085a88ae5ea6bd28342996817acb2d9b0a5e8486e197bba77b832a1
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_ADAx1 INT4_AWQ Latency
      ngcMetadata:
        c95bbf72a36cc53dd0750074c0307cbc16ef98a8634cd89f94046e226c892ac9:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_ADA
            gpu_device: 26b1:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 737909c201e9ccea9bfb138401ed768b71985f2aad636ed91b7ca0712e02cb43
            number_of_gpus: '1'
            pp: '1'
            precision: int4_awq
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: INT4_AWQ
      - key: GPU
        value: RTX6000_ADA
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B1:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 BF16 Latency
      ngcMetadata:
        ccfeded811dbe0f17d70c25f83c247d1317114349b5df99ba1044c1fcb79b8ef:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 689cc0a0026ff1fff0e5818d26ffe369c59e7b16f96d9239248504fbab23c28c
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 BF16 Throughput
      ngcMetadata:
        d3ab627cccb5910fbce6396c9d205c84792abee634eb9f334c47086cf5d01b12:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: fa369969c2e20bb29b6b004cde3f63ba17a65056818bd8ad63528141ecb41527
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:a100x1-throughput-bf16-lwcrbwztpq
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A100x1 BF16 Throughput
      ngcMetadata:
        d67b7f59a9a2851e98bce877ee3702e82a3166322418dbf900a6a15e46643472:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2c735fe09841c686ba2f7ace400337d0f11be549d41cdeb9ba1c82688d0688fa
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_144GBx1 BF16 Latency
      ngcMetadata:
        db8a6f9d6f65eaec69ec78ea131cb34ec66bc63df975d23f8d2ccb031806dcc8:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c9d911dd01c8c520784ca0fec350f83855a8ca1ea1a3fed5f707fa642945a3e3
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:b200x1-throughput-fp8-i5rbiys4jq
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        e0b3ee6ce141beca50c67daccbebb1ce7417c14acd08c81346986898042733b6:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9d7c4bc4201757dcd3f1147712dfb1c83a8f8535405a59e1fa547f17b4a5869b
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 9GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct H100_NVLx1 BF16 Throughput
      ngcMetadata:
        e6c81e90a8ff3f2cf1b1bffbf760b05c7cf12d18c6486a4690b8ab81b6de436d:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b75eb29f401f555ea3d19a6df30861ef874d10760590ee8856ff0542d7ea1e7f
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        ed144c17645499c4cd983b4a2e4bdc23f0f03cc55e19073c357e8eb0ff982dc6:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: aab7bbbbcf3e6f7fb544ee77017dd2ee59aa0b81dc314dec4bb46317def34714
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct RTX6000_BLACKWELL_SVx1 FP8 Throughput
      ngcMetadata:
        ee928087f01a5df571cf5e62c96f66fedccaf180524ce1e43cb4b5a23295deb8:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 60b75ec923fe8a417deb0273d9a21b4fcd4e3e0f8f9ed6e9527a66433cf6030c
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:l40sx1-throughput-bf16-lh60z9g-aq
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct L40Sx1 BF16 Throughput
      ngcMetadata:
        eece8dae913d9055ed8060b6ae1764cefecd6d158dd314851e1ecd15b5d9126d:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ded6e827825103665f5fea2381f04196a88c95525aea31c073556f0204ad9c8e
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 16GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:8c22764a7e3675c50d4c7c9a4edb474456022b16
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct GH200_144GBx1 FP8 Latency
      ngcMetadata:
        ef8d429a394978d394a8d15ddbdd6666bde4dc68e40f8cb399b188f5b7e59db5:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 02d2b0459a15ab0a39ec4335caf74e3105e66f51ae577b7bf8a1b64cfcb5c472
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 30GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-8b-instruct:a10gx4-throughput-bf16-g04kznyzwa
      framework: TensorRT-LLM
      displayName: Llama 3.1 8B Instruct A10Gx4 BF16 Throughput
      ngcMetadata:
        f02876a90b3197bcf046fee9ab2beb6f7482b8b35e3ff9ff545d03ba9ba7bb23:
          model: meta/llama-3.1-8b-instruct
          release: 1.13.1
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: fda7bc4c0bf1f5eaeecbf29fbdd078ecbf587ac57c62610180d3d5fb90ffcfda
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.13.1
      - key: DOWNLOAD SIZE
        value: 19GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  - variantId: Llama 3.1 70B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/llama-3_1-70b-instruct-nemo
    optimizationProfiles:
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x1-throughput-nvfp4-lissxvpltg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x1 NVFP4 Throughput
      ngcMetadata:
        1b7ebc7f2cd12aa502b3f2bc17fa55a91f304abd992b287c535a59b6536d3e05:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b476c975e5339b67e01a1a9aee137aa1dd80c1d520b62ba160b64e426c8e2e6e
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx8 BF16 Latency
      ngcMetadata:
        266a5944d595ad57b186c01686b30ba7d1fc10f22a5b4fa17ef8d5cd54faf0f8:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 62c6e2eeff50dd4b71f6a31817eed7685778f8d1415340f402e269add0ca102b
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h200x4-latency-bf16-csp1xgtxoq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200x4 BF16 Latency
      ngcMetadata:
        2a56d7a6042e02c5b469f5128c76379973e255caf5b1adc1cde6e03230159077:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 91f8367eac71f0e5731988bac7b8b9ae66747619ed7cea336ff1ad2609b07945
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A100_SXM4_40GBx8 BF16 Throughput
      ngcMetadata:
        2fdeceaf1b64acf3ab1c2a22b8e23f6c25d639d6a5d7006c51c80b613fb2699b:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ce61710173c15471c4031430bc8de32b94fb1859a9d4d4cced5c09664b9658c3
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-throughput-fp8-ulen5raong
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct L40Sx4 FP8 Throughput
      ngcMetadata:
        3013dcf9b905cbd2f5e23f804fd5d66d183ddc71a8735631d3cad277f7c23897:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ce87554d33c9d66d40c52c15b3a90b5c802ef4b7d05781dc74fd18485a20e15d
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-latency-nvfp4-aiiz15cu0w
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x1 NVFP4 Latency
      ngcMetadata:
        344979e57f70e669d35378bc48ef7d14a13dc6aa0467ce9cb29166b8a8371bcb:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b668500698d48c5aee9f5b591c4383cb62053acb59539cf0b511b8b2d2ae864f
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx2 FP8 Throughput
      ngcMetadata:
        3526ceaf332ec21d4317c0939a99a3862b19593527fa942ffd5a1df2dade47ce:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2a535c9c9ddfb8e328abc28f3b4d9564ecdf9886fa177096f7b38dee7af754ab
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100_NVLx2 BF16 Throughput
      ngcMetadata:
        3684471ad5d007fa1f72bbc672a794107de7b0e8df88214dc1563a24aa99c8b7:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 22af385c5fd7064b011e826d0d78c210b7ac1fe7a9e29eef15e6a5e433b9db9d
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-latency-nvfp4-hrt0sgzswa
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x2 NVFP4 Latency
      ngcMetadata:
        377c705c5682293482c5094b946b8e74ccba5302c324b5ce41f952e9cac29890:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 289f1c679cc71fbadaa8139366458b0c3fc39d49ba067efdb7db9fbf3801ac1c
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-latency-fp8-ctp-cvrc0w
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct L40Sx4 FP8 Latency
      ngcMetadata:
        43160a1132063bf60ef6d7fe17a9b271f03dedbdb3bd1584a2e53707c8faa9ce:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f1a3de57c511586b258f58e7457103c919f8fa4db289d37961cad2468596ee6c
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100_NVLx2 FP8 Throughput
      ngcMetadata:
        44d44ef91639f0c76a1ef4be0022651ed8d42b485c26de00ba99aee570d1768d:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 1d049541d40b0b0407983f0438189a5d21af6652866d6640437e0323c7878361
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x2-throughput-bf16-lo9t8i-qua
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x2 BF16 Throughput
      ngcMetadata:
        45c52f130d8d467fa6e91f4ffee683fff5601e16df41388d4047e63e294e1165:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 706ae15947d58ed243812620f46199e223e7288c6624ccd33d9e9393a7bfb96a
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx2 NVFP4 Throughput
      ngcMetadata:
        4b9618100e94fc85d674a89eae960e18d8192163abe5db2a0d2be891d32ea06a:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 54ad694d948a6bd8d413341c0d9476b3756a5553aa8ce8ba5479d3b3cf289e9d
            number_of_gpus: '2'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h100x4-throughput-bf16-wf01-bcefa
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100x4 BF16 Throughput
      ngcMetadata:
        4d9f79288ba78fd61b3cc445c6f9da30362a132ea371798a8ec3dff7bddc3a20:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 22f873ff61f22bd360dc173f0f4a068d4d950c02ea6045570eb7f50ec8f83e93
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 139GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h100x2-throughput-fp8-vjxy5bkroq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100x2 FP8 Throughput
      ngcMetadata:
        4fbe63c3f6f9b928dac05fe81a278ac1ad45ccf329850f66bd6cbc0c2f2c044c:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: bb98ff9885aa439391b057063cce3555833a27f88d982b2c210fd4b752390475
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_144GBx2 BF16 Latency
      ngcMetadata:
        50fe6d2879cabe91e1e0b96314d40695e7ffc9e83a02d63629b9cabfae496dbe:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 21c7fedc20e7b94738606f7f4f8ebb346dc3f087f082dd32b713e4b8e6ed0a06
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200_NVLx2 FP8 Latency
      ngcMetadata:
        592714cb05c8f25c0445fb7467d096956db9bfbee0958eb713c02a5410867bff:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 90dae25f9f80d311b10f61f5772c37bac723422cce689c138396be49db0b82f4
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        5fbbcbeb676751bfdc9b65cca39334f82fbe543070ea66b4756f71de6cfe2b59:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b2d2411595259e3d02add53ce15aaae59cf5bb02731910aecbd8b5b7a3f75adc
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:a100x4-throughput-bf16-ftwaepe7oq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A100x4 BF16 Throughput
      ngcMetadata:
        68aff19a2e5198624143bf25060662c863ecf21039b6f2d4ef3fe7965a8bab96:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 8f849c4baf82033a3bbfba75bd2a6fc379c92079e81f6fca99f978c9d1c04ad1
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h200x2-latency-fp8-msyzoyixrw
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200x2 FP8 Latency
      ngcMetadata:
        6c27932dc47820a7130505d6bceca05a3ec27628a8416b4603b9b9c8367f161d:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 070c645e1731e5dd9875c800a22cadcd32f9008bf79b768884a331afc9c96e25
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-throughput-bf16-gfrr6smxia
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct L40Sx4 BF16 Throughput
      ngcMetadata:
        6c9c0490830921741f09a61b59d32ff645681d80194b3af37214824d65f05e7e:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e4710ee55a988086fb6dd511b81e989b78d523d951f0da1719cf0328d750a71e
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 140GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x1-throughput-fp8-ktlniezpyw
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        741556aa43f38761800674e07ff79f5d61136c8301687b3f914f61c78f72ce46:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d8ffe1683a73563951753b8b23c0854020887590f3a2112230e0ad947fe1ae99
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        75e60d670c274c13e9647548bc1c21549d28871432524a0c86becc2b9c73392e:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6a43b054452f258a2315e308da5d8813a4d5c7672764a4f28218373855853197
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 BF16 Throughput
      ngcMetadata:
        76296a7f2a589f543337824f321c38801835885f3a85d9efc3c5b820d7db5228:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4f131424adabbfc81a877f09da0ca3bb31989fc0bed618b8d0c5969faa01f7fe
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:a100x8-latency-bf16-zb8ixw2ong
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A100x8 BF16 Latency
      ngcMetadata:
        7cfa94d868fb7d979659d8418cbf37496cefd480d3b3b3ea06877b08e2868827:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 698871a2af3710aa48027caa8536573c057658a99a89b8d9652e15f19f0c2e12
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 147GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_480GBx1 FP8 Latency
      ngcMetadata:
        88a14e8523e8747165e8574a84cee8c4a580af03ced367e74017bf4046835dd2:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e85188dc62e0c517a93bc24a32bee7b7f27b66fa0c6e3184813a4873369e413f
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x4-latency-bf16-gqr-l-hprg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x4 BF16 Latency
      ngcMetadata:
        8cc3eeb4f2ae763b36bf76a67ed42daea7b533852a65090b522440956de4f327:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3a0889dd10acf4050ccd4fbb878eb5c982c420e3a63df2a2fafaa9fc6c8cf861
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h100x4-latency-fp8-oxqturnvsg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100x4 FP8 Latency
      ngcMetadata:
        9078b6b41878fcfd7e5e9dca2ea0b5c5560d85d31e2cbb9e0e9801d2bb192bfe:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: cc434557f087f390d162cf972e61958ba9e9f09b6112e174e9824b7bcd92e6f4
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200_NVLx1 FP8 Throughput
      ngcMetadata:
        92adc0b1a36388246d3f037e68df053c83b4bfe4d23e1fae59f711e6e451b944:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0e974238d656d94cb79d39fcc0064f619e6606c678fcba61651358275c693e75
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-throughput-nvfp4-w75uvvawyq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x1 NVFP4 Throughput
      ngcMetadata:
        a92446d9168e5b10aabe4d31889c68b90503f2ee9bbefafa7b406ef1f2f2b92b:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c593287a9ac875b3a649fb7725a9f1a1e6816129291594a3783a556296bd8808
            number_of_gpus: '1'
            pp: '1'
            precision: nvfp4
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 41GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-latency-fp8-zkeshhnnug
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x2 FP8 Latency
      ngcMetadata:
        b483bd59b245ec47d9b700691316ed76163f1500d17dcd1fd1fc13ef4fa34dbd:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: daec3db3d904aa6cba1cecd2404867f81d44cf10bb16cc9c9f0ee9a19085bb68
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 69GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100_NVLx4 FP8 Latency
      ngcMetadata:
        b8a18b250c3bd00464dd5194016ecc81756f0121ebc070081bdb2de6dd715a91:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e741999618e5a4d94b595ff13d17028e5f11db1d5ed50644fd584d34d553198b
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_144GBx2 BF16 Throughput
      ngcMetadata:
        bab01e4b4d692d4d879a405cac30bc3830fb4bfed76deaff130bc989bbf70008:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 943e58ca6ffb929366337f69cfc2a49f55a062cb721159a094ae6ade370d2302
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:a10gx8-throughput-bf16-c6h2bujzqq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A10Gx8 BF16 Throughput
      ngcMetadata:
        bb0acd8d341492a58388d49010ebfd53ccf30e9ba61961e68853b7812bdd57d5:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 91af47c6a8cd2c59b5187b47bcb6c3feaef274f685067c0ba391f035ccf265eb
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_144GBx2 FP8 Latency
      ngcMetadata:
        c02d69cc0542152ece147e75cb33487d9058a83ac94866680455b56c075cede4:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 50fd91ee630703f0af954360b638c997fa7e69b60ed949c129e3ba042ed47b66
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h200x1-throughput-fp8-j-xwy-p6zg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        cb42798192666f9b621fb9a5aeecb342ae389bb6c8992183804aeed016fc1862:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 0a504db21e8269006446b7b777218b5fc904fb8308dd5fbba24de96b577d289f
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GH200_144GBx2 FP8 Throughput
      ngcMetadata:
        d40298dbc0f90c12808e7e5becb22e47c284f05012c73dabb9818f03f461cd10:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ceebc0caeb9bdff847a148e0915219590cc463095bfb9545eb265978e4b8eb81
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A100_SXM4_40GBx8 BF16 Latency
      ngcMetadata:
        d847fc6b060db9381d38e6cb59ff183f29c6bb457c402d24c27971e59bad9bf7:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 35500bcc312a974be001478a0b1e2466fea9dac13d7bd087146f70d4c9e854c6
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-latency-fp8-f3rjvlafrw
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x1 FP8 Latency
      ngcMetadata:
        dbcdb5f1412398520d7330cb890aa57f1792596f7dc885cc65a1dc20d390cc9d:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a5a7e9799d92d3e8e2cb39c45acf73dee122f9f65c1bbeaf4eaf7d669745a89c
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:l40sx4-latency-bf16-jhyf9rlszq
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct L40Sx4 BF16 Latency
      ngcMetadata:
        e2b3ba60e795d306cf487ea71c8a5d128769f452eeffb54fada6697f031b556c:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 3d65171e66e53a0c6b9d1253a09c393d917cb611ea6de85f7c7abadf7ea934b6
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H100_NVLx4 BF16 Latency
      ngcMetadata:
        e6fcaba4b0c11392cd4ce8e0eddc261fac45e994c7735c3d79734245aac1a68d:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: dbc58664a141b59a060de53a9e4f2d25b4ec41f75fcb791a0f046981b0634fad
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x1-throughput-fp8-trr9koy1vg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x1 FP8 Throughput
      ngcMetadata:
        e8e4c9317e3e32c8e50d3f4c54019b40df5608a319359ad9f8257d23f2348c2b:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: cb02e92359903bcfa274d5176c8a7a840e58a3df1587ca0f0c734049d4f1d5c8
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 68GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:b200x2-throughput-bf16-gbt9zmjfla
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct B200x2 BF16 Throughput
      ngcMetadata:
        f078cbf33438ea9b68c5d4eba7bec671246d44730cbb0af6d94dfa1517bf3036:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 4db4480cbfa2cd40a70ed784e3bb40e3e7e4d6693b7d275fb0b19b328ea1da0a
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:a10gx8-latency-bf16-mqqdeavnfg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct A10Gx8 BF16 Latency
      ngcMetadata:
        f49e065d985faa3a766163f386395cc53c64429754c58cf9edf553ac0ec96244:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9c2fce4ab72d829d5e3b008b9f6b64a608194a97ee6fc18af7863cf922226107
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 150GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 NVFP4 Latency
      ngcMetadata:
        f66f34808a8fe25ee8a3666427569f3e7119b1af54cd64e31d082282d5d47210:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d7ec938fb438f8d87c58707eb5a60af4e1fb6a9b7ac42eef6738dd9b0d2ff671
            number_of_gpus: '4'
            pp: '1'
            precision: nvfp4
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: NVFP4
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:h200x2-throughput-bf16-9iwul7vevg
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200x2 BF16 Throughput
      ngcMetadata:
        f6d98b286dd43d8a6e677a9a0f218e76928154490a908a2d9f76cbfd2cd043bf:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 583b7cb36984c4bff9e31b3f10937d34d488b2e4e32ac4b0ac5b44e02ef4779b
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 134GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct RTX6000_BLACKWELL_SVx4 FP8 Latency
      ngcMetadata:
        f7397c4ee54cefd8fc3cc3b947406ba51947215d77ff58f35aeaa298605db13a:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ead7f13a4122bc78f9624682198bcccbc485345c9a58742601b0bf0e8ed59760
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:1d54af340dc8906a2d21146191a9c184c35e47bd
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct H200_NVLx2 BF16 Throughput
      ngcMetadata:
        fa4fbf5af52b66775f63d40cbc3db263304d7844095d1a677d799b8e90bf141b:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d2ae506c5cddf13a3d2f0139dcb6edafd042794999162e7d9623bd4ceabb1b70
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 263GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/meta/llama-3.1-70b-instruct:gb200x4-latency-bf16-3uozpudciw
      framework: TensorRT-LLM
      displayName: Llama 3.1 70B Instruct GB200x4 BF16 Latency
      ngcMetadata:
        fe20ab9158c65c3e7765e50c5c72ece46ee34a9e184dcdb13eda9bbef78ab300:
          model: meta/llama-3.1-70b-instruct
          release: 1.14.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e6a18cf6935b817ca2968d06e1abd91444d73634b80ff54f3680d152cadc209e
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.14.0
      - key: DOWNLOAD SIZE
        value: 138GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Llama
  - Meta
  - Text Generation
  - Large Language Model
  - TensorRT-LLM
  - Language Generation
  - NeMo
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
