models:
- name: Llama 3.3 70B Instruct
  displayName: Llama 3.3 70B Instruct
  modelHubID: llama-3-3-70b-instruct
  category: Text Generation
  type: NGC
  description: The Llama 3.3 70B-Instruct NIM simplifies the deployment of the Llama 3.3 70B instruction tuned model which is optimized for language understanding, reasoning, and text generation use cases, and outperforms many of the available open source chat models on common industry benchmarks.
  requireLicense: true
  licenseAgreements:
  - label: Use Policy
    url: https://www.llama.com/llama3_3/use-policy/
  - label: License Agreement
    url: https://www.llama.com/llama3_3/license/
  modelVariants:
  - variantId: Llama 3.3 70B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/meta/containers/llama-3.3-70b-instruct
    optimizationProfiles:
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x4-throughput-bf16-sf8byh808a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x4 BF16 Throughput
      ngcMetadata:
        00e6f59e1003f038ecee8e9aa3ab2d40745bef214c476a381b21886dd8383952:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 140GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-latency-fp8-nju7sb1wcw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x4 FP8 Latency
      ngcMetadata:
        13a9a5e5b372db6e92ecd2523a1a5d8b8f6ebd3fa8849608481e05a596a38d9e:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx8 BF16 Latency
      ngcMetadata:
        144fcde387869e92dfec8597f477ad671ee4424269e3e25cd16037c721bf925d:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx4 BF16 Throughput
      ngcMetadata:
        14654290e66815c15ef45c507c483a4bcc3a22fcc11a479083bce0a14b743b71:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-latency-fp8-z88enisl8a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 FP8 Latency
      ngcMetadata:
        233973ff86b33b1076b8d8dfbf1b1c292ad224ae2d9c8b18f28a44b6f6f42768:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 70GB
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx4-throughput-fp8-daydbgtrgg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx4 FP8 Throughput
      ngcMetadata:
        3d0e5989f2fbc23e7d4504cd69269c9636deb61d0efc12225d3d59d54afea297:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-latency-fp8-yoijdqa45a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x2 FP8 Latency
      ngcMetadata:
        4950d30811e1e426e97cda69e6c03a8a4819db8aa4abf34722ced4542a1f6b52:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx2 FP8 Throughput
      ngcMetadata:
        4c538175eb36814513f5c95c115c8ed15273f0cffda9d2d355a17f0f311f2fbd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx8 FP8 Latency
      ngcMetadata:
        582fd7bfbe504eb5ee4ded5254cced1d83ea2682a91b6dd6610af842be947ecc:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:l40sx8-throughput-bf16-essm4-kcrg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct L40Sx8 BF16 Throughput
      ngcMetadata:
        60b95dfcc3a17bf00cabb2da1a264f5e8757763d0ebe2a3a073c5c0fc7c078ec:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 151GB
    - profileId: nim/meta/llama-3.3-70b-instruct:a100x8-latency-bf16-i6bl589a3a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100x8 BF16 Latency
      ngcMetadata:
        646e2eff5f305302c1cd5fe873ef7c8172021d9948157163761817c4e36352d7:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 150GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx4 FP8 Throughput
      ngcMetadata:
        6708ebad5077e24eaff0eabce1134feb16b2a35d2313567b94e3f27479a90544:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-latency-fp8-tkp3aadetg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Latency
      ngcMetadata:
        6d6d2aebdecec52d7982746f98b00421cf53e10295a9ac7f993e4554fa164d10:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-throughput-bf16-eltdntbjla
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x4 BF16 Throughput
      ngcMetadata:
        6dc00fc21eb6d8de62d35c96eed22174e205fdb3db816dbe547deeb37fbdd9a8:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-latency-bf16-kwqeyhgvua
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 BF16 Latency
      ngcMetadata:
        758482618a1f166cc4e620228600410a6f05649a05c1838d5a93572d44289b95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 147GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx4 FP8 Latency
      ngcMetadata:
        76fc388794dc368145a440d16d72c0ba70e4aecac09901fe4a2c06a767c7eb0d:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-fp8-cqigo1kenw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 FP8 Throughput
      ngcMetadata:
        7d8a02f47911fb7ddf1a6f6b09438f621b6057cb21098999484f09d5a5bb7b23:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x2-throughput-fp8--pwiqokzsa
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x2 FP8 Throughput
      ngcMetadata:
        7ee2258631ed9d51ebfe5ab44bd547ae5777217686d87cc89c15d06ccdca4047:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x4-throughput-bf16-ygpeeau-0q
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x4 BF16 Throughput
      ngcMetadata:
        7f99ed5107c79b938b0ef4fcf2dd21aac27281f71d41a0a7c46d649879d374f0:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 138GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x1-throughput-fp8-sfrhca0ipw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x1 FP8 Throughput
      ngcMetadata:
        8b87146e39b0305ae1d73bc053564d1b4b4c565f81aa5abe3e84385544ca9b60:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 68GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x4-latency-fp8-jwv73nrwia
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x4 FP8 Latency
      ngcMetadata:
        9527145a2d1316a1e55581d1f6b0a45e394fe37b853ec5172dea14c2c9767d96:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x4-latency-bf16-bdxpl7wu-g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x4 BF16 Latency
      ngcMetadata:
        99142c13a095af184ae20945a208a81fae8d650ac0fd91747b03148383f882cf:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x4-throughput-bf16-dnxvrdjuta
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x4 BF16 Throughput
      ngcMetadata:
        9b4836e143f78d245cf161c16a225be11d3e8f9b2024b99dd76e5b2ac6cd7efd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x1-throughput-fp8-9qirfnkola
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x1 FP8 Throughput
      ngcMetadata:
        af876a179190d1832143f8b4f4a71f640f3df07b0503259cedee3e3a8363aa96:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 68GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-throughput-bf16-qxgo9ky1rq
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 BF16 Throughput
      ngcMetadata:
        b407d3df1db123ba8a4c98fb9f73790c01cd53a70fa0e0185814ad57a17cb72b:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-throughput-fp8-j5rwrqq4aa
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 FP8 Throughput
      ngcMetadata:
        c91a755246cb08dd9aa6905bc40b7db552071d141a850be5a791b06eb4fb2ef8:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h100x8-throughput-bf16-2i0l24npsg
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100x8 BF16 Throughput
      ngcMetadata:
        d128c772583bd10da4f31bf8e961893eb2b62363f3cecb94b5ef67d8bbd54665:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 147GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H100_NVLx8 BF16 Throughput
      ngcMetadata:
        d14fa7bd1f4287e74b856fe3f0030312cc4d03b8fe35a8c8aaedf0140ac55067:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x2-throughput-bf16-4qvbdeuv4a
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x2 BF16 Throughput
      ngcMetadata:
        d33e8144476992a7d8d621d8e50cf66b89d254dc721aa2782e5a5a6f07b1af80:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct A100_SXM4_40GBx8 BF16 Throughput
      ngcMetadata:
        dc0f5f87ca37f69af7f525ac293c599cd0cbdaf8130da4d9e2ad63d376b12039:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '8'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '8'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 8
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:h200x2-latency-fp8-pgmrxe0j3g
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct H200x2 FP8 Latency
      ngcMetadata:
        e4f217a5fb016b570e34b8a8eb06051ccfef9534ba43da973bb7f678242eaa5f:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:b200x4-latency-bf16-mnjb4olhmw
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct B200x4 BF16 Latency
      ngcMetadata:
        f17543bf1ee65e4a5c485385016927efe49cbc068a6021573d83eacb32537f76:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            number_of_gpus: '4'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '4'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 4
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 69GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct Generic NVIDIA GPUx8 BF16
      ngcMetadata:
        1d7b604f835f74791e6bfd843047fc00a5aef0f72954ca48ce963811fb6f3f09:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '8'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 8
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct Generic NVIDIA GPUx2 BF16
      ngcMetadata:
        375dc0ff86133c2a423fbe9ef46d8fdf12d6403b3caa3b8e70d7851a89fc90dd:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '2'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 2
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
    - profileId: nim/meta/llama-3.3-70b-instruct:hf-5825c91-tool-calling-fix-checksum
      framework: TensorRT-LLM
      displayName: Llama 3.3 70B Instruct Generic NVIDIA GPUx4 BF16
      ngcMetadata:
        54946b08b79ecf9e7f2d5c000234bf2cce19c8fee21b243c1a084b03897e8c95:
          model: meta/llama-3.3-70b-instruct
          release: 1.8.5
          tags:
            feat_lora: 'false'
            llm_engine: tensorrt_llm
            pp: '1'
            precision: bf16
            tp: '4'
            trtllm_buildable: 'true'
      modelFormat: trt-llm
      spec:
      - key: PRECISION
        value: BF16
      - key: COUNT
        value: 4
      - key: NIM VERSION
        value: 1.8.5
      - key: DOWNLOAD SIZE
        value: 132GB
  labels:
  - Llama
  - Meta
  - Chat
  - Text Generation
  - Large Language Model
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: llama
  license: NVIDIA AI Foundation Models Community License
