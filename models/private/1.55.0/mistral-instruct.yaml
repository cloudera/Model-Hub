models:
- name: Mistral Instruct
  displayName: Mistral Instruct
  modelHubID: mistral-instruct
  category: Text Generation
  type: NGC
  description: Mistral Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. The Mistral Instract Large Language Model (LLM) is an instruct fine-tuned version of the Mistral.
  modelVariants:
  - variantId: Mistral 7B Instruct
    modelCard: {
    "accessType": "NOT_LISTED",
    "application": "Other",
    "bias": "",
    "canGuestDownload": false,
    "createdDate": "2024-06-18T23:25:12.525Z",
    "description": "# **Mistral-7B-Instruct-v0.3 Overview**\n\n## **Description:**\n\n**Mistral-7B-Instruct-v0.3** is a large language model (LLM) that has been fine-tuned for instruction-based tasks. It is an improved version of the Mistral-7B-v0.3 model and is designed to be easily fine-tuned to achieve compelling performance. \n\nThis model is ready for commercial/non-commercial use.\n\nThis version introduces support for GB200 NVL72, GH200 NVL2, B200 and NVFP4. CUDA updated to version 12.9. For detailed information, refer to Release [Notes for NVIDIA NIM for LLMs LLM 1.12](https://docs.nvidia.com/nim/large-language-models/latest/release-notes.html). \n\n## **Third-Party Community Consideration**\n\nThis model is not owned or developed by NVIDIA. This model has been developed and built to a third-party's requirements for this application and use case; see link to Non-NVIDIA \\[mistralai/Mistral-7B-Instruct-v0.3\\]  \n([https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)). \n\n## **License/Terms of Use:**\n\n**GOVERNING TERMS:** The NIM container is governed by the [NVIDIA Software License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the [Product-Specific Terms for NVIDIA AI Products](https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/); and the use of the model is governed by the [NVIDIA AI Foundation Models Community License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-ai-foundation-models-community-license-agreement/).\n\n**ADDITIONAL INFORMATION:** Apache 2.0 License.\n\nYou are responsible for ensuring that your use of NVIDIA provided models complies with all applicable laws.\n\n## **Deployment Geography:**\n\nGlobal \n\n## **Use Case:**\n\nThis model is primarily intended for AI developers, researchers, and businesses seeking a powerful yet efficient foundational language model.\n\n### Expected uses include:\n\n* Fine-tuning for Custom Applications: Developers can use Mistral-7B-Instruct-v0.3 as a base to train specialized models for tasks like creating customer service chatbots, content summarization tools, code generation assistants, and sentiment analysis systems.\n\n* Research and Experimentation: Researchers can leverage this open-source model to study language model behavior, explore new training techniques, or establish performance benchmarks on various natural language processing tasks.\n\n* Prototyping AI Solutions: This model's excellent balance of high performance and relatively low computational cost makes it ideal for startups and individual developers to rapidly build and test proof-of-concept AI features before deploying larger-scale solutions.\n\n## **Release Date:**\n\nHuggingface 05/22/2024 via   \n[https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) \n\n## **Reference(s):** \n\n[https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) \n\n## **Model Architecture:** \n\nArchitecture Type: Transformer  \nNetwork Architecture: Mistral-7B-v0.3\n\nThis model was developed based on Mistral-7B-v0.3  \n[https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)  \n\nNumber of model parameters: 7.25*10^9\n\n## **Input:**\n\nInput Type(s): Text \n\nInput Format: String \n\nInput Parameters: One-Dimensional (1D)\n\nOther Properties Related to Input:\n\n* Tokens: The model processes text as a sequence of tokens. The input string is converted into a sequence of integer token IDs by a tokenizer. The vocabulary size is 32,768 tokens.  \n    \n* Size and Length Limits: The maximum input sequence length supported by the model is 32,768 tokens.  \n    \n* Pre-Processing Needed: Yes. Raw input text must be tokenized. For chat or instruction-following tasks, the input must be formatted according to the model's specific chat template, which typically involves wrapping user prompts in \\[INST\\] and \\[/INST\\] tags.\n\n \n\n## **Output:**\n\nOutput Type(s): Text \n\nOutput Format: String\n\nOutput Parameters: One-Dimensional (1D)\n\nOther Properties Related to Output: \n\n* Tokens: The model generates a sequence of token IDs from its vocabulary of 32,768 tokens.  \n    \n* Post-Processing Needed: Yes. The generated sequence of token IDs must be decoded by the tokenizer to be converted into a human-readable string.  \n* Length: The output length is variable and is controlled by generation parameters. Generation stops when an end-of-sequence (EOS) token is produced or the maximum length is reached.\n\nOur AI models are designed and/or optimized to run on NVIDIA GPU-accelerated systems. By leveraging NVIDIA's hardware (e.g. GPU cores) and software frameworks (e.g., CUDA libraries), the model achieves faster training and inference times compared to CPU-only solutions.\n\n## **Software Integration:**\n\nRuntime Engine: vLLM, TensorRT\n\nSupported Hardware Microarchitecture Compatibility:\n\nNVIDIA Ampere  \nNVIDIA Blackwell  \nNVIDIA Hopper  \nNVIDIA Lovelace \n\nPreferred Operating System(s):\n\nLinux   \nWindows\n\nThe integration of foundation and fine-tuned models into AI systems requires additional testing using use-case-specific data to ensure safe and effective deployment. Following the V-model methodology, iterative testing and validation at both unit and system levels are essential to mitigate risks, meet technical and functional requirements, and ensure compliance with safety and ethical standards before deployment.\n\n## **Model Version(s):**\n\nMistral-7B-Instruct-v0.3\n\n## **Usage**\n\n**Instruct following**\n\n```\nfrom mistral_inference.transformer import Transformer\nfrom mistral_inference.generate import generate\n\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\nfrom mistral_common.protocol.instruct.messages import UserMessage\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\n\n\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\nmodel = Transformer.from_folder(mistral_models_path)\n\ncompletion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\n\ntokens = tokenizer.encode_chat_completion(completion_request).tokens\n\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\nresult = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n\nprint(result)\n```\n\n**Function calling**\n\n```\nfrom mistral_common.protocol.instruct.tool_calls import Function, Tool\nfrom mistral_inference.transformer import Transformer\nfrom mistral_inference.generate import generate\n\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\nfrom mistral_common.protocol.instruct.messages import UserMessage\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\n\n\ntokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\nmodel = Transformer.from_folder(mistral_models_path)\n\ncompletion_request = ChatCompletionRequest(\n    tools=[\n        Tool(\n            function=Function(\n                name=\"get_current_weather\",\n                description=\"Get the current weather\",\n                parameters={\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": {\n                            \"type\": \"string\",\n                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n                        },\n                        \"format\": {\n                            \"type\": \"string\",\n                            \"enum\": [\"celsius\", \"fahrenheit\"],\n                            \"description\": \"The temperature unit to use. Infer this from the users location.\",\n                        },\n                    },\n                    \"required\": [\"location\", \"format\"],\n                },\n            )\n        )\n    ],\n    messages=[\n        UserMessage(content=\"What's the weather like today in Paris?\"),\n        ],\n)\n\ntokens = tokenizer.encode_chat_completion(completion_request).tokens\n\nout_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\nresult = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n\nprint(result)\n```\n\n**Generate with transformers**\n\n```\nfrom transformers import pipeline\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\nchatbot = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.3\")\nchatbot(messages)\n```\n\n**Function calling with transformers**\n\nTo use this example, you'll need transformers version 4.42.0 or higher. Please see the [function calling guide](https://huggingface.co/docs/transformers/main/chat_templating#advanced-tool-use--function-calling) in the transformers docs for more information.\n\n```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\ndef get_current_weather(location: str, format: str):\n    \"\"\"\n    Get the current weather\n\n    Args:\n        location: The city and state, e.g. San Francisco, CA\n        format: The temperature unit to use. Infer this from the users location. (choices: [\"celsius\", \"fahrenheit\"])\n    \"\"\"\n    pass\n\nconversation = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}]\ntools = [get_current_weather]\n\n\n# format and tokenize the tool use prompt \ninputs = tokenizer.apply_chat_template(\n            conversation,\n            tools=tools,\n            add_generation_prompt=True,\n            return_dict=True,\n            return_tensors=\"pt\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n\ninputs.to(model.device)\noutputs = model.generate(**inputs, max_new_tokens=1000)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n```\n\n## **Training, Testing, and Evaluation Datasets:**\n\n### **Training Dataset:**\n\n**Data Modality:** Text \n\n**Link:** Undisclosed\n\n**Data Collection Method by dataset:** Hybrid: Human, Synthetic, Automated\n\n**Labeling Method by dataset:** Hybrid: Automated, Synthetic, Human\n\n**Properties:** The pre-training data is a diverse mix of text and code from the public web. The fine-tuning data consists of high-quality instruction-response pairs.\n\n### **Testing Dataset:**\n\n**Link:** Undisclosed\n\n**Data Collection Method by dataset:** Hybrid: Human, Synthetic, Automated\n\n**Labeling Method by dataset:** Hybrid: Human, Automated\n\n**Properties:** \n\n* Quantity: The number of data items varies significantly per benchmark (e.g., MMLU has \\~15.9k questions, HellaSwag has \\~10k sentences).  \n* Dataset Descriptions: The model is tested against benchmarks designed to evaluate a wide range of capabilities, including: general knowledge and reasoning (MMLU, ARC), commonsense inference (HellaSwag, Winogrande), truthfulness (TruthfulQA), conversational ability (MT-Bench), and code generation (HumanEval, MBPP). \n\n### **Evaluation Dataset:**\n\n**Link:** Undisclosed\n\n**Data Collection Method by dataset:** Hybrid: Human, Synthetic, Automated\n\n**Labeling Method by dataset:** Hybrid: Human, Automated\n\n**Properties:** The model is evaluated against benchmarks designed to measure a wide range of capabilities, including: general knowledge and reasoning (MMLU), truthfulness (TruthfulQA), conversational ability (MT-Bench), and code generation (HumanEval). The quantity of data varies significantly per benchmark.\n\n## **Technical Limitations** \n\nThe Mistral-7B-Instruct model is a quick demonstration that the base model can be easily fine-tuned to achieve compelling performance. It does not have any moderation mechanisms. We're looking forward to engaging with the community on ways to leverage guardrails, allowing for deployment in environments requiring moderated outputs. \n\n## **Inference:**\n\n**Acceleration Engine:** vLLM, TensorRT \n\n**Test Hardware:** \n \n* B200 SXM   \n* H200 SXM  \n* H100 SXM  \n* A100 SXM 80GB  \n* A100 SXM 40GB  \n* L40S PCIe  \n* A10G  \n* H100 NVL  \n* H200 NVL  \n* GH200 96GB\n* GB200 NVL72\n* GH200 NVL2   \n* RTX 5090  \n* RTX 4090  \n* RTX 6000 Ada\n\n## **Deployment Details:**\n\nVisit the [NIM Container LLM](https://docs.nvidia.com/nim/large-language-models/latest/introduction.html) page for release documentation, deployment guides, and more.\n\n## Get Help\n\n## **Enterprise Support**\nGet access to knowledge base articles and support cases or [submit a ticket](https://www.nvidia.com/en-us/data-center/products/ai-enterprise-suite/support/).\n\nOur AI models are designed and/or optimized to run on NVIDIA GPU-accelerated systems. By leveraging NVIDIA\u2019s hardware (e.g. GPU cores) and software frameworks (e.g., CUDA libraries), the model achieves faster training and inference times compared to CPU-only solutions.\n\n## **Ethical Considerations:**\n\nNVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications. When downloaded or used in accordance with our terms of service, developers should work with their internal model team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse. Please report security vulnerabilities or NVIDIA AI Concerns [here](https://www.nvidia.com/en-us/support/submit-security-vulnerability/).\n\n**You are responsible for ensuring that your use of NVIDIA AI Foundation Models complies with all applicable laws.**",
    "displayName": "Mistral-7B-Instruct-v0.3",
    "explainability": "",
    "framework": "Other",
    "hasPlayground": false,
    "hasSignedVersion": true,
    "isPlaygroundEnabled": false,
    "isPublic": false,
    "isReadOnly": true,
    "labels": [
        "Bulk Build",
        "Mistral",
        "NIM",
        "NSPECT-YDAW-FMDD",
        "mistral-7b-instruct-v0-3",
        "nvaie:model:nvaie_supported",
        "nvidia_nim:model:nimmcro_nvidia_nim",
        "productNames:nim-dev",
        "productNames:nv-ai-enterprise"
    ],
    "latestVersionIdStr": "l40sx2-latency-bf16--dooucx8xw",
    "latestVersionSizeInBytes": 14861937693,
    "logo": "https://assets.ngc.nvidia.com/products/api-catalog/images/mistral-7b-instruct.jpg",
    "modelFormat": "N/A",
    "name": "mistral-7b-instruct-v0-3",
    "orgName": "nim",
    "precision": "N/A",
    "privacy": "",
    "productNames": [
        "nim-dev",
        "nv-ai-enterprise"
    ],
    "publicDatasetUsed": {},
    "publisher": "Mistral AI",
    "safetyAndSecurity": "",
    "shortDescription": "Mistral-7B-Instruct-v0.3 is a language model that can follow instructions, complete requests, and generate creative text formats",
    "teamName": "mistralai",
    "updatedDate": "2025-08-29T13:34:39.863Z"
}
    displayName: Mistral 7B Instruct
    source:
      URL: https://catalog.ngc.nvidia.com/orgs/nim/teams/mistralai/containers/mistral-7b-instruct-v0.3
    optimizationProfiles:
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200_NVLx1 BF16 Throughput
      ngcMetadata:
        090aed9ae0f4312f525a15003626f36dd30aded5cabb5bfd580cfb88510f7175:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 713cc9e4be3d70c5a99ac45e46c5cd2cb271b5c16228561f1daf992f8feac8ff
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x2-latency-fp8-6ewdxacbyg
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GB200x2 FP8 Latency
      ngcMetadata:
        0c430e8114b7d75876e040eb9e57f94f8780339c06d2afd7d52b8b520fe7d002:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 783069b3e78233c4649dfbd4031e5e32109f7eda1e54e623f39afa6771f69812
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx2-latency-fp8-werjmjtilg
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 L40Sx2 FP8 Latency
      ngcMetadata:
        0dd2f4179304094d417e6326812f71bf5583853f655c71d2992893485208b6c4:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f8c9fdd309012b470e249367853869bb7c38c8adf82866e2e1f02b6ffabc6429
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200_NVLx2 BF16 Latency
      ngcMetadata:
        1c8d8380b88e5e0b9dfa9bd7d9808e7b44533516e015e085121a17bec9f2803a:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9a8267f26d4614a846205cc91d2282acd830762361507abc23e58dfe78cd412c
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x2-latency-fp8-nnktn87ayw
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200x2 FP8 Latency
      ngcMetadata:
        1d71ecae305c2a01b823eac3cac374e0cf882795349b7c9aa045363c82f331a3:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6edfcc1e5567c57e834b36011decd5d2efb559be351273b2ad7c8768bae66e39
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 BF16 Latency
      ngcMetadata:
        21d116fd5db9b38ae613c9ec2117e796e0aeec6d8f24e92928ca1171b5f0db8a:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c78a84fee0362ed61ba62a668240cb6619c459e8c105ba274e13c186512f846d
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x1-throughput-bf16-fii9d12dng
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200x1 BF16 Throughput
      ngcMetadata:
        240f8bb29f20bd7b6f3a76367e82c2182d6f626ac3ac800daac124d6cdce1be6:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 9190e11b1ecbdeb46a92c026ca480103519885a8f07638f6d4a21d27a9118141
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A100_SXM4_40GBx2 BF16 Latency
      ngcMetadata:
        31f3565f323b25fb739b4319a054db75e52ad21e1e3adb93de0b7f932de6e954:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b84730aefe89d65c679b93ea096271ba583373eca30f081c680bed7dcff8f7c1
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x1-throughput-bf16-p8aaj1ui3a
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100x1 BF16 Throughput
      ngcMetadata:
        37fe5e59120c01002604cd395d38f91f3c71808c9a76060d772ee8625db8a9aa:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 43b0efb1c318ab00e8740ac496ec18fd55db1d3f50a9c9470408fd5b647ccb0e
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 BF16 Throughput
      ngcMetadata:
        3822e73f5b87aab36b8fa7f67f06b027ee79f259d4a6f6149d6e6e8834e15694:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 99355664e85deab8cef6bcda9b64b62eae3e6cb4fb72654992701318971d9cab
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 BF16 Latency
      ngcMetadata:
        3929f189d9fe09ced84378d555047f329e9b5d22ea05a84dfc27bf4e423ab2ab:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a01faf2c27412adcdcc908764085b24d58398d230a42ecc86b4d0241886d55b6
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 FP8 Throughput
      ngcMetadata:
        3d2e4a566abec5fdab7016cf1ee4b9f0a28c0bbaf1ab5ba1fbcb739b9fbbfab6:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: dcbbb88340365f3a3ce5006101441492476ef83235d14fb9d2eaf245868f6e51
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx1-throughput-bf16-wgortubrfa
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 L40Sx1 BF16 Throughput
      ngcMetadata:
        3d97e245329239baeda4299616d3379ddbea98f0f30a9fb6a0f97ff3bb593593:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 59b129434dc4805de4e69fc1e786327abcad095b67e099df18a0741700fc3562
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x2-latency-bf16-k0zyvwltfq
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 B200x2 BF16 Latency
      ngcMetadata:
        4369fb715f1d8a01cec62d750cbea038af0b5f5f032a372236fe6cb7ecaad891:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: b41d026216b5cc343dc386982bc593595899581dd03e2e608bc13a7d7fe1fb71
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100_NVLx1 FP8 Throughput
      ngcMetadata:
        4c9a845c4a8037390a5d87a8e2db4a9ef8c7cc5c5e613960b771adce3e548deb:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 00ae490b209e488c85835da5990d77b81c03bd111838c6ab188f5b3c1084f5f0
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x2-latency-bf16-wkgtx84w0q
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GB200x2 BF16 Latency
      ngcMetadata:
        514f55258d4cffc08411144a8709add1d6dfda7563894feee671bad11a2be79c:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 054261eb6e99db9b73dd8ff0146b8748e4676c27344512bb070ffd471c54002d
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100_NVLx2 FP8 Latency
      ngcMetadata:
        5165a3e3a29e9d6717869d3960133151f93437c8c34a297c2b6080763bfdcf32:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 20bd7371c735a556fea27dd89285a4bc2bb8cc5630c912da7ba9bdfd4fe0f149
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x1-throughput-bf16-bzgxd7omcg
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 B200x1 BF16 Throughput
      ngcMetadata:
        5a9eef29a1519f40178baec3444a0133990c5ed49ebd6e0ee5de5391f403c25f:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 99677dd60c3849da7d5daab13e7094c8f15c1ed0b324691dcfeb07c340748155
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x1-throughput-fp8-1kujysl0bw
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 B200x1 FP8 Throughput
      ngcMetadata:
        61a13f62e79b27cd7c69c32477b58857196ccc914a1b9f526fb9715238ceaddd:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f9ef3850321d85a46a3267f358c73bc62479d5fd3bd077bfbaa54968926284ab
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_144GBx1 FP8 Latency
      ngcMetadata:
        6bdad363d842f0dc7b89c0bcdbfce49ab7ff3c77a7f1aaf741e10b5a8cfc7b65:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_144GB
            gpu_device: 2348:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 05684b1b6aeb72f02bd8422d6f4bd2c193e2409465575f3b01fd7fe0ca606056
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_144GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2348:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 BF16 Latency
      ngcMetadata:
        6e083975f86a7bd245f26d412ca4c0d99bed4a05e85eb516c7bf23d4a8dbc635:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 01c793b12ef404fe8d3d97f17a5851e07af0ce3e1ed7028940203e38020cff5b
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 FP8 Throughput
      ngcMetadata:
        6f9107642dc7198eb0084ba462da560fe696b28a74dc9bd5747f58b2229c0833:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 60a40aa9dddaddacb1f4f7ebbb536b33494d4a252b563fb321152125c6e5be1d
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a10gx1-throughput-bf16-dbarntjrxg
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A10Gx1 BF16 Throughput
      ngcMetadata:
        8aff3c4c1c985c1ab4bd362202c194479652465f22c634e79fead9f935d9f308:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e936f5f6f910166d5a160a10cd1a565e15bac32bd77cdf527f23a97e9a792622
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a100x1-throughput-bf16-ug2ytdn9rq
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A100x1 BF16 Throughput
      ngcMetadata:
        8d844ff4c978b716fb1b3044d4663305081e95fe9e3281ccbc60ebd243137939:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 52c07121ddb1886588c745606458ef1289c479b94c2e1d77b8260c89cb5e40ce
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200_NVLx1 FP8 Throughput
      ngcMetadata:
        8e60a02116ccc9ed3587946a5b2ad0c431826d89e36be714dfa92044e84579de:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e395395c3d17874ecbc16978f25f851e3a8e4b08e6f107f8d1e00dc1f485aad2
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100_NVLx1 BF16 Throughput
      ngcMetadata:
        8f1c5ed6338e2517b1db9987ca4a9cab78ad17acca14801eb301cd52fb60a4e2:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 7b2c3bc5c67da0408b365dcde48b64e5ac4c4b316e7061e4da026d8ebfa23c60
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 BF16 Throughput
      ngcMetadata:
        a049a483413cc9fcf09502fb199582de0948a105c7d58ed41023f74fcf46a84a:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6fd41902191734a0e6c6105beef1c9eaec18a21786868ec1f5cf9876f924709f
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x2-latency-bf16-utfzkvbx7q
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200x2 BF16 Latency
      ngcMetadata:
        a2bd430ddfc5a8063daef926241911c1db8503f6b24034483213620ea0d6534c:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: fb34a1eb2c580f06657b13b17ed3fdcebd849fce79f29c090d58c8798bf18df0
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x1-throughput-fp8-3zk3rahgzq
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100x1 FP8 Throughput
      ngcMetadata:
        a91be3d64f314c006fa8f85baacd7a54eda8be911ac8ab66cca6b02044de16a8:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 6f2d35f77b6e720ee0f8c950a138b31d739efd3c69094c0d830c7a6e1657575b
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx1-throughput-fp8-kegtu7-f8w
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 L40Sx1 FP8 Throughput
      ngcMetadata:
        a9776f67cf10b8456cb9c6a3cc657310cf6b402b482f75294f89a832813e585d:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: a002dbee023af5c15de8bd132e0ad771081f285acdb4196fc77df8e2d5025bf7
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: L40S
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a10gx2-latency-bf16-ultpn-z0fa
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A10Gx2 BF16 Latency
      ngcMetadata:
        b75e85db64643ec2a6fe296828296b6fb2971998445181b3e92bb4edb7028f9c:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A10G
            gpu_device: 2237:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 2d647a36531389075e6d579d0e030fcaeb428ec3056fdf12e56ad673c99c3e9d
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A10G
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2237:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A100_SXM4_40GBx1 BF16 Throughput
      ngcMetadata:
        c30c03b6c527e5bbc13c9024db7888bd3ef1f81f5437dd5eeb639963e7f956c0:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100_SXM4_40GB
            gpu_device: 20b0:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 1b85347f49cd97c7a43491a4065364128a860973559d1fbb418436cf1d22071f
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100_SXM4_40GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 20B0:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 FP8 Latency
      ngcMetadata:
        c5440e61e502d2bde9d8182735ec4b3cb5dc07386768b22e3fd11afb8f9123e1:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c1481c7a0c16fafd6097a18868e47f96bdb3e9bfef14223ed63d4c58b0b41046
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 FP8 Latency
      ngcMetadata:
        c6298bc319a27d0b8ce68b6ff2ee478f4503a532f85281db4e58e09bdc1e828d:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: bb8fc0519d6e093698164f6283010687e2acf7b28c240faeebcb9f6d04f3bdfd
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:a100x2-latency-bf16-eao98qqyaq
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 A100x2 BF16 Latency
      ngcMetadata:
        cffacd84594ea7bf5f03f8eaaa107d0e6078dadf84c2b8919c53ecc44ec0a418:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: A100
            gpu_device: 20b2:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 31efbfeecc0071b15073a663036ed7854fe34edad643248b0b33f1648d396528
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: A100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 20B2:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x1-throughput-bf16-b7lzpmozrg
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GB200x1 BF16 Throughput
      ngcMetadata:
        d3e771cdfdccfc6685afb1749f581cbd723b3f4a7180453c366e49fe02201035:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 36332f865d9e636409ef1d780e1e129a7958c56612e251e991090198a71ecca2
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x2-latency-fp8-ubwp9icmag
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100x2 FP8 Latency
      ngcMetadata:
        d4d4737e0a2b76a1409c12d66a70924643f1bfca7448ca7bb9deb7a25f449470:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 5a148e8d8559629ab65b636a3344bd0a6c9d5ea1e7974bcdc5eb9273bc0c3aec
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:b200x2-latency-fp8-dmol-yoeqa
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 B200x2 FP8 Latency
      ngcMetadata:
        d772d81834faf0d0f3021ff92ea6893131a28c7b1eacedff9586b5304c768e16:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: B200
            gpu_device: 2901:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: d21056b60d5e01083565a8671683b54e86879aa36a36475318838deec4613666
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: B200
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2901:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GH200_480GBx1 FP8 Throughput
      ngcMetadata:
        e2392b25430a3f1fcec000a51661f633d36450438db8b09765dffaced7fac7e7:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GH200_480GB
            gpu_device: 2342:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 5ae57ff46795ac07b5bb351fafc5f767a4c62e864a2c283d982e92c8d82273e8
            number_of_gpus: '1'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GH200_480GB
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2342:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 RTX6000_BLACKWELL_SVx1 BF16 Throughput
      ngcMetadata:
        e2698f06fe02b17f4ac157fb39bd9ae75282d96e0a618c96ca9472a04bd3679b:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: RTX6000_BLACKWELL_SV
            gpu_device: 2bb5:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: e8b647653354c51429e61400d7e38ea59531989d0808b570fa5755b7d6bfe130
            number_of_gpus: '1'
            pp: '1'
            precision: bf16
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: BF16
      - key: GPU
        value: RTX6000_BLACKWELL_SV
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2BB5:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200_NVLx2 FP8 Latency
      ngcMetadata:
        e7014f30a669dca5d114ee37df6385a5453b02a23614832ef7bdb0e7f1622d11:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200_NVL
            gpu_device: 233b:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 43c16ff7a8e64039006342b0ba5d0067d7b3e49f7a913f06e67128585266aa67
            number_of_gpus: '4'
            pp: '1'
            precision: fp8
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 233B:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:l40sx2-latency-bf16--dooucx8xw
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 L40Sx2 BF16 Latency
      ngcMetadata:
        e93d09fc66b8e716a8370d431143b6d5efa1ab47a3aed691907d3c3d8d85bd4d:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: L40S
            gpu_device: 26b9:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: ee18ec1b20cc3bbaff5d95b5e157c2d8ab9dc856df258de26b73ff6ec8e9f98d
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: L40S
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 26B9:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h100x2-latency-bf16-y5oxwbaufw
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100x2 BF16 Latency
      ngcMetadata:
        f01bf801094b032f87027566ae9036ac0489547a3a650a93bf7af4e12d7975c8:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100
            gpu_device: 2330:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 87eccccb3d5001d66e004f0e0bd2e26e245774007035b6d3c9a01f120c5d5f02
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2330:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 14GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:gb200x1-throughput-fp8-ndgj2enqyq
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 GB200x1 FP8 Throughput
      ngcMetadata:
        f76535fba1856c95ce15f11a3228fcb0469242f4921644d94fa682220c518c3f:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: GB200
            gpu_device: 2941:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: c0ef6863d68dbd3c3fdb7f3a0e8f2da9daf77c94757f228736a335de4a1ae628
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: GB200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2941:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:hf-0d4b76e-tool_calling-bf16
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H100_NVLx2 BF16 Latency
      ngcMetadata:
        f97a97adc7e9ca1ae225535ac8949af0f306846b429f079946fcc43cf0346f20:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H100_NVL
            gpu_device: 2321:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: 620affc99411e713b97069819f83de5bb626bf16dcb1d064492ad50dfc9641b7
            number_of_gpus: '2'
            pp: '1'
            precision: bf16
            profile: latency
            tp: '2'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: LATENCY
      - key: PRECISION
        value: BF16
      - key: GPU
        value: H100_NVL
      - key: COUNT
        value: 2
      - key: GPU DEVICE
        value: 2321:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 28GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
    - profileId: nim/mistralai/mistral-7b-instruct-v0-3:h200x1-throughput-fp8-ez1figc57w
      framework: TensorRT-LLM
      displayName: Mistral 7B Instruct V0.3 H200x1 FP8 Throughput
      ngcMetadata:
        fd130b01c59445a3967c804d57077fd77a3b2f76048603516402320f809f88ad:
          model: mistralai/mistral-7b-instruct-v0.3
          release: 1.12.0
          tags:
            feat_lora: 'false'
            gpu: H200
            gpu_device: 2335:10de
            llm_engine: tensorrt_llm
            nim_workspace_hash_v1: f830f542f5a36acc42ddf3d7f7823662ed361c4e8e0ee0007cfe70da3df2fb9f
            number_of_gpus: '2'
            pp: '1'
            precision: fp8
            profile: throughput
            tp: '1'
      modelFormat: trt-llm
      spec:
      - key: PROFILE
        value: THROUGHPUT
      - key: PRECISION
        value: FP8
      - key: GPU
        value: H200
      - key: COUNT
        value: 1
      - key: GPU DEVICE
        value: 2335:10DE
      - key: NIM VERSION
        value: 1.12.0
      - key: DOWNLOAD SIZE
        value: 8GB
      - key: LLM ENGINE
        value: TENSORRT_LLM
  labels:
  - Mistral
  - Instruct
  - Large Language Model
  - TensorRT-LLM
  - Language Generation
  - NeMo
  - NVIDIA Validated
  config:
    architectures:
    - Other
    modelType: Mistral
  license: NVIDIA AI Foundation Models Community License
